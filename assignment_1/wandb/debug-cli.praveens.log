2024-05-19 07:08:12 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:08:12 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:08:12 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:08:12 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:08:12 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:08:12 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:09:31 INFO Running runs: []
2024-05-19 07:09:31 INFO Agent received command: run
2024-05-19 07:09:31 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta_1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-19 07:09:31 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta_1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=random
2024-05-19 07:09:36 INFO Running runs: ['phit4zw4']
2024-05-19 07:10:40 INFO Cleaning up finished run: phit4zw4
2024-05-19 07:10:41 INFO Agent received command: run
2024-05-19 07:10:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta_1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-19 07:10:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta_1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=random
2024-05-19 07:10:46 INFO Running runs: ['wqzl2xvv']
2024-05-19 07:10:51 INFO Cleaning up finished run: wqzl2xvv
2024-05-19 07:10:52 INFO Agent received command: run
2024-05-19 07:10:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta_1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: Xavier
2024-05-19 07:10:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta_1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=Xavier
2024-05-19 07:10:57 INFO Running runs: ['t4gxpzb2']
2024-05-19 07:10:57 INFO Cleaning up finished run: t4gxpzb2
2024-05-19 07:10:57 INFO Agent received command: run
2024-05-19 07:10:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta_1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-19 07:10:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta_1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-19 07:11:02 INFO Running runs: ['opk2r571']
2024-05-19 07:11:02 INFO Cleaning up finished run: opk2r571
2024-05-19 07:11:03 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:11:03 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:11:03 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:11:03 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:11:03 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:11:03 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:09 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:12:34 INFO Running runs: []
2024-05-19 07:12:35 INFO Agent received command: run
2024-05-19 07:12:35 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: random
2024-05-19 07:12:35 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=random
2024-05-19 07:12:40 INFO Running runs: ['jwg67obr']
2024-05-19 07:14:37 INFO Cleaning up finished run: jwg67obr
2024-05-19 07:14:46 INFO Agent received command: run
2024-05-19 07:14:46 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: Xavier
2024-05-19 07:14:46 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=Xavier
2024-05-19 07:14:51 INFO Running runs: ['ux28pwtd']
2024-05-19 07:15:44 INFO Cleaning up finished run: ux28pwtd
2024-05-19 07:15:45 INFO Agent received command: run
2024-05-19 07:15:45 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: Xavier
2024-05-19 07:15:45 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=Xavier
2024-05-19 07:15:50 INFO Running runs: ['w873t0ik']
2024-05-19 07:16:11 INFO Cleaning up finished run: w873t0ik
2024-05-19 07:16:12 INFO Agent received command: run
2024-05-19 07:16:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: Xavier
2024-05-19 07:16:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=Xavier
2024-05-19 07:16:17 INFO Running runs: ['emuzboyv']
2024-05-19 07:16:34 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:16:34 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:16:34 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:16:34 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:16:34 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:16:34 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:06 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-19 07:18:37 INFO Running runs: []
2024-05-19 07:18:38 INFO Agent received command: run
2024-05-19 07:18:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-19 07:18:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=random
2024-05-19 07:18:43 INFO Running runs: ['uroeg935']
2024-05-19 07:21:17 INFO Cleaning up finished run: uroeg935
2024-05-19 07:21:22 INFO Agent received command: run
2024-05-19 07:21:22 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-19 07:21:22 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-19 07:21:27 INFO Running runs: ['aua6byuh']
2024-05-19 07:23:02 INFO Cleaning up finished run: aua6byuh
2024-05-19 07:23:03 INFO Agent received command: run
2024-05-19 07:23:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 07:23:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 07:23:08 INFO Running runs: ['my1up8q2']
2024-05-19 07:25:52 INFO Cleaning up finished run: my1up8q2
2024-05-19 07:25:53 INFO Agent received command: run
2024-05-19 07:25:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 07:25:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 07:25:58 INFO Running runs: ['zxyks7nh']
2024-05-19 07:28:16 INFO Cleaning up finished run: zxyks7nh
2024-05-19 07:28:17 INFO Agent received command: run
2024-05-19 07:28:17 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 07:28:17 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 07:28:22 INFO Running runs: ['ohsv8gyv']
2024-05-19 07:30:50 INFO Cleaning up finished run: ohsv8gyv
2024-05-19 07:30:51 INFO Agent received command: run
2024-05-19 07:30:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: random
2024-05-19 07:30:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=random
2024-05-19 07:30:56 INFO Running runs: ['wqhr7003']
2024-05-19 07:33:14 INFO Cleaning up finished run: wqhr7003
2024-05-19 07:33:15 INFO Agent received command: run
2024-05-19 07:33:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-19 07:33:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=random
2024-05-19 07:33:20 INFO Running runs: ['6qve0hfl']
2024-05-19 07:35:33 INFO Cleaning up finished run: 6qve0hfl
2024-05-19 07:35:33 INFO Agent received command: run
2024-05-19 07:35:33 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: random
2024-05-19 07:35:33 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=random
2024-05-19 07:35:38 INFO Running runs: ['rds23ri9']
2024-05-19 07:36:47 INFO Cleaning up finished run: rds23ri9
2024-05-19 07:36:48 INFO Agent received command: run
2024-05-19 07:36:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-19 07:36:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=random
2024-05-19 07:36:53 INFO Running runs: ['8ridkr57']
2024-05-19 07:37:41 INFO Cleaning up finished run: 8ridkr57
2024-05-19 07:37:42 INFO Agent received command: run
2024-05-19 07:37:42 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 07:37:42 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 07:37:47 INFO Running runs: ['60ra0ly4']
2024-05-19 07:39:01 INFO Cleaning up finished run: 60ra0ly4
2024-05-19 07:39:02 INFO Agent received command: run
2024-05-19 07:39:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-19 07:39:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=random
2024-05-19 07:39:07 INFO Running runs: ['w80gu1rn']
2024-05-19 07:40:53 INFO Cleaning up finished run: w80gu1rn
2024-05-19 07:40:54 INFO Agent received command: run
2024-05-19 07:40:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 07:40:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 07:40:59 INFO Running runs: ['mr0td1di']
2024-05-19 07:43:17 INFO Cleaning up finished run: mr0td1di
2024-05-19 07:43:18 INFO Agent received command: run
2024-05-19 07:43:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-19 07:43:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=random
2024-05-19 07:43:23 INFO Running runs: ['210ofbvx']
2024-05-19 07:44:37 INFO Cleaning up finished run: 210ofbvx
2024-05-19 07:44:38 INFO Agent received command: run
2024-05-19 07:44:38 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 07:44:38 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 07:44:43 INFO Running runs: ['mvazt3vo']
2024-05-19 07:45:51 INFO Cleaning up finished run: mvazt3vo
2024-05-19 07:45:53 INFO Agent received command: run
2024-05-19 07:45:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 07:45:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 07:45:58 INFO Running runs: ['k25s2z7j']
2024-05-19 07:46:56 INFO Cleaning up finished run: k25s2z7j
2024-05-19 07:46:57 INFO Agent received command: run
2024-05-19 07:46:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 07:46:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 07:47:02 INFO Running runs: ['e570hhws']
2024-05-19 07:50:02 INFO Cleaning up finished run: e570hhws
2024-05-19 07:50:07 INFO Agent received command: run
2024-05-19 07:50:07 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-19 07:50:07 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=random
2024-05-19 07:50:12 INFO Running runs: ['90wu8akq']
2024-05-19 07:51:26 INFO Cleaning up finished run: 90wu8akq
2024-05-19 07:51:27 INFO Agent received command: run
2024-05-19 07:51:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: random
2024-05-19 07:51:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=random
2024-05-19 07:51:32 INFO Running runs: ['7ziofv4x']
2024-05-19 07:54:27 INFO Cleaning up finished run: 7ziofv4x
2024-05-19 07:54:30 INFO Agent received command: run
2024-05-19 07:54:30 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 07:54:30 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 07:54:35 INFO Running runs: ['sadaxqs0']
2024-05-19 07:57:25 INFO Cleaning up finished run: sadaxqs0
2024-05-19 07:57:26 INFO Agent received command: run
2024-05-19 07:57:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-19 07:57:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-19 07:57:31 INFO Running runs: ['oes03ljj']
2024-05-19 07:59:01 INFO Cleaning up finished run: oes03ljj
2024-05-19 07:59:01 INFO Agent received command: run
2024-05-19 07:59:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-19 07:59:01 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=random
2024-05-19 07:59:06 INFO Running runs: ['1yjq1tuo']
2024-05-19 08:00:31 INFO Cleaning up finished run: 1yjq1tuo
2024-05-19 08:00:32 INFO Agent received command: run
2024-05-19 08:00:32 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-19 08:00:32 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=random
2024-05-19 08:00:37 INFO Running runs: ['38nclizx']
2024-05-19 08:01:51 INFO Cleaning up finished run: 38nclizx
2024-05-19 08:01:52 INFO Agent received command: run
2024-05-19 08:01:52 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-19 08:01:52 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=random
2024-05-19 08:01:57 INFO Running runs: ['oghhgyvv']
2024-05-19 08:03:06 INFO Cleaning up finished run: oghhgyvv
2024-05-19 08:03:08 INFO Agent received command: run
2024-05-19 08:03:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 08:03:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 08:03:13 INFO Running runs: ['1762hlr3']
2024-05-19 08:04:59 INFO Cleaning up finished run: 1762hlr3
2024-05-19 08:05:01 INFO Agent received command: run
2024-05-19 08:05:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-19 08:05:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=random
2024-05-19 08:05:06 INFO Running runs: ['z5fq96co']
2024-05-19 08:06:20 INFO Cleaning up finished run: z5fq96co
2024-05-19 08:06:20 INFO Agent received command: run
2024-05-19 08:06:20 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 08:06:20 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 08:06:26 INFO Running runs: ['dsi9c8qx']
2024-05-19 08:07:29 INFO Cleaning up finished run: dsi9c8qx
2024-05-19 08:07:30 INFO Agent received command: run
2024-05-19 08:07:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-19 08:07:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-19 08:07:35 INFO Running runs: ['kegcuz31']
2024-05-19 08:08:33 INFO Cleaning up finished run: kegcuz31
2024-05-19 08:08:34 INFO Agent received command: run
2024-05-19 08:08:34 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 08:08:34 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 08:08:39 INFO Running runs: ['t5jfhjfy']
2024-05-19 08:10:25 INFO Cleaning up finished run: t5jfhjfy
2024-05-19 08:10:31 INFO Agent received command: run
2024-05-19 08:10:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-19 08:10:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-19 08:10:36 INFO Running runs: ['c5v97ys4']
2024-05-19 08:13:31 INFO Cleaning up finished run: c5v97ys4
2024-05-19 08:13:32 INFO Agent received command: run
2024-05-19 08:13:32 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-19 08:13:32 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-19 08:13:37 INFO Running runs: ['0b0tdsqq']
2024-05-19 08:15:55 INFO Cleaning up finished run: 0b0tdsqq
2024-05-19 08:16:07 INFO Agent received command: run
2024-05-19 08:16:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-19 08:16:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=random
2024-05-19 08:16:12 INFO Running runs: ['nu8jer6s']
2024-05-19 08:18:35 INFO Cleaning up finished run: nu8jer6s
2024-05-19 08:18:36 INFO Agent received command: run
2024-05-19 08:18:36 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: random
2024-05-19 08:18:36 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=random
2024-05-19 08:18:41 INFO Running runs: ['15kd8umh']
2024-05-19 08:20:17 INFO Cleaning up finished run: 15kd8umh
2024-05-19 08:20:18 INFO Agent received command: run
2024-05-19 08:20:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 08:20:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 08:20:23 INFO Running runs: ['icq6nck8']
2024-05-19 08:22:04 INFO Cleaning up finished run: icq6nck8
2024-05-19 08:22:05 INFO Agent received command: run
2024-05-19 08:22:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 08:22:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 08:22:10 INFO Running runs: ['46tfgqob']
2024-05-19 08:25:10 INFO Cleaning up finished run: 46tfgqob
2024-05-19 08:25:10 INFO Agent received command: run
2024-05-19 08:25:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 08:25:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 08:25:15 INFO Running runs: ['y92pke6m']
2024-05-19 08:26:51 INFO Cleaning up finished run: y92pke6m
2024-05-19 08:26:53 INFO Agent received command: run
2024-05-19 08:26:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-19 08:26:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=random
2024-05-19 08:26:58 INFO Running runs: ['41r8on89']
2024-05-19 08:29:05 INFO Cleaning up finished run: 41r8on89
2024-05-19 08:29:05 INFO Agent received command: run
2024-05-19 08:29:05 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 08:29:05 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 08:29:10 INFO Running runs: ['mso6w4t3']
2024-05-19 08:31:17 INFO Cleaning up finished run: mso6w4t3
2024-05-19 08:31:18 INFO Agent received command: run
2024-05-19 08:31:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 08:31:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 08:31:23 INFO Running runs: ['nrmxjq5o']
2024-05-19 08:32:32 INFO Cleaning up finished run: nrmxjq5o
2024-05-19 08:32:33 INFO Agent received command: run
2024-05-19 08:32:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 08:32:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 08:32:38 INFO Running runs: ['6cv1bqmk']
2024-05-19 08:34:45 INFO Cleaning up finished run: 6cv1bqmk
2024-05-19 08:34:46 INFO Agent received command: run
2024-05-19 08:34:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 08:34:46 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 08:34:51 INFO Running runs: ['0ltqb20q']
2024-05-19 08:36:47 INFO Cleaning up finished run: 0ltqb20q
2024-05-19 08:36:48 INFO Agent received command: run
2024-05-19 08:36:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: random
2024-05-19 08:36:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=random
2024-05-19 08:36:53 INFO Running runs: ['bmoeogby']
2024-05-19 08:38:49 INFO Cleaning up finished run: bmoeogby
2024-05-19 08:38:50 INFO Agent received command: run
2024-05-19 08:38:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 08:38:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 08:38:55 INFO Running runs: ['d3w9qydm']
2024-05-19 08:40:35 INFO Cleaning up finished run: d3w9qydm
2024-05-19 08:40:36 INFO Agent received command: run
2024-05-19 08:40:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-19 08:40:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=random
2024-05-19 08:40:41 INFO Running runs: ['cuctamoz']
2024-05-19 08:42:27 INFO Cleaning up finished run: cuctamoz
2024-05-19 08:42:28 INFO Agent received command: run
2024-05-19 08:42:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 08:42:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 08:42:33 INFO Running runs: ['9bxk4yf4']
2024-05-19 08:45:12 INFO Cleaning up finished run: 9bxk4yf4
2024-05-19 08:45:12 INFO Agent received command: run
2024-05-19 08:45:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 08:45:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 08:45:17 INFO Running runs: ['ekb2vcu4']
2024-05-19 08:47:20 INFO Cleaning up finished run: ekb2vcu4
2024-05-19 08:47:33 INFO Agent received command: run
2024-05-19 08:47:33 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 08:47:33 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 08:47:38 INFO Running runs: ['sd90vdzl']
2024-05-19 08:50:38 INFO Cleaning up finished run: sd90vdzl
2024-05-19 08:50:39 INFO Agent received command: run
2024-05-19 08:50:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 08:50:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 08:50:44 INFO Running runs: ['lih13tjp']
2024-05-19 08:53:44 INFO Cleaning up finished run: lih13tjp
2024-05-19 08:53:45 INFO Agent received command: run
2024-05-19 08:53:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 08:53:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 08:53:50 INFO Running runs: ['in8jnt8m']
2024-05-19 08:55:30 INFO Cleaning up finished run: in8jnt8m
2024-05-19 08:55:31 INFO Agent received command: run
2024-05-19 08:55:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 08:55:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 08:55:36 INFO Running runs: ['cn423jhc']
2024-05-19 08:57:54 INFO Cleaning up finished run: cn423jhc
2024-05-19 08:57:57 INFO Agent received command: run
2024-05-19 08:57:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 08:57:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 08:58:02 INFO Running runs: ['etz4kbn5']
2024-05-19 09:00:25 INFO Cleaning up finished run: etz4kbn5
2024-05-19 09:00:26 INFO Agent received command: run
2024-05-19 09:00:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: random
2024-05-19 09:00:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=random
2024-05-19 09:00:31 INFO Running runs: ['itfnoan6']
2024-05-19 09:03:15 INFO Cleaning up finished run: itfnoan6
2024-05-19 09:03:32 INFO Agent received command: run
2024-05-19 09:03:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 09:03:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 09:03:37 INFO Running runs: ['19l5lxv5']
2024-05-19 09:06:00 INFO Cleaning up finished run: 19l5lxv5
2024-05-19 09:06:01 INFO Agent received command: run
2024-05-19 09:06:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 09:06:01 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 09:06:06 INFO Running runs: ['xb5p2b66']
2024-05-19 09:07:52 INFO Cleaning up finished run: xb5p2b66
2024-05-19 09:07:53 INFO Agent received command: run
2024-05-19 09:07:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:07:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:07:58 INFO Running runs: ['ir89pci9']
2024-05-19 09:10:05 INFO Cleaning up finished run: ir89pci9
2024-05-19 09:10:10 INFO Agent received command: run
2024-05-19 09:10:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:10:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:10:15 INFO Running runs: ['vnrh803q']
2024-05-19 09:11:50 INFO Cleaning up finished run: vnrh803q
2024-05-19 09:11:51 INFO Agent received command: run
2024-05-19 09:11:51 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:11:51 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:11:56 INFO Running runs: ['6vh1frju']
2024-05-19 09:13:10 INFO Cleaning up finished run: 6vh1frju
2024-05-19 09:13:11 INFO Agent received command: run
2024-05-19 09:13:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:13:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:13:16 INFO Running runs: ['3g1z5hua']
2024-05-19 09:15:02 INFO Cleaning up finished run: 3g1z5hua
2024-05-19 09:15:03 INFO Agent received command: run
2024-05-19 09:15:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:15:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:15:08 INFO Running runs: ['fjmq0u0n']
2024-05-19 09:17:10 INFO Cleaning up finished run: fjmq0u0n
2024-05-19 09:17:11 INFO Agent received command: run
2024-05-19 09:17:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:17:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:17:16 INFO Running runs: ['i3z962v2']
2024-05-19 09:20:05 INFO Cleaning up finished run: i3z962v2
2024-05-19 09:20:06 INFO Agent received command: run
2024-05-19 09:20:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:20:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:20:11 INFO Running runs: ['9h3dcb1c']
2024-05-19 09:22:19 INFO Cleaning up finished run: 9h3dcb1c
2024-05-19 09:22:20 INFO Agent received command: run
2024-05-19 09:22:20 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:22:20 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:22:25 INFO Running runs: ['z1n8w78q']
2024-05-19 09:23:55 INFO Cleaning up finished run: z1n8w78q
2024-05-19 09:23:56 INFO Agent received command: run
2024-05-19 09:23:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 09:23:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 09:24:01 INFO Running runs: ['fzzpcahk']
2024-05-19 09:26:46 INFO Cleaning up finished run: fzzpcahk
2024-05-19 09:26:47 INFO Agent received command: run
2024-05-19 09:26:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:26:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:26:52 INFO Running runs: ['tbhwvd4t']
2024-05-19 09:28:54 INFO Cleaning up finished run: tbhwvd4t
2024-05-19 09:28:54 INFO Agent received command: run
2024-05-19 09:28:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:28:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:28:59 INFO Running runs: ['34yefzit']
2024-05-19 09:30:45 INFO Cleaning up finished run: 34yefzit
2024-05-19 09:30:46 INFO Agent received command: run
2024-05-19 09:30:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 09:30:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 09:30:51 INFO Running runs: ['c0lwopzf']
2024-05-19 09:32:53 INFO Cleaning up finished run: c0lwopzf
2024-05-19 09:32:54 INFO Agent received command: run
2024-05-19 09:32:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 09:32:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 09:32:59 INFO Running runs: ['nxgpwkh8']
2024-05-19 09:35:17 INFO Cleaning up finished run: nxgpwkh8
2024-05-19 09:35:18 INFO Agent received command: run
2024-05-19 09:35:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 09:35:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 09:35:23 INFO Running runs: ['u4awjxe4']
2024-05-19 09:37:51 INFO Cleaning up finished run: u4awjxe4
2024-05-19 09:37:53 INFO Agent received command: run
2024-05-19 09:37:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 09:37:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 09:37:58 INFO Running runs: ['f4o0pwyq']
2024-05-19 09:39:44 INFO Cleaning up finished run: f4o0pwyq
2024-05-19 09:39:45 INFO Agent received command: run
2024-05-19 09:39:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 09:39:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 09:39:50 INFO Running runs: ['e5o65xyx']
2024-05-19 09:41:42 INFO Cleaning up finished run: e5o65xyx
2024-05-19 09:41:43 INFO Agent received command: run
2024-05-19 09:41:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:41:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:41:48 INFO Running runs: ['003e4qu0']
2024-05-19 09:43:39 INFO Cleaning up finished run: 003e4qu0
2024-05-19 09:43:40 INFO Agent received command: run
2024-05-19 09:43:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:43:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:43:45 INFO Running runs: ['elnfsrh9']
2024-05-19 09:45:21 INFO Cleaning up finished run: elnfsrh9
2024-05-19 09:45:21 INFO Agent received command: run
2024-05-19 09:45:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:45:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:45:26 INFO Running runs: ['s45x04gu']
2024-05-19 09:48:01 INFO Cleaning up finished run: s45x04gu
2024-05-19 09:48:03 INFO Agent received command: run
2024-05-19 09:48:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:48:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:48:08 INFO Running runs: ['1au39s9b']
2024-05-19 09:50:37 INFO Cleaning up finished run: 1au39s9b
2024-05-19 09:50:38 INFO Agent received command: run
2024-05-19 09:50:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:50:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:50:43 INFO Running runs: ['cqz5a28s']
2024-05-19 09:52:50 INFO Cleaning up finished run: cqz5a28s
2024-05-19 09:52:53 INFO Agent received command: run
2024-05-19 09:52:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 09:52:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 09:52:58 INFO Running runs: ['838h3hoh']
2024-05-19 09:53:56 INFO Cleaning up finished run: 838h3hoh
2024-05-19 09:53:57 INFO Agent received command: run
2024-05-19 09:53:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:53:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:54:02 INFO Running runs: ['ts877cji']
2024-05-19 09:56:04 INFO Cleaning up finished run: ts877cji
2024-05-19 09:56:05 INFO Agent received command: run
2024-05-19 09:56:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:56:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:56:10 INFO Running runs: ['qjkdf086']
2024-05-19 09:58:17 INFO Cleaning up finished run: qjkdf086
2024-05-19 09:58:18 INFO Agent received command: run
2024-05-19 09:58:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 09:58:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 09:58:23 INFO Running runs: ['vu2w9ozt']
2024-05-19 10:00:36 INFO Cleaning up finished run: vu2w9ozt
2024-05-19 10:00:37 INFO Agent received command: run
2024-05-19 10:00:37 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:00:37 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:00:42 INFO Running runs: ['inxg28m2']
2024-05-19 10:02:38 INFO Cleaning up finished run: inxg28m2
2024-05-19 10:02:40 INFO Agent received command: run
2024-05-19 10:02:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 10:02:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 10:02:45 INFO Running runs: ['wa4vq5pc']
2024-05-19 10:04:52 INFO Cleaning up finished run: wa4vq5pc
2024-05-19 10:04:53 INFO Agent received command: run
2024-05-19 10:04:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 10:04:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 10:04:58 INFO Running runs: ['0p5pbmq5']
2024-05-19 10:07:16 INFO Cleaning up finished run: 0p5pbmq5
2024-05-19 10:07:17 INFO Agent received command: run
2024-05-19 10:07:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:07:17 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:07:22 INFO Running runs: ['fn170mry']
2024-05-19 10:09:25 INFO Cleaning up finished run: fn170mry
2024-05-19 10:09:25 INFO Agent received command: run
2024-05-19 10:09:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: random
2024-05-19 10:09:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=random
2024-05-19 10:09:30 INFO Running runs: ['1f0qlyee']
2024-05-19 10:12:10 INFO Cleaning up finished run: 1f0qlyee
2024-05-19 10:12:11 INFO Agent received command: run
2024-05-19 10:12:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:12:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:12:16 INFO Running runs: ['ycq5tp27']
2024-05-19 10:14:55 INFO Cleaning up finished run: ycq5tp27
2024-05-19 10:14:56 INFO Agent received command: run
2024-05-19 10:14:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 10:14:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 10:15:01 INFO Running runs: ['j3kpcz1w']
2024-05-19 10:16:58 INFO Cleaning up finished run: j3kpcz1w
2024-05-19 10:16:59 INFO Agent received command: run
2024-05-19 10:16:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:16:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:17:04 INFO Running runs: ['ki4yzw1p']
2024-05-19 10:18:39 INFO Cleaning up finished run: ki4yzw1p
2024-05-19 10:18:40 INFO Agent received command: run
2024-05-19 10:18:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 10:18:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 10:18:45 INFO Running runs: ['ne1bgs5h']
2024-05-19 10:21:45 INFO Cleaning up finished run: ne1bgs5h
2024-05-19 10:21:48 INFO Agent received command: run
2024-05-19 10:21:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:21:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:21:53 INFO Running runs: ['c42nuiw0']
2024-05-19 10:24:38 INFO Cleaning up finished run: c42nuiw0
2024-05-19 10:24:39 INFO Agent received command: run
2024-05-19 10:24:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 10:24:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 10:24:44 INFO Running runs: ['j7z6rbwu']
2024-05-19 10:27:34 INFO Cleaning up finished run: j7z6rbwu
2024-05-19 10:27:35 INFO Agent received command: run
2024-05-19 10:27:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:27:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:27:40 INFO Running runs: ['2ka5pql3']
2024-05-19 10:29:10 INFO Cleaning up finished run: 2ka5pql3
2024-05-19 10:29:11 INFO Agent received command: run
2024-05-19 10:29:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 10:29:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 10:29:16 INFO Running runs: ['7q0ficul']
2024-05-19 10:31:02 INFO Cleaning up finished run: 7q0ficul
2024-05-19 10:31:03 INFO Agent received command: run
2024-05-19 10:31:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:31:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:31:08 INFO Running runs: ['twha99yr']
2024-05-19 10:33:48 INFO Cleaning up finished run: twha99yr
2024-05-19 10:33:49 INFO Agent received command: run
2024-05-19 10:33:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 10:33:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 10:33:54 INFO Running runs: ['gnw2wqju']
2024-05-19 10:35:13 INFO Cleaning up finished run: gnw2wqju
2024-05-19 10:35:14 INFO Agent received command: run
2024-05-19 10:35:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:35:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:35:19 INFO Running runs: ['q3wk8t4f']
2024-05-19 10:37:21 INFO Cleaning up finished run: q3wk8t4f
2024-05-19 10:37:22 INFO Agent received command: run
2024-05-19 10:37:22 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:37:22 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:37:27 INFO Running runs: ['8c2thnth']
2024-05-19 10:39:34 INFO Cleaning up finished run: 8c2thnth
2024-05-19 10:39:35 INFO Agent received command: run
2024-05-19 10:39:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:39:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:39:40 INFO Running runs: ['20de9k6h']
2024-05-19 10:40:59 INFO Cleaning up finished run: 20de9k6h
2024-05-19 10:41:00 INFO Agent received command: run
2024-05-19 10:41:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:41:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:41:05 INFO Running runs: ['2pmfrw1m']
2024-05-19 10:43:13 INFO Cleaning up finished run: 2pmfrw1m
2024-05-19 10:43:13 INFO Agent received command: run
2024-05-19 10:43:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:43:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:43:18 INFO Running runs: ['6mjvaecb']
2024-05-19 10:45:05 INFO Cleaning up finished run: 6mjvaecb
2024-05-19 10:45:06 INFO Agent received command: run
2024-05-19 10:45:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:45:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:45:11 INFO Running runs: ['tme1i5b0']
2024-05-19 10:47:34 INFO Cleaning up finished run: tme1i5b0
2024-05-19 10:47:35 INFO Agent received command: run
2024-05-19 10:47:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 10:47:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 10:47:40 INFO Running runs: ['8tewcm09']
2024-05-19 10:49:53 INFO Cleaning up finished run: 8tewcm09
2024-05-19 10:49:54 INFO Agent received command: run
2024-05-19 10:49:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 10:49:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 10:49:59 INFO Running runs: ['d2dzky33']
2024-05-19 10:52:17 INFO Cleaning up finished run: d2dzky33
2024-05-19 10:52:18 INFO Agent received command: run
2024-05-19 10:52:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:52:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:52:23 INFO Running runs: ['ou8beluw']
2024-05-19 10:54:58 INFO Cleaning up finished run: ou8beluw
2024-05-19 10:54:59 INFO Agent received command: run
2024-05-19 10:54:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 10:54:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 10:55:04 INFO Running runs: ['i12wl1ir']
2024-05-19 10:56:50 INFO Cleaning up finished run: i12wl1ir
2024-05-19 10:56:51 INFO Agent received command: run
2024-05-19 10:56:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 10:56:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 10:56:56 INFO Running runs: ['ghn9pohp']
2024-05-19 10:59:03 INFO Cleaning up finished run: ghn9pohp
2024-05-19 10:59:09 INFO Agent received command: run
2024-05-19 10:59:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 10:59:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 10:59:14 INFO Running runs: ['ymgud85o']
2024-05-19 11:00:39 INFO Cleaning up finished run: ymgud85o
2024-05-19 11:00:40 INFO Agent received command: run
2024-05-19 11:00:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 11:00:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 11:00:45 INFO Running runs: ['5p3b0mro']
2024-05-19 11:03:03 INFO Cleaning up finished run: 5p3b0mro
2024-05-19 11:03:05 INFO Agent received command: run
2024-05-19 11:03:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:03:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:03:10 INFO Running runs: ['3yjx230h']
2024-05-19 11:04:24 INFO Cleaning up finished run: 3yjx230h
2024-05-19 11:04:34 INFO Agent received command: run
2024-05-19 11:04:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 11:04:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 11:04:39 INFO Running runs: ['eirx228q']
2024-05-19 11:05:59 INFO Cleaning up finished run: eirx228q
2024-05-19 11:06:00 INFO Agent received command: run
2024-05-19 11:06:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 11:06:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 11:06:05 INFO Running runs: ['28baqmih']
2024-05-19 11:07:35 INFO Cleaning up finished run: 28baqmih
2024-05-19 11:07:46 INFO Agent received command: run
2024-05-19 11:07:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:07:46 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:07:51 INFO Running runs: ['nvo6mi9n']
2024-05-19 11:09:42 INFO Cleaning up finished run: nvo6mi9n
2024-05-19 11:09:43 INFO Agent received command: run
2024-05-19 11:09:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:09:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:09:48 INFO Running runs: ['yjsh52r2']
2024-05-19 11:12:07 INFO Cleaning up finished run: yjsh52r2
2024-05-19 11:12:07 INFO Agent received command: run
2024-05-19 11:12:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 11:12:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 11:12:12 INFO Running runs: ['bl44m2ed']
2024-05-19 11:13:53 INFO Cleaning up finished run: bl44m2ed
2024-05-19 11:13:54 INFO Agent received command: run
2024-05-19 11:13:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:13:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:13:59 INFO Running runs: ['8cnibb2p']
2024-05-19 11:14:57 INFO Cleaning up finished run: 8cnibb2p
2024-05-19 11:14:58 INFO Agent received command: run
2024-05-19 11:14:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:14:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:15:03 INFO Running runs: ['f2b0wgn0']
2024-05-19 11:17:32 INFO Cleaning up finished run: f2b0wgn0
2024-05-19 11:17:33 INFO Agent received command: run
2024-05-19 11:17:33 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 11:17:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 11:17:38 INFO Running runs: ['ontp0p5u']
2024-05-19 11:19:03 INFO Cleaning up finished run: ontp0p5u
2024-05-19 11:19:04 INFO Agent received command: run
2024-05-19 11:19:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 11:19:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 11:19:09 INFO Running runs: ['pf8o83et']
2024-05-19 11:20:39 INFO Cleaning up finished run: pf8o83et
2024-05-19 11:20:40 INFO Agent received command: run
2024-05-19 11:20:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:20:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:20:45 INFO Running runs: ['nt9p5rau']
2024-05-19 11:23:09 INFO Cleaning up finished run: nt9p5rau
2024-05-19 11:23:10 INFO Agent received command: run
2024-05-19 11:23:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:23:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:23:15 INFO Running runs: ['jv0wlnuw']
2024-05-19 11:24:24 INFO Cleaning up finished run: jv0wlnuw
2024-05-19 11:24:25 INFO Agent received command: run
2024-05-19 11:24:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 11:24:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 11:24:30 INFO Running runs: ['bom9zswt']
2024-05-19 11:25:44 INFO Cleaning up finished run: bom9zswt
2024-05-19 11:25:45 INFO Agent received command: run
2024-05-19 11:25:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 11:25:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 11:25:50 INFO Running runs: ['t0zk7fkz']
2024-05-19 11:27:47 INFO Cleaning up finished run: t0zk7fkz
2024-05-19 11:27:48 INFO Agent received command: run
2024-05-19 11:27:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:27:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:27:53 INFO Running runs: ['xkwjz8fy']
2024-05-19 11:30:12 INFO Cleaning up finished run: xkwjz8fy
2024-05-19 11:30:13 INFO Agent received command: run
2024-05-19 11:30:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 11:30:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 11:30:18 INFO Running runs: ['g3vsuw8c']
2024-05-19 11:32:04 INFO Cleaning up finished run: g3vsuw8c
2024-05-19 11:32:27 INFO Agent received command: run
2024-05-19 11:32:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:32:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:32:32 INFO Running runs: ['qaqabq9v']
2024-05-19 11:34:13 INFO Cleaning up finished run: qaqabq9v
2024-05-19 11:34:14 INFO Agent received command: run
2024-05-19 11:34:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:34:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:34:19 INFO Running runs: ['cdyg01d1']
2024-05-19 11:35:34 INFO Cleaning up finished run: cdyg01d1
2024-05-19 11:35:35 INFO Agent received command: run
2024-05-19 11:35:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:35:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:35:40 INFO Running runs: ['t4dpkhw0']
2024-05-19 11:36:49 INFO Cleaning up finished run: t4dpkhw0
2024-05-19 11:36:51 INFO Agent received command: run
2024-05-19 11:36:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:36:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:36:56 INFO Running runs: ['4efx9krs']
2024-05-19 11:39:30 INFO Cleaning up finished run: 4efx9krs
2024-05-19 11:39:31 INFO Agent received command: run
2024-05-19 11:39:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 11:39:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 11:39:36 INFO Running runs: ['m0qr2cld']
2024-05-19 11:41:59 INFO Cleaning up finished run: m0qr2cld
2024-05-19 11:42:00 INFO Agent received command: run
2024-05-19 11:42:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 11:42:00 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 11:42:05 INFO Running runs: ['c3ao8shc']
2024-05-19 11:43:30 INFO Cleaning up finished run: c3ao8shc
2024-05-19 11:43:32 INFO Agent received command: run
2024-05-19 11:43:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 11:43:32 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 11:43:37 INFO Running runs: ['ijb2aprv']
2024-05-19 11:45:29 INFO Cleaning up finished run: ijb2aprv
2024-05-19 11:45:30 INFO Agent received command: run
2024-05-19 11:45:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 11:45:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 11:45:35 INFO Running runs: ['8g5t5fz9']
2024-05-19 11:46:54 INFO Cleaning up finished run: 8g5t5fz9
2024-05-19 11:46:55 INFO Agent received command: run
2024-05-19 11:46:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 11:46:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 11:47:00 INFO Running runs: ['0f79eqky']
2024-05-19 11:49:08 INFO Cleaning up finished run: 0f79eqky
2024-05-19 11:49:28 INFO Agent received command: run
2024-05-19 11:49:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:49:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:49:33 INFO Running runs: ['w0bynd1x']
2024-05-19 11:50:27 INFO Cleaning up finished run: w0bynd1x
2024-05-19 11:50:27 INFO Agent received command: run
2024-05-19 11:50:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 11:50:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 11:50:32 INFO Running runs: ['a8ec3xwn']
2024-05-19 11:51:58 INFO Cleaning up finished run: a8ec3xwn
2024-05-19 11:51:59 INFO Agent received command: run
2024-05-19 11:51:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 11:51:59 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 11:52:04 INFO Running runs: ['gtnt0ayf']
2024-05-19 11:53:34 INFO Cleaning up finished run: gtnt0ayf
2024-05-19 11:53:35 INFO Agent received command: run
2024-05-19 11:53:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 11:53:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 11:53:40 INFO Running runs: ['xev2crci']
2024-05-19 11:55:26 INFO Cleaning up finished run: xev2crci
2024-05-19 11:55:27 INFO Agent received command: run
2024-05-19 11:55:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 11:55:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 11:55:32 INFO Running runs: ['hwmsoywr']
2024-05-19 11:56:47 INFO Cleaning up finished run: hwmsoywr
2024-05-19 11:56:48 INFO Agent received command: run
2024-05-19 11:56:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:56:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:56:53 INFO Running runs: ['h77p5xej']
2024-05-19 11:58:07 INFO Cleaning up finished run: h77p5xej
2024-05-19 11:58:08 INFO Agent received command: run
2024-05-19 11:58:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 11:58:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 11:58:13 INFO Running runs: ['2qwg93ul']
2024-05-19 11:59:49 INFO Cleaning up finished run: 2qwg93ul
2024-05-19 11:59:50 INFO Agent received command: run
2024-05-19 11:59:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 11:59:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 11:59:55 INFO Running runs: ['qkeek1t0']
2024-05-19 12:03:59 INFO Cleaning up finished run: qkeek1t0
2024-05-19 12:04:00 INFO Agent received command: run
2024-05-19 12:04:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 12:04:00 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 12:04:05 INFO Running runs: ['ee2l4b83']
2024-05-19 12:06:45 INFO Cleaning up finished run: ee2l4b83
2024-05-19 12:06:46 INFO Agent received command: run
2024-05-19 12:06:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 12:06:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 12:06:51 INFO Running runs: ['8nr6kpoi']
2024-05-19 12:08:26 INFO Cleaning up finished run: 8nr6kpoi
2024-05-19 12:08:27 INFO Agent received command: run
2024-05-19 12:08:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:08:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:08:32 INFO Running runs: ['f8ttq6gd']
2024-05-19 12:10:18 INFO Cleaning up finished run: f8ttq6gd
2024-05-19 12:10:19 INFO Agent received command: run
2024-05-19 12:10:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-19 12:10:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-19 12:10:24 INFO Running runs: ['n946t4zy']
2024-05-19 12:12:11 INFO Cleaning up finished run: n946t4zy
2024-05-19 12:12:12 INFO Agent received command: run
2024-05-19 12:12:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:12:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:12:17 INFO Running runs: ['sjapd0au']
2024-05-19 12:13:31 INFO Cleaning up finished run: sjapd0au
2024-05-19 12:13:32 INFO Agent received command: run
2024-05-19 12:13:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:13:32 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:13:37 INFO Running runs: ['ge24e941']
2024-05-19 12:14:52 INFO Cleaning up finished run: ge24e941
2024-05-19 12:14:53 INFO Agent received command: run
2024-05-19 12:14:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 12:14:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 12:14:58 INFO Running runs: ['sxvp350l']
2024-05-19 12:16:01 INFO Cleaning up finished run: sxvp350l
2024-05-19 12:16:03 INFO Agent received command: run
2024-05-19 12:16:03 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 12:16:03 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 12:16:08 INFO Running runs: ['f11dqagh']
2024-05-19 12:17:49 INFO Cleaning up finished run: f11dqagh
2024-05-19 12:17:50 INFO Agent received command: run
2024-05-19 12:17:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 12:17:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 12:17:55 INFO Running runs: ['vnglv5ab']
2024-05-19 12:19:42 INFO Cleaning up finished run: vnglv5ab
2024-05-19 12:19:43 INFO Agent received command: run
2024-05-19 12:19:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 12:19:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 12:19:48 INFO Running runs: ['5qv00tn7']
2024-05-19 12:21:18 INFO Cleaning up finished run: 5qv00tn7
2024-05-19 12:21:19 INFO Agent received command: run
2024-05-19 12:21:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:21:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:21:24 INFO Running runs: ['z3p1890q']
2024-05-19 12:24:04 INFO Cleaning up finished run: z3p1890q
2024-05-19 12:24:04 INFO Agent received command: run
2024-05-19 12:24:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 12:24:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 12:24:10 INFO Running runs: ['w45rrkqk']
2024-05-19 12:28:10 INFO Cleaning up finished run: w45rrkqk
2024-05-19 12:28:11 INFO Agent received command: run
2024-05-19 12:28:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:28:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:28:16 INFO Running runs: ['pzmhku82']
2024-05-19 12:29:36 INFO Cleaning up finished run: pzmhku82
2024-05-19 12:29:36 INFO Agent received command: run
2024-05-19 12:29:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 12:29:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 12:29:41 INFO Running runs: ['dxyc8473']
2024-05-19 12:30:45 INFO Cleaning up finished run: dxyc8473
2024-05-19 12:30:54 INFO Agent received command: run
2024-05-19 12:30:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 12:30:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 12:30:59 INFO Running runs: ['8kusp5gk']
2024-05-19 12:32:56 INFO Cleaning up finished run: 8kusp5gk
2024-05-19 12:32:57 INFO Agent received command: run
2024-05-19 12:32:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:32:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:33:02 INFO Running runs: ['830bafnf']
2024-05-19 12:34:17 INFO Cleaning up finished run: 830bafnf
2024-05-19 12:34:18 INFO Agent received command: run
2024-05-19 12:34:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 12:34:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 12:34:23 INFO Running runs: ['pedprwai']
2024-05-19 12:35:32 INFO Cleaning up finished run: pedprwai
2024-05-19 12:35:34 INFO Agent received command: run
2024-05-19 12:35:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 12:35:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 12:35:39 INFO Running runs: ['avurgby5']
2024-05-19 12:38:23 INFO Cleaning up finished run: avurgby5
2024-05-19 12:38:24 INFO Agent received command: run
2024-05-19 12:38:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:38:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:38:29 INFO Running runs: ['dkownl2s']
2024-05-19 12:40:00 INFO Cleaning up finished run: dkownl2s
2024-05-19 12:40:01 INFO Agent received command: run
2024-05-19 12:40:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:40:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:40:06 INFO Running runs: ['8nfacatc']
2024-05-19 12:42:03 INFO Cleaning up finished run: 8nfacatc
2024-05-19 12:42:03 INFO Agent received command: run
2024-05-19 12:42:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: random
2024-05-19 12:42:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=random
2024-05-19 12:42:08 INFO Running runs: ['jlokypq5']
2024-05-19 12:43:44 INFO Cleaning up finished run: jlokypq5
2024-05-19 12:43:45 INFO Agent received command: run
2024-05-19 12:43:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 12:43:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 12:43:50 INFO Running runs: ['1leoy33f']
2024-05-19 12:45:09 INFO Cleaning up finished run: 1leoy33f
2024-05-19 12:45:10 INFO Agent received command: run
2024-05-19 12:45:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 12:45:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 12:45:15 INFO Running runs: ['ouqjcc8g']
2024-05-19 12:48:10 INFO Cleaning up finished run: ouqjcc8g
2024-05-19 12:48:11 INFO Agent received command: run
2024-05-19 12:48:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 12:48:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 12:48:16 INFO Running runs: ['wh3w7p6c']
2024-05-19 12:50:18 INFO Cleaning up finished run: wh3w7p6c
2024-05-19 12:50:27 INFO Agent received command: run
2024-05-19 12:50:27 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:50:27 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:50:32 INFO Running runs: ['6rok71z5']
2024-05-19 12:51:41 INFO Cleaning up finished run: 6rok71z5
2024-05-19 12:51:42 INFO Agent received command: run
2024-05-19 12:51:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:51:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:51:47 INFO Running runs: ['z1ctpaaf']
2024-05-19 12:53:38 INFO Cleaning up finished run: z1ctpaaf
2024-05-19 12:53:39 INFO Agent received command: run
2024-05-19 12:53:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 12:53:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 12:53:44 INFO Running runs: ['fq2yzrd1']
2024-05-19 12:55:40 INFO Cleaning up finished run: fq2yzrd1
2024-05-19 12:55:41 INFO Agent received command: run
2024-05-19 12:55:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 12:55:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 12:55:46 INFO Running runs: ['62g6efzj']
2024-05-19 12:57:00 INFO Cleaning up finished run: 62g6efzj
2024-05-19 12:57:01 INFO Agent received command: run
2024-05-19 12:57:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 12:57:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 12:57:06 INFO Running runs: ['us0gmrvh']
2024-05-19 12:59:13 INFO Cleaning up finished run: us0gmrvh
2024-05-19 12:59:14 INFO Agent received command: run
2024-05-19 12:59:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 12:59:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 12:59:19 INFO Running runs: ['lvjf5bpk']
2024-05-19 13:02:19 INFO Cleaning up finished run: lvjf5bpk
2024-05-19 13:02:20 INFO Agent received command: run
2024-05-19 13:02:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:02:20 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:02:25 INFO Running runs: ['12snxu7m']
2024-05-19 13:04:06 INFO Cleaning up finished run: 12snxu7m
2024-05-19 13:04:07 INFO Agent received command: run
2024-05-19 13:04:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 13:04:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 13:04:12 INFO Running runs: ['rysv01hq']
2024-05-19 13:06:03 INFO Cleaning up finished run: rysv01hq
2024-05-19 13:06:04 INFO Agent received command: run
2024-05-19 13:06:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 13:06:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 13:06:09 INFO Running runs: ['7884q0je']
2024-05-19 13:08:59 INFO Cleaning up finished run: 7884q0je
2024-05-19 13:09:00 INFO Agent received command: run
2024-05-19 13:09:00 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 13:09:00 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 13:09:05 INFO Running runs: ['okq12ulw']
2024-05-19 13:10:56 INFO Cleaning up finished run: okq12ulw
2024-05-19 13:10:57 INFO Agent received command: run
2024-05-19 13:10:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 13:10:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 13:11:02 INFO Running runs: ['m3eats6h']
2024-05-19 13:12:54 INFO Cleaning up finished run: m3eats6h
2024-05-19 13:13:05 INFO Agent received command: run
2024-05-19 13:13:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 13:13:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 13:13:10 INFO Running runs: ['2zvt27bm']
2024-05-19 13:15:01 INFO Cleaning up finished run: 2zvt27bm
2024-05-19 13:15:24 INFO Agent received command: run
2024-05-19 13:15:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:15:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:15:29 INFO Running runs: ['x6zuzknz']
2024-05-19 13:18:19 INFO Cleaning up finished run: x6zuzknz
2024-05-19 13:18:20 INFO Agent received command: run
2024-05-19 13:18:20 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 13:18:20 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 13:18:25 INFO Running runs: ['t24pg6zp']
2024-05-19 13:20:10 INFO Cleaning up finished run: t24pg6zp
2024-05-19 13:20:11 INFO Agent received command: run
2024-05-19 13:20:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 13:20:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 13:20:16 INFO Running runs: ['77kev4sl']
2024-05-19 13:21:36 INFO Cleaning up finished run: 77kev4sl
2024-05-19 13:21:36 INFO Agent received command: run
2024-05-19 13:21:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:21:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:21:41 INFO Running runs: ['yvcg5mcz']
2024-05-19 13:23:38 INFO Cleaning up finished run: yvcg5mcz
2024-05-19 13:23:41 INFO Agent received command: run
2024-05-19 13:23:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 13:23:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 13:23:46 INFO Running runs: ['d9x164cs']
2024-05-19 13:25:32 INFO Cleaning up finished run: d9x164cs
2024-05-19 13:25:46 INFO Agent received command: run
2024-05-19 13:25:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 13:25:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 13:25:51 INFO Running runs: ['uv9ugde2']
2024-05-19 13:27:00 INFO Cleaning up finished run: uv9ugde2
2024-05-19 13:27:10 INFO Agent received command: run
2024-05-19 13:27:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:27:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:27:15 INFO Running runs: ['qwh7d5lg']
2024-05-19 13:28:24 INFO Cleaning up finished run: qwh7d5lg
2024-05-19 13:28:25 INFO Agent received command: run
2024-05-19 13:28:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:28:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:28:30 INFO Running runs: ['n4pzmov6']
2024-05-19 13:30:58 INFO Cleaning up finished run: n4pzmov6
2024-05-19 13:30:59 INFO Agent received command: run
2024-05-19 13:30:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:30:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:31:04 INFO Running runs: ['h6q9w13y']
2024-05-19 13:32:39 INFO Cleaning up finished run: h6q9w13y
2024-05-19 13:32:42 INFO Agent received command: run
2024-05-19 13:32:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 13:32:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 13:32:47 INFO Running runs: ['8z2vlc0r']
2024-05-19 13:34:44 INFO Cleaning up finished run: 8z2vlc0r
2024-05-19 13:34:45 INFO Agent received command: run
2024-05-19 13:34:45 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 13:34:45 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 13:34:50 INFO Running runs: ['sjkuotvn']
2024-05-19 13:36:54 INFO Cleaning up finished run: sjkuotvn
2024-05-19 13:36:54 INFO Agent received command: run
2024-05-19 13:36:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:36:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:36:59 INFO Running runs: ['ga0cjpgl']
2024-05-19 13:37:58 INFO Cleaning up finished run: ga0cjpgl
2024-05-19 13:37:59 INFO Agent received command: run
2024-05-19 13:37:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:37:59 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:38:04 INFO Running runs: ['159a8aqd']
2024-05-19 13:39:33 INFO Cleaning up finished run: 159a8aqd
2024-05-19 13:39:34 INFO Agent received command: run
2024-05-19 13:39:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 13:39:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 13:39:39 INFO Running runs: ['s23crt68']
2024-05-19 13:41:46 INFO Cleaning up finished run: s23crt68
2024-05-19 13:42:04 INFO Agent received command: run
2024-05-19 13:42:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:42:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:42:09 INFO Running runs: ['ev1v3m83']
2024-05-19 13:43:18 INFO Cleaning up finished run: ev1v3m83
2024-05-19 13:43:19 INFO Agent received command: run
2024-05-19 13:43:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:43:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:43:24 INFO Running runs: ['j6ia8kck']
2024-05-19 13:44:32 INFO Cleaning up finished run: j6ia8kck
2024-05-19 13:44:34 INFO Agent received command: run
2024-05-19 13:44:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 13:44:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 13:44:39 INFO Running runs: ['zz2ydvxs']
2024-05-19 13:46:25 INFO Cleaning up finished run: zz2ydvxs
2024-05-19 13:46:26 INFO Agent received command: run
2024-05-19 13:46:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 13:46:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 13:46:31 INFO Running runs: ['z5oiu9sj']
2024-05-19 13:47:45 INFO Cleaning up finished run: z5oiu9sj
2024-05-19 13:47:46 INFO Agent received command: run
2024-05-19 13:47:46 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:47:46 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:47:51 INFO Running runs: ['vx37qqn5']
2024-05-19 13:49:42 INFO Cleaning up finished run: vx37qqn5
2024-05-19 13:49:43 INFO Agent received command: run
2024-05-19 13:49:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 13:49:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 13:49:48 INFO Running runs: ['ozuxloag']
2024-05-19 13:51:28 INFO Cleaning up finished run: ozuxloag
2024-05-19 13:51:29 INFO Agent received command: run
2024-05-19 13:51:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 13:51:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 13:51:34 INFO Running runs: ['tqk3p40r']
2024-05-19 13:54:08 INFO Cleaning up finished run: tqk3p40r
2024-05-19 13:54:09 INFO Agent received command: run
2024-05-19 13:54:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 13:54:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 13:54:14 INFO Running runs: ['izu105bc']
2024-05-19 13:55:54 INFO Cleaning up finished run: izu105bc
2024-05-19 13:55:55 INFO Agent received command: run
2024-05-19 13:55:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 13:55:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 13:56:00 INFO Running runs: ['iuatj923']
2024-05-19 13:57:46 INFO Cleaning up finished run: iuatj923
2024-05-19 13:57:47 INFO Agent received command: run
2024-05-19 13:57:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 13:57:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 13:57:52 INFO Running runs: ['y79xt025']
2024-05-19 13:59:48 INFO Cleaning up finished run: y79xt025
2024-05-19 13:59:49 INFO Agent received command: run
2024-05-19 13:59:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 13:59:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 13:59:54 INFO Running runs: ['lsgwybxi']
2024-05-19 14:02:28 INFO Cleaning up finished run: lsgwybxi
2024-05-19 14:02:28 INFO Agent received command: run
2024-05-19 14:02:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:02:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:02:33 INFO Running runs: ['xjg6ep1w']
2024-05-19 14:03:47 INFO Cleaning up finished run: xjg6ep1w
2024-05-19 14:03:49 INFO Agent received command: run
2024-05-19 14:03:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 14:03:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 14:03:54 INFO Running runs: ['dbtu9jc2']
2024-05-19 14:05:45 INFO Cleaning up finished run: dbtu9jc2
2024-05-19 14:05:46 INFO Agent received command: run
2024-05-19 14:05:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 14:05:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 14:05:51 INFO Running runs: ['0a5xj6g3']
2024-05-19 14:08:13 INFO Cleaning up finished run: 0a5xj6g3
2024-05-19 14:08:14 INFO Agent received command: run
2024-05-19 14:08:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-19 14:08:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-19 14:08:19 INFO Running runs: ['1nx9rtsx']
2024-05-19 14:09:44 INFO Cleaning up finished run: 1nx9rtsx
2024-05-19 14:09:48 INFO Agent received command: run
2024-05-19 14:09:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:09:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:09:53 INFO Running runs: ['17euw2d5']
2024-05-19 14:11:07 INFO Cleaning up finished run: 17euw2d5
2024-05-19 14:11:08 INFO Agent received command: run
2024-05-19 14:11:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 14:11:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 14:11:13 INFO Running runs: ['12piywj3']
2024-05-19 14:12:54 INFO Cleaning up finished run: 12piywj3
2024-05-19 14:12:55 INFO Agent received command: run
2024-05-19 14:12:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 14:12:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 14:13:00 INFO Running runs: ['4b6hbj7v']
2024-05-19 14:15:23 INFO Cleaning up finished run: 4b6hbj7v
2024-05-19 14:15:23 INFO Agent received command: run
2024-05-19 14:15:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:15:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:15:28 INFO Running runs: ['y2mr2gft']
2024-05-19 14:16:53 INFO Cleaning up finished run: y2mr2gft
2024-05-19 14:16:54 INFO Agent received command: run
2024-05-19 14:16:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 14:16:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 14:16:59 INFO Running runs: ['5nysduwp']
2024-05-19 14:18:18 INFO Cleaning up finished run: 5nysduwp
2024-05-19 14:18:19 INFO Agent received command: run
2024-05-19 14:18:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-19 14:18:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-19 14:18:24 INFO Running runs: ['89526m0h']
2024-05-19 14:20:10 INFO Cleaning up finished run: 89526m0h
2024-05-19 14:20:11 INFO Agent received command: run
2024-05-19 14:20:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 14:20:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 14:20:16 INFO Running runs: ['w81e1ngk']
2024-05-19 14:22:02 INFO Cleaning up finished run: w81e1ngk
2024-05-19 14:22:04 INFO Agent received command: run
2024-05-19 14:22:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:22:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:22:09 INFO Running runs: ['cqisfpz5']
2024-05-19 14:23:44 INFO Cleaning up finished run: cqisfpz5
2024-05-19 14:23:45 INFO Agent received command: run
2024-05-19 14:23:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:23:46 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:23:51 INFO Running runs: ['pbzqfkr0']
2024-05-19 14:26:29 INFO Cleaning up finished run: pbzqfkr0
2024-05-19 14:26:30 INFO Agent received command: run
2024-05-19 14:26:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:26:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:26:35 INFO Running runs: ['g9go6cd8']
2024-05-19 14:28:05 INFO Cleaning up finished run: g9go6cd8
2024-05-19 14:28:06 INFO Agent received command: run
2024-05-19 14:28:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:28:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:28:11 INFO Running runs: ['k77qdxzu']
2024-05-19 14:29:36 INFO Cleaning up finished run: k77qdxzu
2024-05-19 14:29:38 INFO Agent received command: run
2024-05-19 14:29:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 14:29:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 14:29:43 INFO Running runs: ['xo8hp42e']
2024-05-19 14:31:55 INFO Cleaning up finished run: xo8hp42e
2024-05-19 14:31:56 INFO Agent received command: run
2024-05-19 14:31:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 14:31:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 14:32:01 INFO Running runs: ['er934tv9']
2024-05-19 14:34:03 INFO Cleaning up finished run: er934tv9
2024-05-19 14:34:04 INFO Agent received command: run
2024-05-19 14:34:04 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 14:34:04 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 14:34:09 INFO Running runs: ['14n2ia49']
2024-05-19 14:36:16 INFO Cleaning up finished run: 14n2ia49
2024-05-19 14:36:17 INFO Agent received command: run
2024-05-19 14:36:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 14:36:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 14:36:22 INFO Running runs: ['tyfyo1m5']
2024-05-19 14:38:24 INFO Cleaning up finished run: tyfyo1m5
2024-05-19 14:38:25 INFO Agent received command: run
2024-05-19 14:38:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:38:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:38:30 INFO Running runs: ['1v7ho1om']
2024-05-19 14:39:54 INFO Cleaning up finished run: 1v7ho1om
2024-05-19 14:39:55 INFO Agent received command: run
2024-05-19 14:39:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:39:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:40:00 INFO Running runs: ['j41bior4']
2024-05-19 14:42:23 INFO Cleaning up finished run: j41bior4
2024-05-19 14:42:24 INFO Agent received command: run
2024-05-19 14:42:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:42:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:42:29 INFO Running runs: ['i8qnj4y3']
2024-05-19 14:44:36 INFO Cleaning up finished run: i8qnj4y3
2024-05-19 14:44:37 INFO Agent received command: run
2024-05-19 14:44:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:44:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:44:42 INFO Running runs: ['bdcqj54m']
2024-05-19 14:46:44 INFO Cleaning up finished run: bdcqj54m
2024-05-19 14:46:45 INFO Agent received command: run
2024-05-19 14:46:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 14:46:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 14:46:50 INFO Running runs: ['har8a2e7']
2024-05-19 14:48:25 INFO Cleaning up finished run: har8a2e7
2024-05-19 14:48:26 INFO Agent received command: run
2024-05-19 14:48:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 14:48:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 14:48:31 INFO Running runs: ['atpkmesm']
2024-05-19 14:50:01 INFO Cleaning up finished run: atpkmesm
2024-05-19 14:50:02 INFO Agent received command: run
2024-05-19 14:50:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:50:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:50:07 INFO Running runs: ['ywo68e70']
2024-05-19 14:51:21 INFO Cleaning up finished run: ywo68e70
2024-05-19 14:51:22 INFO Agent received command: run
2024-05-19 14:51:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:51:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:51:27 INFO Running runs: ['90vhc9zc']
2024-05-19 14:53:45 INFO Cleaning up finished run: 90vhc9zc
2024-05-19 14:53:46 INFO Agent received command: run
2024-05-19 14:53:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:53:46 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:53:51 INFO Running runs: ['18u9tygt']
2024-05-19 14:56:30 INFO Cleaning up finished run: 18u9tygt
2024-05-19 14:56:31 INFO Agent received command: run
2024-05-19 14:56:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 14:56:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 14:56:36 INFO Running runs: ['2hmfkwn8']
2024-05-19 14:58:17 INFO Cleaning up finished run: 2hmfkwn8
2024-05-19 14:58:18 INFO Agent received command: run
2024-05-19 14:58:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 14:58:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 14:58:23 INFO Running runs: ['7v2tldlr']
2024-05-19 15:00:08 INFO Cleaning up finished run: 7v2tldlr
2024-05-19 15:00:09 INFO Agent received command: run
2024-05-19 15:00:09 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 15:00:10 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 15:00:15 INFO Running runs: ['fg6dmshe']
2024-05-19 15:02:38 INFO Cleaning up finished run: fg6dmshe
2024-05-19 15:02:38 INFO Agent received command: run
2024-05-19 15:02:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:02:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:02:43 INFO Running runs: ['kkcuvyi5']
2024-05-19 15:04:08 INFO Cleaning up finished run: kkcuvyi5
2024-05-19 15:04:09 INFO Agent received command: run
2024-05-19 15:04:09 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:04:09 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:04:14 INFO Running runs: ['2rpk5m9r']
2024-05-19 15:06:27 INFO Cleaning up finished run: 2rpk5m9r
2024-05-19 15:06:28 INFO Agent received command: run
2024-05-19 15:06:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:06:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:06:33 INFO Running runs: ['wtdjb4x3']
2024-05-19 15:08:29 INFO Cleaning up finished run: wtdjb4x3
2024-05-19 15:08:33 INFO Agent received command: run
2024-05-19 15:08:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 15:08:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 15:08:38 INFO Running runs: ['kalt0vzs']
2024-05-19 15:11:17 INFO Cleaning up finished run: kalt0vzs
2024-05-19 15:11:18 INFO Agent received command: run
2024-05-19 15:11:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 15:11:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 15:11:23 INFO Running runs: ['jq3ue1lo']
2024-05-19 15:13:25 INFO Cleaning up finished run: jq3ue1lo
2024-05-19 15:13:26 INFO Agent received command: run
2024-05-19 15:13:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:13:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:13:31 INFO Running runs: ['udrkyhk8']
2024-05-19 15:15:49 INFO Cleaning up finished run: udrkyhk8
2024-05-19 15:15:49 INFO Agent received command: run
2024-05-19 15:15:49 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-19 15:15:49 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=random
2024-05-19 15:15:54 INFO Running runs: ['8iq5at6s']
2024-05-19 15:17:19 INFO Cleaning up finished run: 8iq5at6s
2024-05-19 15:17:20 INFO Agent received command: run
2024-05-19 15:17:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 15:17:20 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 15:17:25 INFO Running runs: ['j63l0n92']
2024-05-19 15:18:39 INFO Cleaning up finished run: j63l0n92
2024-05-19 15:18:40 INFO Agent received command: run
2024-05-19 15:18:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:18:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:18:45 INFO Running runs: ['fhdb6uu0']
2024-05-19 15:20:15 INFO Cleaning up finished run: fhdb6uu0
2024-05-19 15:20:26 INFO Agent received command: run
2024-05-19 15:20:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:20:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:20:31 INFO Running runs: ['yaeb8kyq']
2024-05-19 15:23:52 INFO Cleaning up finished run: yaeb8kyq
2024-05-19 15:23:53 INFO Agent received command: run
2024-05-19 15:23:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 15:23:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 15:23:58 INFO Running runs: ['df7cphl7']
2024-05-19 15:26:15 INFO Cleaning up finished run: df7cphl7
2024-05-19 15:26:16 INFO Agent received command: run
2024-05-19 15:26:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:26:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:26:21 INFO Running runs: ['to2lnqkm']
2024-05-19 15:29:26 INFO Cleaning up finished run: to2lnqkm
2024-05-19 15:29:31 INFO Agent received command: run
2024-05-19 15:29:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 15:29:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 15:29:36 INFO Running runs: ['vw2yip7h']
2024-05-19 15:31:43 INFO Cleaning up finished run: vw2yip7h
2024-05-19 15:31:44 INFO Agent received command: run
2024-05-19 15:31:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:31:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:31:49 INFO Running runs: ['syq3qo8v']
2024-05-19 15:32:41 INFO Cleaning up finished run: syq3qo8v
2024-05-19 15:32:42 INFO Agent received command: run
2024-05-19 15:32:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:32:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:32:47 INFO Running runs: ['z5u947d8']
2024-05-19 15:34:01 INFO Cleaning up finished run: z5u947d8
2024-05-19 15:34:02 INFO Agent received command: run
2024-05-19 15:34:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:34:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:34:07 INFO Running runs: ['i9vr590e']
2024-05-19 15:35:59 INFO Cleaning up finished run: i9vr590e
2024-05-19 15:35:59 INFO Agent received command: run
2024-05-19 15:35:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:35:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:36:04 INFO Running runs: ['b3kcjn0t']
2024-05-19 15:38:38 INFO Cleaning up finished run: b3kcjn0t
2024-05-19 15:38:39 INFO Agent received command: run
2024-05-19 15:38:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:38:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:38:44 INFO Running runs: ['vrf9fo65']
2024-05-19 15:40:56 INFO Cleaning up finished run: vrf9fo65
2024-05-19 15:40:57 INFO Agent received command: run
2024-05-19 15:40:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 15:40:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 15:41:02 INFO Running runs: ['9dqmpveb']
2024-05-19 15:43:46 INFO Cleaning up finished run: 9dqmpveb
2024-05-19 15:43:47 INFO Agent received command: run
2024-05-19 15:43:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:43:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:43:52 INFO Running runs: ['hq04vyes']
2024-05-19 15:45:59 INFO Cleaning up finished run: hq04vyes
2024-05-19 15:46:00 INFO Agent received command: run
2024-05-19 15:46:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 15:46:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 15:46:05 INFO Running runs: ['fnkwg2kb']
2024-05-19 15:48:01 INFO Cleaning up finished run: fnkwg2kb
2024-05-19 15:48:02 INFO Agent received command: run
2024-05-19 15:48:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:48:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:48:07 INFO Running runs: ['3smwzw2l']
2024-05-19 15:49:26 INFO Cleaning up finished run: 3smwzw2l
2024-05-19 15:49:28 INFO Agent received command: run
2024-05-19 15:49:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:49:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:49:33 INFO Running runs: ['9dt48v3j']
2024-05-19 15:50:52 INFO Cleaning up finished run: 9dt48v3j
2024-05-19 15:51:05 INFO Agent received command: run
2024-05-19 15:51:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 15:51:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 15:51:10 INFO Running runs: ['c7nbww2u']
2024-05-19 15:53:17 INFO Cleaning up finished run: c7nbww2u
2024-05-19 15:53:18 INFO Agent received command: run
2024-05-19 15:53:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 15:53:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 15:53:23 INFO Running runs: ['si5mwj4j']
2024-05-19 15:55:30 INFO Cleaning up finished run: si5mwj4j
2024-05-19 15:55:40 INFO Agent received command: run
2024-05-19 15:55:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 15:55:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 15:55:45 INFO Running runs: ['5um0jow4']
2024-05-19 15:57:53 INFO Cleaning up finished run: 5um0jow4
2024-05-19 15:57:54 INFO Agent received command: run
2024-05-19 15:57:54 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 15:57:54 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 15:57:59 INFO Running runs: ['sr8as9u7']
2024-05-19 15:59:18 INFO Cleaning up finished run: sr8as9u7
2024-05-19 15:59:19 INFO Agent received command: run
2024-05-19 15:59:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 15:59:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 15:59:24 INFO Running runs: ['zf7yh791']
2024-05-19 16:00:59 INFO Cleaning up finished run: zf7yh791
2024-05-19 16:01:00 INFO Agent received command: run
2024-05-19 16:01:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:01:00 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:01:05 INFO Running runs: ['z1zzv4t3']
2024-05-19 16:03:07 INFO Cleaning up finished run: z1zzv4t3
2024-05-19 16:03:08 INFO Agent received command: run
2024-05-19 16:03:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 16:03:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 16:03:13 INFO Running runs: ['1ukxpnhl']
2024-05-19 16:04:11 INFO Cleaning up finished run: 1ukxpnhl
2024-05-19 16:04:12 INFO Agent received command: run
2024-05-19 16:04:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:04:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:04:17 INFO Running runs: ['r73byq61']
2024-05-19 16:05:47 INFO Cleaning up finished run: r73byq61
2024-05-19 16:05:48 INFO Agent received command: run
2024-05-19 16:05:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:05:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:05:53 INFO Running runs: ['u6zamm0m']
2024-05-19 16:07:07 INFO Cleaning up finished run: u6zamm0m
2024-05-19 16:07:30 INFO Agent received command: run
2024-05-19 16:07:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:07:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:07:35 INFO Running runs: ['kumk17j2']
2024-05-19 16:08:49 INFO Cleaning up finished run: kumk17j2
2024-05-19 16:08:50 INFO Agent received command: run
2024-05-19 16:08:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 16:08:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 16:08:55 INFO Running runs: ['usewmfti']
2024-05-19 16:10:57 INFO Cleaning up finished run: usewmfti
2024-05-19 16:10:58 INFO Agent received command: run
2024-05-19 16:10:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 16:10:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 16:11:03 INFO Running runs: ['6w68oval']
2024-05-19 16:13:05 INFO Cleaning up finished run: 6w68oval
2024-05-19 16:13:05 INFO Agent received command: run
2024-05-19 16:13:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:13:05 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:13:11 INFO Running runs: ['mdpro1fw']
2024-05-19 16:15:07 INFO Cleaning up finished run: mdpro1fw
2024-05-19 16:15:08 INFO Agent received command: run
2024-05-19 16:15:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 16:15:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 16:15:13 INFO Running runs: ['snnelrpk']
2024-05-19 16:16:49 INFO Cleaning up finished run: snnelrpk
2024-05-19 16:16:49 INFO Agent received command: run
2024-05-19 16:16:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 16:16:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 16:16:54 INFO Running runs: ['54wlq0fl']
2024-05-19 16:18:14 INFO Cleaning up finished run: 54wlq0fl
2024-05-19 16:18:15 INFO Agent received command: run
2024-05-19 16:18:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 16:18:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 16:18:20 INFO Running runs: ['dvb0uxz6']
2024-05-19 16:20:38 INFO Cleaning up finished run: dvb0uxz6
2024-05-19 16:20:39 INFO Agent received command: run
2024-05-19 16:20:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:20:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:20:44 INFO Running runs: ['youz5ybc']
2024-05-19 16:23:06 INFO Cleaning up finished run: youz5ybc
2024-05-19 16:23:07 INFO Agent received command: run
2024-05-19 16:23:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:23:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:23:12 INFO Running runs: ['94u93rg4']
2024-05-19 16:24:58 INFO Cleaning up finished run: 94u93rg4
2024-05-19 16:24:59 INFO Agent received command: run
2024-05-19 16:24:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 16:24:59 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 16:25:04 INFO Running runs: ['2zq4st9u']
2024-05-19 16:27:06 INFO Cleaning up finished run: 2zq4st9u
2024-05-19 16:27:07 INFO Agent received command: run
2024-05-19 16:27:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:27:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:27:12 INFO Running runs: ['d79orlns']
2024-05-19 16:29:35 INFO Cleaning up finished run: d79orlns
2024-05-19 16:29:36 INFO Agent received command: run
2024-05-19 16:29:36 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 16:29:36 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 16:29:41 INFO Running runs: ['83s5y25t']
2024-05-19 16:31:32 INFO Cleaning up finished run: 83s5y25t
2024-05-19 16:31:33 INFO Agent received command: run
2024-05-19 16:31:33 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:31:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:31:38 INFO Running runs: ['wa07yif1']
2024-05-19 16:33:57 INFO Cleaning up finished run: wa07yif1
2024-05-19 16:33:58 INFO Agent received command: run
2024-05-19 16:33:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 16:33:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 16:34:03 INFO Running runs: ['fzg85gu3']
2024-05-19 16:36:42 INFO Cleaning up finished run: fzg85gu3
2024-05-19 16:36:43 INFO Agent received command: run
2024-05-19 16:36:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 16:36:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 16:36:48 INFO Running runs: ['236gf3wu']
2024-05-19 16:37:57 INFO Cleaning up finished run: 236gf3wu
2024-05-19 16:37:58 INFO Agent received command: run
2024-05-19 16:37:58 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:37:58 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:38:03 INFO Running runs: ['p324mfr0']
2024-05-19 16:39:17 INFO Cleaning up finished run: p324mfr0
2024-05-19 16:39:18 INFO Agent received command: run
2024-05-19 16:39:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 16:39:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 16:39:23 INFO Running runs: ['pqt77fgs']
2024-05-19 16:41:36 INFO Cleaning up finished run: pqt77fgs
2024-05-19 16:41:36 INFO Agent received command: run
2024-05-19 16:41:36 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 16:41:36 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 16:41:42 INFO Running runs: ['2iv2vbai']
2024-05-19 16:44:04 INFO Cleaning up finished run: 2iv2vbai
2024-05-19 16:44:11 INFO Agent received command: run
2024-05-19 16:44:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 16:44:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 16:44:16 INFO Running runs: ['gtrqwhns']
2024-05-19 16:46:07 INFO Cleaning up finished run: gtrqwhns
2024-05-19 16:46:14 INFO Agent received command: run
2024-05-19 16:46:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:46:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:46:19 INFO Running runs: ['319iplq7']
2024-05-19 16:47:49 INFO Cleaning up finished run: 319iplq7
2024-05-19 16:47:50 INFO Agent received command: run
2024-05-19 16:47:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 16:47:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 16:47:55 INFO Running runs: ['o6t3zolg']
2024-05-19 16:50:18 INFO Cleaning up finished run: o6t3zolg
2024-05-19 16:50:19 INFO Agent received command: run
2024-05-19 16:50:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 16:50:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 16:50:24 INFO Running runs: ['t6u8l4gn']
2024-05-19 16:52:20 INFO Cleaning up finished run: t6u8l4gn
2024-05-19 16:52:21 INFO Agent received command: run
2024-05-19 16:52:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 16:52:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 16:52:26 INFO Running runs: ['dxplr57m']
2024-05-19 16:54:12 INFO Cleaning up finished run: dxplr57m
2024-05-19 16:54:13 INFO Agent received command: run
2024-05-19 16:54:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 16:54:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 16:54:18 INFO Running runs: ['gidj76n8']
2024-05-19 16:55:16 INFO Cleaning up finished run: gidj76n8
2024-05-19 16:55:17 INFO Agent received command: run
2024-05-19 16:55:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 16:55:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 16:55:22 INFO Running runs: ['3gb6wva9']
2024-05-19 16:57:14 INFO Cleaning up finished run: 3gb6wva9
2024-05-19 16:57:14 INFO Agent received command: run
2024-05-19 16:57:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 16:57:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 16:57:19 INFO Running runs: ['niqhv4i0']
2024-05-19 16:59:37 INFO Cleaning up finished run: niqhv4i0
2024-05-19 16:59:38 INFO Agent received command: run
2024-05-19 16:59:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 16:59:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 16:59:43 INFO Running runs: ['8im7px08']
2024-05-19 17:00:42 INFO Cleaning up finished run: 8im7px08
2024-05-19 17:00:42 INFO Agent received command: run
2024-05-19 17:00:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:00:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:00:48 INFO Running runs: ['mbrc1x0i']
2024-05-19 17:03:11 INFO Cleaning up finished run: mbrc1x0i
2024-05-19 17:03:11 INFO Agent received command: run
2024-05-19 17:03:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 17:03:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 17:03:16 INFO Running runs: ['ruq1vrjb']
2024-05-19 17:05:23 INFO Cleaning up finished run: ruq1vrjb
2024-05-19 17:05:26 INFO Agent received command: run
2024-05-19 17:05:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:05:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:05:31 INFO Running runs: ['lyqnlikd']
2024-05-19 17:07:07 INFO Cleaning up finished run: lyqnlikd
2024-05-19 17:07:07 INFO Agent received command: run
2024-05-19 17:07:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 17:07:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 17:07:12 INFO Running runs: ['83drwhwj']
2024-05-19 17:08:58 INFO Cleaning up finished run: 83drwhwj
2024-05-19 17:09:01 INFO Agent received command: run
2024-05-19 17:09:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 17:09:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 17:09:06 INFO Running runs: ['qmvmz7q5']
2024-05-19 17:10:53 INFO Cleaning up finished run: qmvmz7q5
2024-05-19 17:10:53 INFO Agent received command: run
2024-05-19 17:10:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-19 17:10:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-19 17:10:58 INFO Running runs: ['dj4vc4tx']
2024-05-19 17:12:55 INFO Cleaning up finished run: dj4vc4tx
2024-05-19 17:13:03 INFO Agent received command: run
2024-05-19 17:13:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 17:13:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 17:13:08 INFO Running runs: ['no6zjvxm']
2024-05-19 17:14:50 INFO Cleaning up finished run: no6zjvxm
2024-05-19 17:14:50 INFO Agent received command: run
2024-05-19 17:14:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:14:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:14:55 INFO Running runs: ['drlndiv8']
2024-05-19 17:16:31 INFO Cleaning up finished run: drlndiv8
2024-05-19 17:16:32 INFO Agent received command: run
2024-05-19 17:16:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 17:16:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 17:16:37 INFO Running runs: ['m3ig2c33']
2024-05-19 17:18:07 INFO Cleaning up finished run: m3ig2c33
2024-05-19 17:18:12 INFO Agent received command: run
2024-05-19 17:18:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 17:18:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 17:18:17 INFO Running runs: ['hg1immwb']
2024-05-19 17:20:03 INFO Cleaning up finished run: hg1immwb
2024-05-19 17:20:06 INFO Agent received command: run
2024-05-19 17:20:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 17:20:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 17:20:11 INFO Running runs: ['fktiidhk']
2024-05-19 17:22:08 INFO Cleaning up finished run: fktiidhk
2024-05-19 17:22:09 INFO Agent received command: run
2024-05-19 17:22:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 17:22:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 17:22:14 INFO Running runs: ['4e744ais']
2024-05-19 17:23:44 INFO Cleaning up finished run: 4e744ais
2024-05-19 17:23:45 INFO Agent received command: run
2024-05-19 17:23:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 17:23:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 17:23:50 INFO Running runs: ['j4jz943o']
2024-05-19 17:26:18 INFO Cleaning up finished run: j4jz943o
2024-05-19 17:26:19 INFO Agent received command: run
2024-05-19 17:26:19 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 17:26:19 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 17:26:24 INFO Running runs: ['ceg0lr3g']
2024-05-19 17:27:54 INFO Cleaning up finished run: ceg0lr3g
2024-05-19 17:27:55 INFO Agent received command: run
2024-05-19 17:27:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:27:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:28:00 INFO Running runs: ['fl4bhrci']
2024-05-19 17:29:46 INFO Cleaning up finished run: fl4bhrci
2024-05-19 17:29:47 INFO Agent received command: run
2024-05-19 17:29:47 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 17:29:47 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 17:29:52 INFO Running runs: ['s9a9uj8u']
2024-05-19 17:31:06 INFO Cleaning up finished run: s9a9uj8u
2024-05-19 17:31:07 INFO Agent received command: run
2024-05-19 17:31:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 17:31:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 17:31:12 INFO Running runs: ['125k3rzn']
2024-05-19 17:32:47 INFO Cleaning up finished run: 125k3rzn
2024-05-19 17:32:48 INFO Agent received command: run
2024-05-19 17:32:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 17:32:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 17:32:53 INFO Running runs: ['s3oflqvw']
2024-05-19 17:34:02 INFO Cleaning up finished run: s3oflqvw
2024-05-19 17:34:02 INFO Agent received command: run
2024-05-19 17:34:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:34:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:34:07 INFO Running runs: ['v6r72jr6']
2024-05-19 17:35:53 INFO Cleaning up finished run: v6r72jr6
2024-05-19 17:35:54 INFO Agent received command: run
2024-05-19 17:35:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:35:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:35:59 INFO Running runs: ['1s5lspz5']
2024-05-19 17:36:52 INFO Cleaning up finished run: 1s5lspz5
2024-05-19 17:36:53 INFO Agent received command: run
2024-05-19 17:36:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 17:36:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 17:36:58 INFO Running runs: ['ynp1v058']
2024-05-19 17:38:07 INFO Cleaning up finished run: ynp1v058
2024-05-19 17:38:08 INFO Agent received command: run
2024-05-19 17:38:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 17:38:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 17:38:13 INFO Running runs: ['jrsefbrd']
2024-05-19 17:40:15 INFO Cleaning up finished run: jrsefbrd
2024-05-19 17:40:30 INFO Agent received command: run
2024-05-19 17:40:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 17:40:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 17:40:35 INFO Running runs: ['ov0kuawy']
2024-05-19 17:42:11 INFO Cleaning up finished run: ov0kuawy
2024-05-19 17:42:12 INFO Agent received command: run
2024-05-19 17:42:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 17:42:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 17:42:17 INFO Running runs: ['ghq8d8bc']
2024-05-19 17:43:37 INFO Cleaning up finished run: ghq8d8bc
2024-05-19 17:43:39 INFO Agent received command: run
2024-05-19 17:43:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:43:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:43:44 INFO Running runs: ['dfr680yr']
2024-05-19 17:46:07 INFO Cleaning up finished run: dfr680yr
2024-05-19 17:46:07 INFO Agent received command: run
2024-05-19 17:46:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 17:46:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 17:46:12 INFO Running runs: ['p89ewqwf']
2024-05-19 17:47:48 INFO Cleaning up finished run: p89ewqwf
2024-05-19 17:47:49 INFO Agent received command: run
2024-05-19 17:47:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 17:47:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 17:47:54 INFO Running runs: ['2mm5qzri']
2024-05-19 17:49:29 INFO Cleaning up finished run: 2mm5qzri
2024-05-19 17:49:29 INFO Agent received command: run
2024-05-19 17:49:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 17:49:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 17:49:35 INFO Running runs: ['96m2ea3s']
2024-05-19 17:51:36 INFO Cleaning up finished run: 96m2ea3s
2024-05-19 17:51:38 INFO Agent received command: run
2024-05-19 17:51:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 17:51:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 17:51:43 INFO Running runs: ['b73j1f81']
2024-05-19 17:54:12 INFO Cleaning up finished run: b73j1f81
2024-05-19 17:54:13 INFO Agent received command: run
2024-05-19 17:54:13 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 17:54:13 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 17:54:18 INFO Running runs: ['98xoofe7']
2024-05-19 17:56:14 INFO Cleaning up finished run: 98xoofe7
2024-05-19 17:56:15 INFO Agent received command: run
2024-05-19 17:56:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 17:56:15 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 17:56:20 INFO Running runs: ['ajquvp6r']
2024-05-19 17:57:34 INFO Cleaning up finished run: ajquvp6r
2024-05-19 17:57:35 INFO Agent received command: run
2024-05-19 17:57:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 17:57:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 17:57:40 INFO Running runs: ['5k8swwxy']
2024-05-19 18:00:08 INFO Cleaning up finished run: 5k8swwxy
2024-05-19 18:00:09 INFO Agent received command: run
2024-05-19 18:00:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:00:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:00:14 INFO Running runs: ['3enrfpt0']
2024-05-19 18:02:37 INFO Cleaning up finished run: 3enrfpt0
2024-05-19 18:02:38 INFO Agent received command: run
2024-05-19 18:02:38 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 18:02:38 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 18:02:43 INFO Running runs: ['km4lupmv']
2024-05-19 18:04:50 INFO Cleaning up finished run: km4lupmv
2024-05-19 18:04:50 INFO Agent received command: run
2024-05-19 18:04:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 18:04:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 18:04:55 INFO Running runs: ['souei3qp']
2024-05-19 18:06:10 INFO Cleaning up finished run: souei3qp
2024-05-19 18:06:10 INFO Agent received command: run
2024-05-19 18:06:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 18:06:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 18:06:15 INFO Running runs: ['3pquwyoo']
2024-05-19 18:07:30 INFO Cleaning up finished run: 3pquwyoo
2024-05-19 18:07:31 INFO Agent received command: run
2024-05-19 18:07:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:07:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:07:36 INFO Running runs: ['hhc42qjw']
2024-05-19 18:08:34 INFO Cleaning up finished run: hhc42qjw
2024-05-19 18:08:35 INFO Agent received command: run
2024-05-19 18:08:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:08:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:08:40 INFO Running runs: ['n7vjqt79']
2024-05-19 18:10:04 INFO Cleaning up finished run: n7vjqt79
2024-05-19 18:10:05 INFO Agent received command: run
2024-05-19 18:10:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:10:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:10:10 INFO Running runs: ['jxd966xh']
2024-05-19 18:12:02 INFO Cleaning up finished run: jxd966xh
2024-05-19 18:12:03 INFO Agent received command: run
2024-05-19 18:12:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:12:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:12:08 INFO Running runs: ['gb2cjtvt']
2024-05-19 18:13:38 INFO Cleaning up finished run: gb2cjtvt
2024-05-19 18:13:39 INFO Agent received command: run
2024-05-19 18:13:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:13:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:13:44 INFO Running runs: ['b7iambgz']
2024-05-19 18:15:19 INFO Cleaning up finished run: b7iambgz
2024-05-19 18:15:21 INFO Agent received command: run
2024-05-19 18:15:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 18:15:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 18:15:26 INFO Running runs: ['h6pz5ijp']
2024-05-19 18:16:24 INFO Cleaning up finished run: h6pz5ijp
2024-05-19 18:16:24 INFO Agent received command: run
2024-05-19 18:16:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 18:16:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 18:16:30 INFO Running runs: ['zd57nd06']
2024-05-19 18:18:10 INFO Cleaning up finished run: zd57nd06
2024-05-19 18:18:11 INFO Agent received command: run
2024-05-19 18:18:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:18:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:18:16 INFO Running runs: ['td9322by']
2024-05-19 18:20:12 INFO Cleaning up finished run: td9322by
2024-05-19 18:20:13 INFO Agent received command: run
2024-05-19 18:20:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 18:20:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 18:20:18 INFO Running runs: ['fwt0xhds']
2024-05-19 18:21:16 INFO Cleaning up finished run: fwt0xhds
2024-05-19 18:21:18 INFO Agent received command: run
2024-05-19 18:21:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 18:21:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 18:21:23 INFO Running runs: ['l135jo2x']
2024-05-19 18:24:23 INFO Cleaning up finished run: l135jo2x
2024-05-19 18:24:23 INFO Agent received command: run
2024-05-19 18:24:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-19 18:24:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-19 18:24:28 INFO Running runs: ['mtl7oavy']
2024-05-19 18:26:14 INFO Cleaning up finished run: mtl7oavy
2024-05-19 18:26:15 INFO Agent received command: run
2024-05-19 18:26:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 18:26:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 18:26:20 INFO Running runs: ['umxmkudn']
2024-05-19 18:27:35 INFO Cleaning up finished run: umxmkudn
2024-05-19 18:27:36 INFO Agent received command: run
2024-05-19 18:27:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:27:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:27:41 INFO Running runs: ['kpz65uvn']
2024-05-19 18:28:44 INFO Cleaning up finished run: kpz65uvn
2024-05-19 18:28:45 INFO Agent received command: run
2024-05-19 18:28:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:28:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:28:50 INFO Running runs: ['f20vwo2v']
2024-05-19 18:30:47 INFO Cleaning up finished run: f20vwo2v
2024-05-19 18:30:47 INFO Agent received command: run
2024-05-19 18:30:47 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:30:47 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:30:52 INFO Running runs: ['sl0v5cmo']
2024-05-19 18:33:31 INFO Cleaning up finished run: sl0v5cmo
2024-05-19 18:33:35 INFO Agent received command: run
2024-05-19 18:33:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:33:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:33:40 INFO Running runs: ['vyar588p']
2024-05-19 18:36:08 INFO Cleaning up finished run: vyar588p
2024-05-19 18:36:09 INFO Agent received command: run
2024-05-19 18:36:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 18:36:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 18:36:14 INFO Running runs: ['ovpgqoel']
2024-05-19 18:38:10 INFO Cleaning up finished run: ovpgqoel
2024-05-19 18:38:12 INFO Agent received command: run
2024-05-19 18:38:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:38:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:38:17 INFO Running runs: ['67s5qqgr']
2024-05-19 18:39:15 INFO Cleaning up finished run: 67s5qqgr
2024-05-19 18:39:16 INFO Agent received command: run
2024-05-19 18:39:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-19 18:39:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-19 18:39:21 INFO Running runs: ['tt7fkalb']
2024-05-19 18:40:56 INFO Cleaning up finished run: tt7fkalb
2024-05-19 18:40:57 INFO Agent received command: run
2024-05-19 18:40:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 18:40:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 18:41:02 INFO Running runs: ['1kohft7v']
2024-05-19 18:42:48 INFO Cleaning up finished run: 1kohft7v
2024-05-19 18:42:49 INFO Agent received command: run
2024-05-19 18:42:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 18:42:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 18:42:54 INFO Running runs: ['n0085kjw']
2024-05-19 18:44:51 INFO Cleaning up finished run: n0085kjw
2024-05-19 18:44:51 INFO Agent received command: run
2024-05-19 18:44:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:44:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:44:56 INFO Running runs: ['c58fab65']
2024-05-19 18:46:16 INFO Cleaning up finished run: c58fab65
2024-05-19 18:46:23 INFO Agent received command: run
2024-05-19 18:46:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:46:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:46:28 INFO Running runs: ['ns4azupa']
2024-05-19 18:49:49 INFO Cleaning up finished run: ns4azupa
2024-05-19 18:49:50 INFO Agent received command: run
2024-05-19 18:49:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 18:49:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 18:49:55 INFO Running runs: ['3l459bu0']
2024-05-19 18:52:55 INFO Cleaning up finished run: 3l459bu0
2024-05-19 18:52:56 INFO Agent received command: run
2024-05-19 18:52:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 18:52:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 18:53:01 INFO Running runs: ['wjibyiac']
2024-05-19 18:54:58 INFO Cleaning up finished run: wjibyiac
2024-05-19 18:54:59 INFO Agent received command: run
2024-05-19 18:54:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 18:54:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 18:55:04 INFO Running runs: ['hpp0c98i']
2024-05-19 18:56:55 INFO Cleaning up finished run: hpp0c98i
2024-05-19 18:56:57 INFO Agent received command: run
2024-05-19 18:56:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:56:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:57:02 INFO Running runs: ['x0elb8c4']
2024-05-19 18:58:53 INFO Cleaning up finished run: x0elb8c4
2024-05-19 18:58:54 INFO Agent received command: run
2024-05-19 18:58:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 18:58:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 18:58:59 INFO Running runs: ['f1n2aqyr']
2024-05-19 19:01:06 INFO Cleaning up finished run: f1n2aqyr
2024-05-19 19:01:07 INFO Agent received command: run
2024-05-19 19:01:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 19:01:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 19:01:12 INFO Running runs: ['odk0hnk4']
2024-05-19 19:04:17 INFO Cleaning up finished run: odk0hnk4
2024-05-19 19:04:18 INFO Agent received command: run
2024-05-19 19:04:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 19:04:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 19:04:23 INFO Running runs: ['wu0hfnuy']
2024-05-19 19:05:43 INFO Cleaning up finished run: wu0hfnuy
2024-05-19 19:05:44 INFO Agent received command: run
2024-05-19 19:05:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 19:05:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 19:05:49 INFO Running runs: ['bzescpro']
2024-05-19 19:07:50 INFO Cleaning up finished run: bzescpro
2024-05-19 19:07:57 INFO Agent received command: run
2024-05-19 19:07:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 19:07:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 19:08:02 INFO Running runs: ['8jr2wout']
2024-05-19 19:10:14 INFO Cleaning up finished run: 8jr2wout
2024-05-19 19:10:15 INFO Agent received command: run
2024-05-19 19:10:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 19:10:15 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 19:10:20 INFO Running runs: ['ec6rgwuv']
2024-05-19 19:12:06 INFO Cleaning up finished run: ec6rgwuv
2024-05-19 19:12:07 INFO Agent received command: run
2024-05-19 19:12:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 19:12:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 19:12:12 INFO Running runs: ['56i97nbw']
2024-05-19 19:15:07 INFO Cleaning up finished run: 56i97nbw
2024-05-19 19:15:07 INFO Agent received command: run
2024-05-19 19:15:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 19:15:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 19:15:12 INFO Running runs: ['pt8jcm7r']
2024-05-19 19:17:41 INFO Cleaning up finished run: pt8jcm7r
2024-05-19 19:17:41 INFO Agent received command: run
2024-05-19 19:17:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 19:17:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 19:17:46 INFO Running runs: ['bjonmhfq']
2024-05-19 19:19:48 INFO Cleaning up finished run: bjonmhfq
2024-05-19 19:19:49 INFO Agent received command: run
2024-05-19 19:19:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 19:19:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 19:19:54 INFO Running runs: ['qiv3g03p']
2024-05-19 19:23:05 INFO Cleaning up finished run: qiv3g03p
2024-05-19 19:23:13 INFO Agent received command: run
2024-05-19 19:23:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 19:23:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 19:23:19 INFO Running runs: ['7psekjkn']
2024-05-19 19:25:15 INFO Cleaning up finished run: 7psekjkn
2024-05-19 19:25:16 INFO Agent received command: run
2024-05-19 19:25:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 19:25:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 19:25:21 INFO Running runs: ['6nn7efll']
2024-05-19 19:26:36 INFO Cleaning up finished run: 6nn7efll
2024-05-19 19:26:37 INFO Agent received command: run
2024-05-19 19:26:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 19:26:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 19:26:42 INFO Running runs: ['ocmnnaut']
2024-05-19 19:28:38 INFO Cleaning up finished run: ocmnnaut
2024-05-19 19:28:39 INFO Agent received command: run
2024-05-19 19:28:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 19:28:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 19:28:44 INFO Running runs: ['xufktx5u']
2024-05-19 19:30:19 INFO Cleaning up finished run: xufktx5u
2024-05-19 19:30:20 INFO Agent received command: run
2024-05-19 19:30:20 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 19:30:20 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 19:30:25 INFO Running runs: ['ylcgeisp']
2024-05-19 19:31:44 INFO Cleaning up finished run: ylcgeisp
2024-05-19 19:31:46 INFO Agent received command: run
2024-05-19 19:31:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:31:46 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:31:51 INFO Running runs: ['jlwpqvs7']
2024-05-19 19:33:52 INFO Cleaning up finished run: jlwpqvs7
2024-05-19 19:33:53 INFO Agent received command: run
2024-05-19 19:33:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:33:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:33:58 INFO Running runs: ['ueriqqmy']
2024-05-19 19:36:16 INFO Cleaning up finished run: ueriqqmy
2024-05-19 19:36:17 INFO Agent received command: run
2024-05-19 19:36:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:36:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:36:22 INFO Running runs: ['d3cuxucf']
2024-05-19 19:38:19 INFO Cleaning up finished run: d3cuxucf
2024-05-19 19:38:19 INFO Agent received command: run
2024-05-19 19:38:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:38:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:38:24 INFO Running runs: ['zv6jde5q']
2024-05-19 19:39:44 INFO Cleaning up finished run: zv6jde5q
2024-05-19 19:39:44 INFO Agent received command: run
2024-05-19 19:39:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:39:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:39:49 INFO Running runs: ['9zc8p8if']
2024-05-19 19:42:23 INFO Cleaning up finished run: 9zc8p8if
2024-05-19 19:42:24 INFO Agent received command: run
2024-05-19 19:42:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 19:42:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 19:42:29 INFO Running runs: ['f5a7m79p']
2024-05-19 19:45:13 INFO Cleaning up finished run: f5a7m79p
2024-05-19 19:45:15 INFO Agent received command: run
2024-05-19 19:45:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-19 19:45:15 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-19 19:45:20 INFO Running runs: ['xlfldsdx']
2024-05-19 19:47:00 INFO Cleaning up finished run: xlfldsdx
2024-05-19 19:47:01 INFO Agent received command: run
2024-05-19 19:47:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 19:47:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 19:47:06 INFO Running runs: ['pbkhox9l']
2024-05-19 19:48:25 INFO Cleaning up finished run: pbkhox9l
2024-05-19 19:48:26 INFO Agent received command: run
2024-05-19 19:48:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: random
2024-05-19 19:48:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=random
2024-05-19 19:48:31 INFO Running runs: ['g9q475at']
2024-05-19 19:50:33 INFO Cleaning up finished run: g9q475at
2024-05-19 19:50:34 INFO Agent received command: run
2024-05-19 19:50:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 19:50:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 19:50:39 INFO Running runs: ['0tw8pb58']
2024-05-19 19:52:41 INFO Cleaning up finished run: 0tw8pb58
2024-05-19 19:52:41 INFO Agent received command: run
2024-05-19 19:52:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 19:52:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 19:52:46 INFO Running runs: ['11pmtk9u']
2024-05-19 19:54:11 INFO Cleaning up finished run: 11pmtk9u
2024-05-19 19:54:12 INFO Agent received command: run
2024-05-19 19:54:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 19:54:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 19:54:17 INFO Running runs: ['eg5i6lhh']
2024-05-19 19:55:26 INFO Cleaning up finished run: eg5i6lhh
2024-05-19 19:55:27 INFO Agent received command: run
2024-05-19 19:55:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 19:55:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 19:55:32 INFO Running runs: ['xlhidfkf']
2024-05-19 19:58:05 INFO Cleaning up finished run: xlhidfkf
2024-05-19 19:58:06 INFO Agent received command: run
2024-05-19 19:58:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 19:58:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 19:58:11 INFO Running runs: ['rpkaoas8']
2024-05-19 19:59:36 INFO Cleaning up finished run: rpkaoas8
2024-05-19 19:59:37 INFO Agent received command: run
2024-05-19 19:59:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 19:59:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 19:59:42 INFO Running runs: ['jaj256x3']
2024-05-19 20:01:44 INFO Cleaning up finished run: jaj256x3
2024-05-19 20:01:45 INFO Agent received command: run
2024-05-19 20:01:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 20:01:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 20:01:50 INFO Running runs: ['yu4lf8tb']
2024-05-19 20:03:41 INFO Cleaning up finished run: yu4lf8tb
2024-05-19 20:03:42 INFO Agent received command: run
2024-05-19 20:03:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 20:03:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 20:03:47 INFO Running runs: ['eco9dxxb']
2024-05-19 20:07:08 INFO Cleaning up finished run: eco9dxxb
2024-05-19 20:07:08 INFO Agent received command: run
2024-05-19 20:07:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 20:07:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 20:07:13 INFO Running runs: ['qie9cvwa']
2024-05-19 20:09:15 INFO Cleaning up finished run: qie9cvwa
2024-05-19 20:09:16 INFO Agent received command: run
2024-05-19 20:09:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 20:09:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 20:09:21 INFO Running runs: ['mwgzxjea']
2024-05-19 20:10:57 INFO Cleaning up finished run: mwgzxjea
2024-05-19 20:10:58 INFO Agent received command: run
2024-05-19 20:10:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 20:10:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 20:11:03 INFO Running runs: ['0vu0nxgh']
2024-05-19 20:14:24 INFO Cleaning up finished run: 0vu0nxgh
2024-05-19 20:14:33 INFO Agent received command: run
2024-05-19 20:14:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 20:14:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 20:14:38 INFO Running runs: ['4nh1limd']
2024-05-19 20:17:27 INFO Cleaning up finished run: 4nh1limd
2024-05-19 20:17:28 INFO Agent received command: run
2024-05-19 20:17:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 20:17:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 20:17:33 INFO Running runs: ['t2ujrm2c']
2024-05-19 20:19:03 INFO Cleaning up finished run: t2ujrm2c
2024-05-19 20:19:04 INFO Agent received command: run
2024-05-19 20:19:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 20:19:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 20:19:09 INFO Running runs: ['21uswivm']
2024-05-19 20:21:32 INFO Cleaning up finished run: 21uswivm
2024-05-19 20:21:33 INFO Agent received command: run
2024-05-19 20:21:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 20:21:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 20:21:38 INFO Running runs: ['xjo6sit7']
2024-05-19 20:23:03 INFO Cleaning up finished run: xjo6sit7
2024-05-19 20:23:04 INFO Agent received command: run
2024-05-19 20:23:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 20:23:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 20:23:09 INFO Running runs: ['gbwvekfv']
2024-05-19 20:25:10 INFO Cleaning up finished run: gbwvekfv
2024-05-19 20:25:11 INFO Agent received command: run
2024-05-19 20:25:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 20:25:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 20:25:16 INFO Running runs: ['mcuf8q8x']
2024-05-19 20:26:41 INFO Cleaning up finished run: mcuf8q8x
2024-05-19 20:26:42 INFO Agent received command: run
2024-05-19 20:26:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 20:26:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 20:26:47 INFO Running runs: ['b10wd6em']
2024-05-19 20:28:54 INFO Cleaning up finished run: b10wd6em
2024-05-19 20:29:06 INFO Agent received command: run
2024-05-19 20:29:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 20:29:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 20:29:11 INFO Running runs: ['gfqgf52g']
2024-05-19 20:30:57 INFO Cleaning up finished run: gfqgf52g
2024-05-19 20:30:58 INFO Agent received command: run
2024-05-19 20:30:58 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 20:30:58 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 20:31:03 INFO Running runs: ['blrq2vhu']
2024-05-19 20:32:17 INFO Cleaning up finished run: blrq2vhu
2024-05-19 20:32:18 INFO Agent received command: run
2024-05-19 20:32:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 20:32:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 20:32:23 INFO Running runs: ['gki6y2mo']
2024-05-19 20:33:48 INFO Cleaning up finished run: gki6y2mo
2024-05-19 20:33:49 INFO Agent received command: run
2024-05-19 20:33:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 20:33:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 20:33:54 INFO Running runs: ['9scxva3z']
2024-05-19 20:35:34 INFO Cleaning up finished run: 9scxva3z
2024-05-19 20:35:35 INFO Agent received command: run
2024-05-19 20:35:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 20:35:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 20:35:40 INFO Running runs: ['0juroztb']
2024-05-19 20:38:14 INFO Cleaning up finished run: 0juroztb
2024-05-19 20:38:34 INFO Agent received command: run
2024-05-19 20:38:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 20:38:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 20:38:39 INFO Running runs: ['iviw4jqe']
2024-05-19 20:41:13 INFO Cleaning up finished run: iviw4jqe
2024-05-19 20:41:14 INFO Agent received command: run
2024-05-19 20:41:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 20:41:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 20:41:19 INFO Running runs: ['zap88cj4']
2024-05-19 20:42:45 INFO Cleaning up finished run: zap88cj4
2024-05-19 20:42:46 INFO Agent received command: run
2024-05-19 20:42:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 20:42:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 20:42:51 INFO Running runs: ['k63ozndi']
2024-05-19 20:45:09 INFO Cleaning up finished run: k63ozndi
2024-05-19 20:45:10 INFO Agent received command: run
2024-05-19 20:45:10 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 20:45:10 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 20:45:15 INFO Running runs: ['7ovhua0s']
2024-05-19 20:47:48 INFO Cleaning up finished run: 7ovhua0s
2024-05-19 20:47:49 INFO Agent received command: run
2024-05-19 20:47:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 20:47:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 20:47:54 INFO Running runs: ['ncnkaph2']
2024-05-19 20:50:38 INFO Cleaning up finished run: ncnkaph2
2024-05-19 20:51:03 INFO Agent received command: run
2024-05-19 20:51:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 20:51:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 20:51:08 INFO Running runs: ['d825rpy1']
2024-05-19 20:53:31 INFO Cleaning up finished run: d825rpy1
2024-05-19 20:53:32 INFO Agent received command: run
2024-05-19 20:53:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 20:53:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 20:53:37 INFO Running runs: ['5naweb5y']
2024-05-19 20:56:42 INFO Cleaning up finished run: 5naweb5y
2024-05-19 20:56:43 INFO Agent received command: run
2024-05-19 20:56:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 20:56:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 20:56:48 INFO Running runs: ['j5fifebk']
2024-05-19 21:00:46 INFO Cleaning up finished run: j5fifebk
2024-05-19 21:00:47 INFO Agent received command: run
2024-05-19 21:00:47 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 21:00:47 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 21:00:52 INFO Running runs: ['mipr5a15']
2024-05-19 21:03:26 INFO Cleaning up finished run: mipr5a15
2024-05-19 21:03:27 INFO Agent received command: run
2024-05-19 21:03:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:03:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:03:32 INFO Running runs: ['osxrhii2']
2024-05-19 21:04:35 INFO Cleaning up finished run: osxrhii2
2024-05-19 21:04:50 INFO Agent received command: run
2024-05-19 21:04:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:04:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:04:55 INFO Running runs: ['1e29u2dm']
2024-05-19 21:07:13 INFO Cleaning up finished run: 1e29u2dm
2024-05-19 21:07:14 INFO Agent received command: run
2024-05-19 21:07:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 21:07:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 21:07:19 INFO Running runs: ['mdsitbav']
2024-05-19 21:11:01 INFO Cleaning up finished run: mdsitbav
2024-05-19 21:11:02 INFO Agent received command: run
2024-05-19 21:11:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:11:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:11:07 INFO Running runs: ['ossm0mb2']
2024-05-19 21:14:23 INFO Cleaning up finished run: ossm0mb2
2024-05-19 21:14:24 INFO Agent received command: run
2024-05-19 21:14:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:14:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:14:29 INFO Running runs: ['b82errnd']
2024-05-19 21:16:46 INFO Cleaning up finished run: b82errnd
2024-05-19 21:16:47 INFO Agent received command: run
2024-05-19 21:16:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: random
2024-05-19 21:16:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=random
2024-05-19 21:16:52 INFO Running runs: ['1ybjwe2c']
2024-05-19 21:18:22 INFO Cleaning up finished run: 1ybjwe2c
2024-05-19 21:18:23 INFO Agent received command: run
2024-05-19 21:18:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 21:18:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 21:18:28 INFO Running runs: ['50bfggyr']
2024-05-19 21:20:35 INFO Cleaning up finished run: 50bfggyr
2024-05-19 21:20:45 INFO Agent received command: run
2024-05-19 21:20:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:20:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:20:50 INFO Running runs: ['74dam1vz']
2024-05-19 21:23:24 INFO Cleaning up finished run: 74dam1vz
2024-05-19 21:23:25 INFO Agent received command: run
2024-05-19 21:23:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:23:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:23:30 INFO Running runs: ['4kkjche4']
2024-05-19 21:24:49 INFO Cleaning up finished run: 4kkjche4
2024-05-19 21:24:50 INFO Agent received command: run
2024-05-19 21:24:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 21:24:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 21:24:55 INFO Running runs: ['qacywy5v']
2024-05-19 21:27:02 INFO Cleaning up finished run: qacywy5v
2024-05-19 21:27:03 INFO Agent received command: run
2024-05-19 21:27:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:27:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:27:08 INFO Running runs: ['naqha89r']
2024-05-19 21:29:37 INFO Cleaning up finished run: naqha89r
2024-05-19 21:29:38 INFO Agent received command: run
2024-05-19 21:29:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:29:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:29:43 INFO Running runs: ['y82ooq1o']
2024-05-19 21:32:48 INFO Cleaning up finished run: y82ooq1o
2024-05-19 21:32:49 INFO Agent received command: run
2024-05-19 21:32:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:32:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:32:54 INFO Running runs: ['t6t11s91']
2024-05-19 21:36:05 INFO Cleaning up finished run: t6t11s91
2024-05-19 21:36:06 INFO Agent received command: run
2024-05-19 21:36:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 21:36:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 21:36:11 INFO Running runs: ['j0meait9']
2024-05-19 21:38:44 INFO Cleaning up finished run: j0meait9
2024-05-19 21:38:45 INFO Agent received command: run
2024-05-19 21:38:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:38:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:38:50 INFO Running runs: ['2mh0juhe']
2024-05-19 21:40:04 INFO Cleaning up finished run: 2mh0juhe
2024-05-19 21:40:05 INFO Agent received command: run
2024-05-19 21:40:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:40:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:40:10 INFO Running runs: ['0ipug8we']
2024-05-19 21:42:48 INFO Cleaning up finished run: 0ipug8we
2024-05-19 21:42:49 INFO Agent received command: run
2024-05-19 21:42:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:42:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:42:54 INFO Running runs: ['o0ynrcfz']
2024-05-19 21:44:30 INFO Cleaning up finished run: o0ynrcfz
2024-05-19 21:44:30 INFO Agent received command: run
2024-05-19 21:44:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 21:44:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 21:44:35 INFO Running runs: ['xv9ei35y']
2024-05-19 21:46:11 INFO Cleaning up finished run: xv9ei35y
2024-05-19 21:46:12 INFO Agent received command: run
2024-05-19 21:46:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 21:46:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 21:46:17 INFO Running runs: ['zctmy19v']
2024-05-19 21:49:37 INFO Cleaning up finished run: zctmy19v
2024-05-19 21:49:38 INFO Agent received command: run
2024-05-19 21:49:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 21:49:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 21:49:43 INFO Running runs: ['b1dglmye']
2024-05-19 21:50:47 INFO Cleaning up finished run: b1dglmye
2024-05-19 21:50:48 INFO Agent received command: run
2024-05-19 21:50:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 21:50:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 21:50:53 INFO Running runs: ['lxmxdxkr']
2024-05-19 21:52:07 INFO Cleaning up finished run: lxmxdxkr
2024-05-19 21:52:08 INFO Agent received command: run
2024-05-19 21:52:08 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 21:52:08 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 21:52:13 INFO Running runs: ['v0w6cv1s']
2024-05-19 21:54:41 INFO Cleaning up finished run: v0w6cv1s
2024-05-19 21:54:42 INFO Agent received command: run
2024-05-19 21:54:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 21:54:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 21:54:47 INFO Running runs: ['iew0megn']
2024-05-19 21:56:22 INFO Cleaning up finished run: iew0megn
2024-05-19 21:56:24 INFO Agent received command: run
2024-05-19 21:56:24 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 21:56:24 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 21:56:29 INFO Running runs: ['6jot1e0t']
2024-05-19 21:57:37 INFO Cleaning up finished run: 6jot1e0t
2024-05-19 21:57:38 INFO Agent received command: run
2024-05-19 21:57:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: random
2024-05-19 21:57:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=random
2024-05-19 21:57:43 INFO Running runs: ['jf4npkhn']
2024-05-19 22:01:46 INFO Cleaning up finished run: jf4npkhn
2024-05-19 22:01:47 INFO Agent received command: run
2024-05-19 22:01:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 22:01:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 22:01:52 INFO Running runs: ['5vwcbx96']
2024-05-19 22:04:31 INFO Cleaning up finished run: 5vwcbx96
2024-05-19 22:04:32 INFO Agent received command: run
2024-05-19 22:04:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 22:04:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 22:04:37 INFO Running runs: ['crf984u5']
2024-05-19 22:07:21 INFO Cleaning up finished run: crf984u5
2024-05-19 22:07:22 INFO Agent received command: run
2024-05-19 22:07:22 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 22:07:22 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 22:07:27 INFO Running runs: ['0ihr3toq']
2024-05-19 22:09:13 INFO Cleaning up finished run: 0ihr3toq
2024-05-19 22:09:14 INFO Agent received command: run
2024-05-19 22:09:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: random
2024-05-19 22:09:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=random
2024-05-19 22:09:19 INFO Running runs: ['8q1ekjk1']
2024-05-19 22:10:43 INFO Cleaning up finished run: 8q1ekjk1
2024-05-19 22:10:44 INFO Agent received command: run
2024-05-19 22:10:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:10:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:10:49 INFO Running runs: ['ko347yjf']
2024-05-19 22:12:41 INFO Cleaning up finished run: ko347yjf
2024-05-19 22:12:41 INFO Agent received command: run
2024-05-19 22:12:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 22:12:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 22:12:46 INFO Running runs: ['gmhbzvbk']
2024-05-19 22:14:48 INFO Cleaning up finished run: gmhbzvbk
2024-05-19 22:14:49 INFO Agent received command: run
2024-05-19 22:14:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:14:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:14:54 INFO Running runs: ['37i8xgul']
2024-05-19 22:18:15 INFO Cleaning up finished run: 37i8xgul
2024-05-19 22:18:16 INFO Agent received command: run
2024-05-19 22:18:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 22:18:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 22:18:21 INFO Running runs: ['h87gofsw']
2024-05-19 22:20:39 INFO Cleaning up finished run: h87gofsw
2024-05-19 22:20:40 INFO Agent received command: run
2024-05-19 22:20:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:20:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:20:45 INFO Running runs: ['wsm6w4ex']
2024-05-19 22:22:47 INFO Cleaning up finished run: wsm6w4ex
2024-05-19 22:22:48 INFO Agent received command: run
2024-05-19 22:22:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 22:22:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 22:22:53 INFO Running runs: ['5mnqlv9h']
2024-05-19 22:24:12 INFO Cleaning up finished run: 5mnqlv9h
2024-05-19 22:24:13 INFO Agent received command: run
2024-05-19 22:24:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 22:24:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 22:24:18 INFO Running runs: ['4kvqavfm']
2024-05-19 22:26:25 INFO Cleaning up finished run: 4kvqavfm
2024-05-19 22:26:26 INFO Agent received command: run
2024-05-19 22:26:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 22:26:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 22:26:31 INFO Running runs: ['4csbbqjf']
2024-05-19 22:28:54 INFO Cleaning up finished run: 4csbbqjf
2024-05-19 22:28:55 INFO Agent received command: run
2024-05-19 22:28:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-19 22:28:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-19 22:29:00 INFO Running runs: ['1puu1hjn']
2024-05-19 22:30:19 INFO Cleaning up finished run: 1puu1hjn
2024-05-19 22:30:41 INFO Agent received command: run
2024-05-19 22:30:41 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 22:30:41 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 22:30:46 INFO Running runs: ['7r950zg3']
2024-05-19 22:32:37 INFO Cleaning up finished run: 7r950zg3
2024-05-19 22:32:44 INFO Agent received command: run
2024-05-19 22:32:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 22:32:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 22:32:49 INFO Running runs: ['5kafj0nm']
2024-05-19 22:34:08 INFO Cleaning up finished run: 5kafj0nm
2024-05-19 22:34:09 INFO Agent received command: run
2024-05-19 22:34:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 22:34:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 22:34:14 INFO Running runs: ['bwkqlb7r']
2024-05-19 22:36:26 INFO Cleaning up finished run: bwkqlb7r
2024-05-19 22:36:27 INFO Agent received command: run
2024-05-19 22:36:27 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 22:36:27 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 22:36:32 INFO Running runs: ['95jinqrl']
2024-05-19 22:38:23 INFO Cleaning up finished run: 95jinqrl
2024-05-19 22:38:24 INFO Agent received command: run
2024-05-19 22:38:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 22:38:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 22:38:29 INFO Running runs: ['4ohmjchw']
2024-05-19 22:40:15 INFO Cleaning up finished run: 4ohmjchw
2024-05-19 22:40:16 INFO Agent received command: run
2024-05-19 22:40:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 22:40:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 22:40:21 INFO Running runs: ['h5ybtp5w']
2024-05-19 22:42:28 INFO Cleaning up finished run: h5ybtp5w
2024-05-19 22:42:29 INFO Agent received command: run
2024-05-19 22:42:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-19 22:42:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-19 22:42:34 INFO Running runs: ['vqfxvhad']
2024-05-19 22:43:58 INFO Cleaning up finished run: vqfxvhad
2024-05-19 22:43:59 INFO Agent received command: run
2024-05-19 22:43:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: random
2024-05-19 22:43:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=random
2024-05-19 22:44:04 INFO Running runs: ['y46w45cq']
2024-05-19 22:46:11 INFO Cleaning up finished run: y46w45cq
2024-05-19 22:46:12 INFO Agent received command: run
2024-05-19 22:46:12 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 22:46:12 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 22:46:17 INFO Running runs: ['t86wv4mu']
2024-05-19 22:47:26 INFO Cleaning up finished run: t86wv4mu
2024-05-19 22:47:27 INFO Agent received command: run
2024-05-19 22:47:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:47:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:47:32 INFO Running runs: ['oc1yikcx']
2024-05-19 22:49:07 INFO Cleaning up finished run: oc1yikcx
2024-05-19 22:49:08 INFO Agent received command: run
2024-05-19 22:49:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 22:49:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 22:49:13 INFO Running runs: ['jg86fbc7']
2024-05-19 22:50:27 INFO Cleaning up finished run: jg86fbc7
2024-05-19 22:50:42 INFO Agent received command: run
2024-05-19 22:50:42 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:50:42 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:50:47 INFO Running runs: ['buuofinm']
2024-05-19 22:52:43 INFO Cleaning up finished run: buuofinm
2024-05-19 22:52:44 INFO Agent received command: run
2024-05-19 22:52:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 22:52:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 22:52:49 INFO Running runs: ['fghfvxck']
2024-05-19 22:55:43 INFO Cleaning up finished run: fghfvxck
2024-05-19 22:55:44 INFO Agent received command: run
2024-05-19 22:55:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 22:55:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 22:55:49 INFO Running runs: ['1nn7czut']
2024-05-19 22:57:25 INFO Cleaning up finished run: 1nn7czut
2024-05-19 22:57:26 INFO Agent received command: run
2024-05-19 22:57:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 22:57:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 22:57:31 INFO Running runs: ['kpz1gw2u']
2024-05-19 22:58:51 INFO Cleaning up finished run: kpz1gw2u
2024-05-19 22:58:52 INFO Agent received command: run
2024-05-19 22:58:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 22:58:52 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 22:58:57 INFO Running runs: ['t22m1ce1']
2024-05-19 23:01:19 INFO Cleaning up finished run: t22m1ce1
2024-05-19 23:01:20 INFO Agent received command: run
2024-05-19 23:01:20 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 23:01:20 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 23:01:25 INFO Running runs: ['ean9axok']
2024-05-19 23:02:55 INFO Cleaning up finished run: ean9axok
2024-05-19 23:02:56 INFO Agent received command: run
2024-05-19 23:02:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-19 23:02:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-19 23:03:01 INFO Running runs: ['55dhwt2j']
2024-05-19 23:04:42 INFO Cleaning up finished run: 55dhwt2j
2024-05-19 23:04:42 INFO Agent received command: run
2024-05-19 23:04:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 23:04:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 23:04:47 INFO Running runs: ['aut0j6go']
2024-05-19 23:06:01 INFO Cleaning up finished run: aut0j6go
2024-05-19 23:06:08 INFO Agent received command: run
2024-05-19 23:06:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 23:06:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 23:06:13 INFO Running runs: ['8auysjhe']
2024-05-19 23:10:00 INFO Cleaning up finished run: 8auysjhe
2024-05-19 23:10:01 INFO Agent received command: run
2024-05-19 23:10:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 23:10:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 23:10:06 INFO Running runs: ['ov965mh0']
2024-05-19 23:12:29 INFO Cleaning up finished run: ov965mh0
2024-05-19 23:12:30 INFO Agent received command: run
2024-05-19 23:12:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-19 23:12:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-19 23:12:35 INFO Running runs: ['obzh4zqd']
2024-05-19 23:14:26 INFO Cleaning up finished run: obzh4zqd
2024-05-19 23:14:27 INFO Agent received command: run
2024-05-19 23:14:27 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 23:14:27 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 23:14:32 INFO Running runs: ['rqlqa90b']
2024-05-19 23:15:35 INFO Cleaning up finished run: rqlqa90b
2024-05-19 23:15:36 INFO Agent received command: run
2024-05-19 23:15:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: random
2024-05-19 23:15:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=random
2024-05-19 23:15:41 INFO Running runs: ['5od9jcuc']
2024-05-19 23:17:59 INFO Cleaning up finished run: 5od9jcuc
2024-05-19 23:17:59 INFO Agent received command: run
2024-05-19 23:17:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 23:17:59 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 23:18:04 INFO Running runs: ['t1e8p1vc']
2024-05-19 23:20:11 INFO Cleaning up finished run: t1e8p1vc
2024-05-19 23:20:12 INFO Agent received command: run
2024-05-19 23:20:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 23:20:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 23:20:17 INFO Running runs: ['ju6l1r9x']
2024-05-19 23:22:45 INFO Cleaning up finished run: ju6l1r9x
2024-05-19 23:22:46 INFO Agent received command: run
2024-05-19 23:22:46 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-19 23:22:46 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-19 23:22:51 INFO Running runs: ['ijulb1gu']
2024-05-19 23:25:30 INFO Cleaning up finished run: ijulb1gu
2024-05-19 23:25:31 INFO Agent received command: run
2024-05-19 23:25:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-19 23:25:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-19 23:25:36 INFO Running runs: ['xzo5gp08']
2024-05-19 23:29:08 INFO Cleaning up finished run: xzo5gp08
2024-05-19 23:29:09 INFO Agent received command: run
2024-05-19 23:29:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: random
2024-05-19 23:29:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=random
2024-05-19 23:29:14 INFO Running runs: ['61xkv3au']
2024-05-19 23:30:54 INFO Cleaning up finished run: 61xkv3au
2024-05-19 23:30:55 INFO Agent received command: run
2024-05-19 23:30:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-19 23:30:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-19 23:31:00 INFO Running runs: ['3lyovc8n']
2024-05-19 23:32:30 INFO Cleaning up finished run: 3lyovc8n
2024-05-19 23:32:31 INFO Agent received command: run
2024-05-19 23:32:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-19 23:32:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-19 23:32:36 INFO Running runs: ['bxc0myi0']
2024-05-19 23:33:39 INFO Cleaning up finished run: bxc0myi0
2024-05-19 23:33:40 INFO Agent received command: run
2024-05-19 23:33:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-19 23:33:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-19 23:33:45 INFO Running runs: ['fd1sdati']
2024-05-19 23:35:47 INFO Cleaning up finished run: fd1sdati
2024-05-19 23:35:48 INFO Agent received command: run
2024-05-19 23:35:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 23:35:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 23:35:53 INFO Running runs: ['s3vsleaa']
2024-05-19 23:37:59 INFO Cleaning up finished run: s3vsleaa
2024-05-19 23:38:00 INFO Agent received command: run
2024-05-19 23:38:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-19 23:38:00 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-19 23:38:05 INFO Running runs: ['buvfkj8p']
2024-05-19 23:40:07 INFO Cleaning up finished run: buvfkj8p
2024-05-19 23:40:08 INFO Agent received command: run
2024-05-19 23:40:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 23:40:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 23:40:13 INFO Running runs: ['pqyq8kxr']
2024-05-19 23:41:43 INFO Cleaning up finished run: pqyq8kxr
2024-05-19 23:41:44 INFO Agent received command: run
2024-05-19 23:41:44 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 23:41:44 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 23:41:49 INFO Running runs: ['sxutsm4d']
2024-05-19 23:43:08 INFO Cleaning up finished run: sxutsm4d
2024-05-19 23:43:18 INFO Agent received command: run
2024-05-19 23:43:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 23:43:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 23:43:23 INFO Running runs: ['qhmn5qq6']
2024-05-19 23:46:07 INFO Cleaning up finished run: qhmn5qq6
2024-05-19 23:46:08 INFO Agent received command: run
2024-05-19 23:46:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-19 23:46:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-19 23:46:13 INFO Running runs: ['gapgcrde']
2024-05-19 23:48:10 INFO Cleaning up finished run: gapgcrde
2024-05-19 23:48:11 INFO Agent received command: run
2024-05-19 23:48:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-19 23:48:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-19 23:48:16 INFO Running runs: ['o4az4p5t']
2024-05-19 23:49:35 INFO Cleaning up finished run: o4az4p5t
2024-05-19 23:49:36 INFO Agent received command: run
2024-05-19 23:49:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-19 23:49:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-19 23:49:41 INFO Running runs: ['s2x32jdo']
2024-05-19 23:52:46 INFO Cleaning up finished run: s2x32jdo
2024-05-19 23:52:47 INFO Agent received command: run
2024-05-19 23:52:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-19 23:52:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-19 23:52:52 INFO Running runs: ['p0rqg8sl']
2024-05-19 23:55:15 INFO Cleaning up finished run: p0rqg8sl
2024-05-19 23:55:16 INFO Agent received command: run
2024-05-19 23:55:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-19 23:55:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-19 23:55:21 INFO Running runs: ['5tpjekar']
2024-05-19 23:57:01 INFO Cleaning up finished run: 5tpjekar
2024-05-19 23:57:03 INFO Agent received command: run
2024-05-19 23:57:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-19 23:57:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-19 23:57:08 INFO Running runs: ['udy8mobf']
2024-05-19 23:59:57 INFO Cleaning up finished run: udy8mobf
2024-05-19 23:59:58 INFO Agent received command: run
2024-05-19 23:59:58 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-19 23:59:58 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 00:00:03 INFO Running runs: ['s921irg0']
2024-05-20 00:02:36 INFO Cleaning up finished run: s921irg0
2024-05-20 00:02:38 INFO Agent received command: run
2024-05-20 00:02:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:02:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:02:43 INFO Running runs: ['nwd5obsr']
2024-05-20 00:04:18 INFO Cleaning up finished run: nwd5obsr
2024-05-20 00:04:19 INFO Agent received command: run
2024-05-20 00:04:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:04:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:04:24 INFO Running runs: ['wcgm5qyz']
2024-05-20 00:05:54 INFO Cleaning up finished run: wcgm5qyz
2024-05-20 00:05:54 INFO Agent received command: run
2024-05-20 00:05:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: random
2024-05-20 00:05:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=random
2024-05-20 00:05:59 INFO Running runs: ['zs7g7rjr']
2024-05-20 00:07:03 INFO Cleaning up finished run: zs7g7rjr
2024-05-20 00:07:04 INFO Agent received command: run
2024-05-20 00:07:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-20 00:07:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=random
2024-05-20 00:07:09 INFO Running runs: ['b82ym1lx']
2024-05-20 00:08:39 INFO Cleaning up finished run: b82ym1lx
2024-05-20 00:08:39 INFO Agent received command: run
2024-05-20 00:08:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:08:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:08:44 INFO Running runs: ['y346qim8']
2024-05-20 00:11:12 INFO Cleaning up finished run: y346qim8
2024-05-20 00:11:13 INFO Agent received command: run
2024-05-20 00:11:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 00:11:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 00:11:18 INFO Running runs: ['34f9tl78']
2024-05-20 00:13:30 INFO Cleaning up finished run: 34f9tl78
2024-05-20 00:13:32 INFO Agent received command: run
2024-05-20 00:13:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 00:13:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 00:13:37 INFO Running runs: ['5a7jqtk2']
2024-05-20 00:15:22 INFO Cleaning up finished run: 5a7jqtk2
2024-05-20 00:15:23 INFO Agent received command: run
2024-05-20 00:15:23 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:15:23 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:15:28 INFO Running runs: ['k71nj3xu']
2024-05-20 00:17:35 INFO Cleaning up finished run: k71nj3xu
2024-05-20 00:17:36 INFO Agent received command: run
2024-05-20 00:17:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 00:17:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 00:17:41 INFO Running runs: ['s8krdrf3']
2024-05-20 00:19:22 INFO Cleaning up finished run: s8krdrf3
2024-05-20 00:19:23 INFO Agent received command: run
2024-05-20 00:19:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:19:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:19:28 INFO Running runs: ['w5tbhubw']
2024-05-20 00:21:08 INFO Cleaning up finished run: w5tbhubw
2024-05-20 00:21:09 INFO Agent received command: run
2024-05-20 00:21:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:21:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:21:14 INFO Running runs: ['z4wws7r7']
2024-05-20 00:22:50 INFO Cleaning up finished run: z4wws7r7
2024-05-20 00:22:50 INFO Agent received command: run
2024-05-20 00:22:50 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 00:22:50 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 00:22:55 INFO Running runs: ['unpao4fy']
2024-05-20 00:25:13 INFO Cleaning up finished run: unpao4fy
2024-05-20 00:25:15 INFO Agent received command: run
2024-05-20 00:25:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 00:25:15 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 00:25:20 INFO Running runs: ['ll50zi6g']
2024-05-20 00:27:27 INFO Cleaning up finished run: ll50zi6g
2024-05-20 00:27:28 INFO Agent received command: run
2024-05-20 00:27:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:27:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:27:33 INFO Running runs: ['uv9rqh3j']
2024-05-20 00:28:47 INFO Cleaning up finished run: uv9rqh3j
2024-05-20 00:28:48 INFO Agent received command: run
2024-05-20 00:28:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:28:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:28:53 INFO Running runs: ['tmzps1ni']
2024-05-20 00:30:23 INFO Cleaning up finished run: tmzps1ni
2024-05-20 00:30:23 INFO Agent received command: run
2024-05-20 00:30:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:30:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:30:28 INFO Running runs: ['zw0k70eb']
2024-05-20 00:33:49 INFO Cleaning up finished run: zw0k70eb
2024-05-20 00:33:50 INFO Agent received command: run
2024-05-20 00:33:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 00:33:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 00:33:56 INFO Running runs: ['suaj9gv6']
2024-05-20 00:36:13 INFO Cleaning up finished run: suaj9gv6
2024-05-20 00:36:14 INFO Agent received command: run
2024-05-20 00:36:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 00:36:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 00:36:19 INFO Running runs: ['v556a1a5']
2024-05-20 00:37:49 INFO Cleaning up finished run: v556a1a5
2024-05-20 00:37:49 INFO Agent received command: run
2024-05-20 00:37:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 00:37:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 00:37:54 INFO Running runs: ['ge0rxwxn']
2024-05-20 00:40:49 INFO Cleaning up finished run: ge0rxwxn
2024-05-20 00:40:50 INFO Agent received command: run
2024-05-20 00:40:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 00:40:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 00:40:55 INFO Running runs: ['jw6nv1xi']
2024-05-20 00:43:49 INFO Cleaning up finished run: jw6nv1xi
2024-05-20 00:43:50 INFO Agent received command: run
2024-05-20 00:43:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 00:43:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 00:43:55 INFO Running runs: ['wfevs64n']
2024-05-20 00:45:30 INFO Cleaning up finished run: wfevs64n
2024-05-20 00:45:31 INFO Agent received command: run
2024-05-20 00:45:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 00:45:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 00:45:36 INFO Running runs: ['100lb89n']
2024-05-20 00:47:06 INFO Cleaning up finished run: 100lb89n
2024-05-20 00:47:08 INFO Agent received command: run
2024-05-20 00:47:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 00:47:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 00:47:13 INFO Running runs: ['i1adg8vl']
2024-05-20 00:48:43 INFO Cleaning up finished run: i1adg8vl
2024-05-20 00:48:44 INFO Agent received command: run
2024-05-20 00:48:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: random
2024-05-20 00:48:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=random
2024-05-20 00:48:49 INFO Running runs: ['8z0b03kg']
2024-05-20 00:50:34 INFO Cleaning up finished run: 8z0b03kg
2024-05-20 00:50:35 INFO Agent received command: run
2024-05-20 00:50:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 00:50:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 00:50:40 INFO Running runs: ['625qt4p2']
2024-05-20 00:52:53 INFO Cleaning up finished run: 625qt4p2
2024-05-20 00:52:53 INFO Agent received command: run
2024-05-20 00:52:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 00:52:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 00:52:58 INFO Running runs: ['44khp2tq']
2024-05-20 00:54:34 INFO Cleaning up finished run: 44khp2tq
2024-05-20 00:54:56 INFO Agent received command: run
2024-05-20 00:54:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 00:54:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 00:55:01 INFO Running runs: ['xyee39qi']
2024-05-20 00:56:10 INFO Cleaning up finished run: xyee39qi
2024-05-20 00:56:11 INFO Agent received command: run
2024-05-20 00:56:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:56:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:56:16 INFO Running runs: ['9bi9w13e']
2024-05-20 00:57:30 INFO Cleaning up finished run: 9bi9w13e
2024-05-20 00:57:31 INFO Agent received command: run
2024-05-20 00:57:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 00:57:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 00:57:36 INFO Running runs: ['8bzfh36g']
2024-05-20 00:58:50 INFO Cleaning up finished run: 8bzfh36g
2024-05-20 00:58:51 INFO Agent received command: run
2024-05-20 00:58:51 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 00:58:51 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 00:58:56 INFO Running runs: ['oxbstnfo']
2024-05-20 01:01:19 INFO Cleaning up finished run: oxbstnfo
2024-05-20 01:01:20 INFO Agent received command: run
2024-05-20 01:01:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:01:20 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:01:25 INFO Running runs: ['i3sm8loc']
2024-05-20 01:03:27 INFO Cleaning up finished run: i3sm8loc
2024-05-20 01:03:28 INFO Agent received command: run
2024-05-20 01:03:28 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:03:28 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:03:33 INFO Running runs: ['lzbtskgp']
2024-05-20 01:04:52 INFO Cleaning up finished run: lzbtskgp
2024-05-20 01:05:17 INFO Agent received command: run
2024-05-20 01:05:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 01:05:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 01:05:22 INFO Running runs: ['t5ozfhzc']
2024-05-20 01:08:22 INFO Cleaning up finished run: t5ozfhzc
2024-05-20 01:08:23 INFO Agent received command: run
2024-05-20 01:08:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 01:08:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 01:08:28 INFO Running runs: ['bs8403yk']
2024-05-20 01:10:30 INFO Cleaning up finished run: bs8403yk
2024-05-20 01:10:31 INFO Agent received command: run
2024-05-20 01:10:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 01:10:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 01:10:36 INFO Running runs: ['0sv5c3yv']
2024-05-20 01:11:50 INFO Cleaning up finished run: 0sv5c3yv
2024-05-20 01:11:51 INFO Agent received command: run
2024-05-20 01:11:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 01:11:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 01:11:56 INFO Running runs: ['7kli710u']
2024-05-20 01:15:54 INFO Cleaning up finished run: 7kli710u
2024-05-20 01:15:55 INFO Agent received command: run
2024-05-20 01:15:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 01:15:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 01:16:00 INFO Running runs: ['e7r40mnj']
2024-05-20 01:19:00 INFO Cleaning up finished run: e7r40mnj
2024-05-20 01:19:01 INFO Agent received command: run
2024-05-20 01:19:01 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 01:19:01 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 01:19:06 INFO Running runs: ['iwo05j5q']
2024-05-20 01:21:40 INFO Cleaning up finished run: iwo05j5q
2024-05-20 01:21:41 INFO Agent received command: run
2024-05-20 01:21:41 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 01:21:41 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 01:21:46 INFO Running runs: ['lb7x93n3']
2024-05-20 01:23:15 INFO Cleaning up finished run: lb7x93n3
2024-05-20 01:23:16 INFO Agent received command: run
2024-05-20 01:23:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 01:23:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 01:23:21 INFO Running runs: ['jvkibryq']
2024-05-20 01:25:49 INFO Cleaning up finished run: jvkibryq
2024-05-20 01:25:50 INFO Agent received command: run
2024-05-20 01:25:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 01:25:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 01:25:55 INFO Running runs: ['05yzrrsj']
2024-05-20 01:27:30 INFO Cleaning up finished run: 05yzrrsj
2024-05-20 01:27:43 INFO Agent received command: run
2024-05-20 01:27:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 01:27:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 01:27:48 INFO Running runs: ['6ttca4nn']
2024-05-20 01:29:34 INFO Cleaning up finished run: 6ttca4nn
2024-05-20 01:29:35 INFO Agent received command: run
2024-05-20 01:29:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 01:29:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 01:29:40 INFO Running runs: ['4wdqp8ch']
2024-05-20 01:31:15 INFO Cleaning up finished run: 4wdqp8ch
2024-05-20 01:31:16 INFO Agent received command: run
2024-05-20 01:31:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 01:31:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 01:31:21 INFO Running runs: ['ynzgnpt0']
2024-05-20 01:33:01 INFO Cleaning up finished run: ynzgnpt0
2024-05-20 01:33:02 INFO Agent received command: run
2024-05-20 01:33:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 01:33:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 01:33:08 INFO Running runs: ['5xj75h93']
2024-05-20 01:34:16 INFO Cleaning up finished run: 5xj75h93
2024-05-20 01:34:17 INFO Agent received command: run
2024-05-20 01:34:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:34:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:34:22 INFO Running runs: ['z2eb05eb']
2024-05-20 01:35:16 INFO Cleaning up finished run: z2eb05eb
2024-05-20 01:35:17 INFO Agent received command: run
2024-05-20 01:35:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 01:35:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 01:35:22 INFO Running runs: ['k2spxyoq']
2024-05-20 01:37:35 INFO Cleaning up finished run: k2spxyoq
2024-05-20 01:37:36 INFO Agent received command: run
2024-05-20 01:37:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 01:37:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 01:37:41 INFO Running runs: ['hzpawngx']
2024-05-20 01:38:49 INFO Cleaning up finished run: hzpawngx
2024-05-20 01:38:51 INFO Agent received command: run
2024-05-20 01:38:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:38:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:38:56 INFO Running runs: ['gotuhi6o']
2024-05-20 01:39:54 INFO Cleaning up finished run: gotuhi6o
2024-05-20 01:39:55 INFO Agent received command: run
2024-05-20 01:39:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:39:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:40:00 INFO Running runs: ['g24heape']
2024-05-20 01:41:56 INFO Cleaning up finished run: g24heape
2024-05-20 01:41:57 INFO Agent received command: run
2024-05-20 01:41:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:41:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:42:02 INFO Running runs: ['pa1wtpn7']
2024-05-20 01:44:46 INFO Cleaning up finished run: pa1wtpn7
2024-05-20 01:44:46 INFO Agent received command: run
2024-05-20 01:44:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 01:44:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 01:44:51 INFO Running runs: ['pn2pcjkq']
2024-05-20 01:46:48 INFO Cleaning up finished run: pn2pcjkq
2024-05-20 01:46:49 INFO Agent received command: run
2024-05-20 01:46:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 01:46:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 01:46:54 INFO Running runs: ['lepauc6c']
2024-05-20 01:49:59 INFO Cleaning up finished run: lepauc6c
2024-05-20 01:50:00 INFO Agent received command: run
2024-05-20 01:50:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 01:50:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 01:50:05 INFO Running runs: ['mejkpku7']
2024-05-20 01:52:06 INFO Cleaning up finished run: mejkpku7
2024-05-20 01:52:07 INFO Agent received command: run
2024-05-20 01:52:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-20 01:52:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 01:52:12 INFO Running runs: ['1tgrk7cm']
2024-05-20 01:54:03 INFO Cleaning up finished run: 1tgrk7cm
2024-05-20 01:54:04 INFO Agent received command: run
2024-05-20 01:54:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: random
2024-05-20 01:54:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=random
2024-05-20 01:54:09 INFO Running runs: ['w78vncmd']
2024-05-20 01:56:05 INFO Cleaning up finished run: w78vncmd
2024-05-20 01:56:06 INFO Agent received command: run
2024-05-20 01:56:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 01:56:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 01:56:11 INFO Running runs: ['4w8lwodb']
2024-05-20 01:57:30 INFO Cleaning up finished run: 4w8lwodb
2024-05-20 01:57:31 INFO Agent received command: run
2024-05-20 01:57:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 01:57:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 01:57:36 INFO Running runs: ['4l1m2phi']
2024-05-20 01:59:11 INFO Cleaning up finished run: 4l1m2phi
2024-05-20 01:59:13 INFO Agent received command: run
2024-05-20 01:59:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 01:59:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 01:59:18 INFO Running runs: ['fezpivcl']
2024-05-20 02:00:37 INFO Cleaning up finished run: fezpivcl
2024-05-20 02:00:38 INFO Agent received command: run
2024-05-20 02:00:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 02:00:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 02:00:43 INFO Running runs: ['kqudm7ns']
2024-05-20 02:02:44 INFO Cleaning up finished run: kqudm7ns
2024-05-20 02:02:45 INFO Agent received command: run
2024-05-20 02:02:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 02:02:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 02:02:50 INFO Running runs: ['x5n66hhm']
2024-05-20 02:04:52 INFO Cleaning up finished run: x5n66hhm
2024-05-20 02:04:52 INFO Agent received command: run
2024-05-20 02:04:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 02:04:52 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 02:04:57 INFO Running runs: ['81m5ousb']
2024-05-20 02:06:59 INFO Cleaning up finished run: 81m5ousb
2024-05-20 02:07:00 INFO Agent received command: run
2024-05-20 02:07:00 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 02:07:00 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 02:07:05 INFO Running runs: ['paxjm2pp']
2024-05-20 02:09:44 INFO Cleaning up finished run: paxjm2pp
2024-05-20 02:09:45 INFO Agent received command: run
2024-05-20 02:09:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 02:09:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 02:09:50 INFO Running runs: ['osczgh9p']
2024-05-20 02:11:25 INFO Cleaning up finished run: osczgh9p
2024-05-20 02:11:25 INFO Agent received command: run
2024-05-20 02:11:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 02:11:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 02:11:30 INFO Running runs: ['5hyeusna']
2024-05-20 02:13:00 INFO Cleaning up finished run: 5hyeusna
2024-05-20 02:13:01 INFO Agent received command: run
2024-05-20 02:13:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 02:13:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 02:13:06 INFO Running runs: ['hqq2x5yl']
2024-05-20 02:15:14 INFO Cleaning up finished run: hqq2x5yl
2024-05-20 02:15:15 INFO Agent received command: run
2024-05-20 02:15:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 02:15:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 02:15:20 INFO Running runs: ['jael2ewt']
2024-05-20 02:16:39 INFO Cleaning up finished run: jael2ewt
2024-05-20 02:16:40 INFO Agent received command: run
2024-05-20 02:16:40 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 02:16:40 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 02:16:45 INFO Running runs: ['j0nm1op1']
2024-05-20 02:18:25 INFO Cleaning up finished run: j0nm1op1
2024-05-20 02:18:26 INFO Agent received command: run
2024-05-20 02:18:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 02:18:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 02:18:31 INFO Running runs: ['bad7yx3u']
2024-05-20 02:20:06 INFO Cleaning up finished run: bad7yx3u
2024-05-20 02:20:29 INFO Agent received command: run
2024-05-20 02:20:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 02:20:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 02:20:34 INFO Running runs: ['824smdv3']
2024-05-20 02:22:31 INFO Cleaning up finished run: 824smdv3
2024-05-20 02:22:32 INFO Agent received command: run
2024-05-20 02:22:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 02:22:32 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 02:22:37 INFO Running runs: ['jlqigfkk']
2024-05-20 02:23:45 INFO Cleaning up finished run: jlqigfkk
2024-05-20 02:23:46 INFO Agent received command: run
2024-05-20 02:23:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 02:23:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 02:23:51 INFO Running runs: ['ksvb2p23']
2024-05-20 02:25:53 INFO Cleaning up finished run: ksvb2p23
2024-05-20 02:25:54 INFO Agent received command: run
2024-05-20 02:25:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 02:25:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 02:25:59 INFO Running runs: ['sfaknewg']
2024-05-20 02:28:32 INFO Cleaning up finished run: sfaknewg
2024-05-20 02:28:33 INFO Agent received command: run
2024-05-20 02:28:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 02:28:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 02:28:38 INFO Running runs: ['2h0r7oeg']
2024-05-20 02:30:13 INFO Cleaning up finished run: 2h0r7oeg
2024-05-20 02:30:14 INFO Agent received command: run
2024-05-20 02:30:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 02:30:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 02:30:19 INFO Running runs: ['6q6s13t3']
2024-05-20 02:32:32 INFO Cleaning up finished run: 6q6s13t3
2024-05-20 02:32:33 INFO Agent received command: run
2024-05-20 02:32:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 02:32:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 02:32:38 INFO Running runs: ['n2ddwzkt']
2024-05-20 02:35:32 INFO Cleaning up finished run: n2ddwzkt
2024-05-20 02:35:37 INFO Agent received command: run
2024-05-20 02:35:37 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 02:35:37 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 02:35:42 INFO Running runs: ['x5cavsxd']
2024-05-20 02:37:11 INFO Cleaning up finished run: x5cavsxd
2024-05-20 02:37:12 INFO Agent received command: run
2024-05-20 02:37:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 02:37:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 02:37:17 INFO Running runs: ['zecfx5h3']
2024-05-20 02:38:47 INFO Cleaning up finished run: zecfx5h3
2024-05-20 02:38:48 INFO Agent received command: run
2024-05-20 02:38:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 02:38:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 02:38:53 INFO Running runs: ['9ydyunrm']
2024-05-20 02:40:02 INFO Cleaning up finished run: 9ydyunrm
2024-05-20 02:40:06 INFO Agent received command: run
2024-05-20 02:40:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 02:40:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 02:40:11 INFO Running runs: ['y1tlxjnd']
2024-05-20 02:42:28 INFO Cleaning up finished run: y1tlxjnd
2024-05-20 02:42:37 INFO Agent received command: run
2024-05-20 02:42:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 02:42:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 02:42:42 INFO Running runs: ['1fdr1lok']
2024-05-20 02:44:38 INFO Cleaning up finished run: 1fdr1lok
2024-05-20 02:44:39 INFO Agent received command: run
2024-05-20 02:44:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 02:44:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 02:44:44 INFO Running runs: ['hho7qjtp']
2024-05-20 02:47:33 INFO Cleaning up finished run: hho7qjtp
2024-05-20 02:47:34 INFO Agent received command: run
2024-05-20 02:47:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 02:47:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 02:47:39 INFO Running runs: ['8sadk9k0']
2024-05-20 02:49:35 INFO Cleaning up finished run: 8sadk9k0
2024-05-20 02:49:36 INFO Agent received command: run
2024-05-20 02:49:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 02:49:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 02:49:41 INFO Running runs: ['a9a24jjc']
2024-05-20 02:53:02 INFO Cleaning up finished run: a9a24jjc
2024-05-20 02:53:12 INFO Agent received command: run
2024-05-20 02:53:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 02:53:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 02:53:17 INFO Running runs: ['dgm78ybg']
2024-05-20 02:56:17 INFO Cleaning up finished run: dgm78ybg
2024-05-20 02:56:17 INFO Agent received command: run
2024-05-20 02:56:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 02:56:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 02:56:22 INFO Running runs: ['bwmxweyj']
2024-05-20 02:58:35 INFO Cleaning up finished run: bwmxweyj
2024-05-20 02:59:10 INFO Running runs: []
2024-05-20 02:59:11 INFO Agent received command: run
2024-05-20 02:59:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 02:59:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 02:59:16 INFO Running runs: ['74e0gmv3']
2024-05-20 03:01:39 INFO Cleaning up finished run: 74e0gmv3
2024-05-20 03:01:40 INFO Agent received command: run
2024-05-20 03:01:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 03:01:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 03:01:45 INFO Running runs: ['8twauack']
2024-05-20 03:04:07 INFO Cleaning up finished run: 8twauack
2024-05-20 03:04:08 INFO Agent received command: run
2024-05-20 03:04:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 03:04:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 03:04:13 INFO Running runs: ['sxy8x4rc']
2024-05-20 03:06:52 INFO Cleaning up finished run: sxy8x4rc
2024-05-20 03:06:53 INFO Agent received command: run
2024-05-20 03:06:53 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 03:06:53 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 03:06:58 INFO Running runs: ['u2w804w6']
2024-05-20 03:09:10 INFO Cleaning up finished run: u2w804w6
2024-05-20 03:09:11 INFO Agent received command: run
2024-05-20 03:09:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 03:09:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 03:09:16 INFO Running runs: ['tcdsjktu']
2024-05-20 03:11:02 INFO Cleaning up finished run: tcdsjktu
2024-05-20 03:11:02 INFO Agent received command: run
2024-05-20 03:11:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 03:11:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 03:11:07 INFO Running runs: ['p2six3ts']
2024-05-20 03:14:44 INFO Cleaning up finished run: p2six3ts
2024-05-20 03:14:45 INFO Agent received command: run
2024-05-20 03:14:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 03:14:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 03:14:50 INFO Running runs: ['h0qga32d']
2024-05-20 03:17:24 INFO Cleaning up finished run: h0qga32d
2024-05-20 03:17:29 INFO Agent received command: run
2024-05-20 03:17:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:17:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:17:34 INFO Running runs: ['pz98mont']
2024-05-20 03:18:53 INFO Cleaning up finished run: pz98mont
2024-05-20 03:18:54 INFO Agent received command: run
2024-05-20 03:18:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:18:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:18:59 INFO Running runs: ['zn5mmepu']
2024-05-20 03:21:06 INFO Cleaning up finished run: zn5mmepu
2024-05-20 03:21:07 INFO Agent received command: run
2024-05-20 03:21:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 03:21:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 03:21:12 INFO Running runs: ['qud3wcpy']
2024-05-20 03:22:52 INFO Cleaning up finished run: qud3wcpy
2024-05-20 03:22:53 INFO Agent received command: run
2024-05-20 03:22:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:22:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:22:58 INFO Running runs: ['219rifia']
2024-05-20 03:24:34 INFO Cleaning up finished run: 219rifia
2024-05-20 03:24:34 INFO Agent received command: run
2024-05-20 03:24:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 03:24:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 03:24:40 INFO Running runs: ['812ldohd']
2024-05-20 03:26:15 INFO Cleaning up finished run: 812ldohd
2024-05-20 03:26:18 INFO Agent received command: run
2024-05-20 03:26:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 03:26:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 03:26:23 INFO Running runs: ['pmewkntq']
2024-05-20 03:28:52 INFO Cleaning up finished run: pmewkntq
2024-05-20 03:28:53 INFO Agent received command: run
2024-05-20 03:28:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 03:28:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 03:28:58 INFO Running runs: ['bdp8va0i']
2024-05-20 03:30:33 INFO Cleaning up finished run: bdp8va0i
2024-05-20 03:30:42 INFO Agent received command: run
2024-05-20 03:30:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 03:30:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 03:30:47 INFO Running runs: ['adzl3kg1']
2024-05-20 03:31:56 INFO Cleaning up finished run: adzl3kg1
2024-05-20 03:31:57 INFO Agent received command: run
2024-05-20 03:31:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 03:31:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 03:32:02 INFO Running runs: ['3988h9nj']
2024-05-20 03:34:19 INFO Cleaning up finished run: 3988h9nj
2024-05-20 03:34:28 INFO Agent received command: run
2024-05-20 03:34:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:34:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:34:33 INFO Running runs: ['x20igid7']
2024-05-20 03:37:12 INFO Cleaning up finished run: x20igid7
2024-05-20 03:37:13 INFO Agent received command: run
2024-05-20 03:37:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 03:37:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 03:37:18 INFO Running runs: ['73xp51x9']
2024-05-20 03:39:30 INFO Cleaning up finished run: 73xp51x9
2024-05-20 03:39:31 INFO Agent received command: run
2024-05-20 03:39:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 03:39:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 03:39:36 INFO Running runs: ['ssmrjd1g']
2024-05-20 03:42:10 INFO Cleaning up finished run: ssmrjd1g
2024-05-20 03:42:10 INFO Agent received command: run
2024-05-20 03:42:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:42:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:42:15 INFO Running runs: ['1h50q7dj']
2024-05-20 03:44:33 INFO Cleaning up finished run: 1h50q7dj
2024-05-20 03:44:34 INFO Agent received command: run
2024-05-20 03:44:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 03:44:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 03:44:39 INFO Running runs: ['7aqgcq05']
2024-05-20 03:46:14 INFO Cleaning up finished run: 7aqgcq05
2024-05-20 03:46:28 INFO Agent received command: run
2024-05-20 03:46:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:46:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:46:33 INFO Running runs: ['u18n73h8']
2024-05-20 03:49:01 INFO Cleaning up finished run: u18n73h8
2024-05-20 03:49:02 INFO Agent received command: run
2024-05-20 03:49:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 03:49:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 03:49:07 INFO Running runs: ['27m7dft7']
2024-05-20 03:50:52 INFO Cleaning up finished run: 27m7dft7
2024-05-20 03:50:53 INFO Agent received command: run
2024-05-20 03:50:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 03:50:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 03:50:58 INFO Running runs: ['nrpwwgxy']
2024-05-20 03:52:17 INFO Cleaning up finished run: nrpwwgxy
2024-05-20 03:52:18 INFO Agent received command: run
2024-05-20 03:52:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 03:52:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 03:52:23 INFO Running runs: ['19cbfsj8']
2024-05-20 03:54:46 INFO Cleaning up finished run: 19cbfsj8
2024-05-20 03:54:53 INFO Agent received command: run
2024-05-20 03:54:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 03:54:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 03:54:58 INFO Running runs: ['3owcobqj']
2024-05-20 03:58:35 INFO Cleaning up finished run: 3owcobqj
2024-05-20 03:58:46 INFO Agent received command: run
2024-05-20 03:58:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-20 03:58:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 03:58:51 INFO Running runs: ['l3mko3pj']
2024-05-20 04:00:47 INFO Cleaning up finished run: l3mko3pj
2024-05-20 04:01:03 INFO Agent received command: run
2024-05-20 04:01:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 04:01:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 04:01:08 INFO Running runs: ['ccvs4ix7']
2024-05-20 04:03:20 INFO Cleaning up finished run: ccvs4ix7
2024-05-20 04:03:21 INFO Agent received command: run
2024-05-20 04:03:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 04:03:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 04:03:26 INFO Running runs: ['qaz482q8']
2024-05-20 04:06:21 INFO Cleaning up finished run: qaz482q8
2024-05-20 04:06:24 INFO Agent received command: run
2024-05-20 04:06:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 04:06:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 04:06:29 INFO Running runs: ['zq7lnxl5']
2024-05-20 04:08:52 INFO Cleaning up finished run: zq7lnxl5
2024-05-20 04:08:54 INFO Agent received command: run
2024-05-20 04:08:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:08:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:08:59 INFO Running runs: ['se2cc04v']
2024-05-20 04:11:01 INFO Cleaning up finished run: se2cc04v
2024-05-20 04:11:03 INFO Agent received command: run
2024-05-20 04:11:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:11:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:11:08 INFO Running runs: ['x2wo5j71']
2024-05-20 04:13:31 INFO Cleaning up finished run: x2wo5j71
2024-05-20 04:13:32 INFO Agent received command: run
2024-05-20 04:13:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 04:13:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 04:13:37 INFO Running runs: ['ckrbs41i']
2024-05-20 04:15:18 INFO Cleaning up finished run: ckrbs41i
2024-05-20 04:15:19 INFO Agent received command: run
2024-05-20 04:15:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:15:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:15:24 INFO Running runs: ['nq3hx6v7']
2024-05-20 04:16:43 INFO Cleaning up finished run: nq3hx6v7
2024-05-20 04:16:51 INFO Agent received command: run
2024-05-20 04:16:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:16:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 04:16:56 INFO Running runs: ['u4ui681a']
2024-05-20 04:19:03 INFO Cleaning up finished run: u4ui681a
2024-05-20 04:19:06 INFO Agent received command: run
2024-05-20 04:19:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 04:19:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 04:19:11 INFO Running runs: ['kpbdxbh2']
2024-05-20 04:21:50 INFO Cleaning up finished run: kpbdxbh2
2024-05-20 04:21:51 INFO Agent received command: run
2024-05-20 04:21:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:21:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 04:21:56 INFO Running runs: ['avhx4kk2']
2024-05-20 04:23:20 INFO Cleaning up finished run: avhx4kk2
2024-05-20 04:23:21 INFO Agent received command: run
2024-05-20 04:23:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 04:23:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 04:23:26 INFO Running runs: ['muauseri']
2024-05-20 04:25:33 INFO Cleaning up finished run: muauseri
2024-05-20 04:25:34 INFO Agent received command: run
2024-05-20 04:25:34 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 04:25:34 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 04:25:39 INFO Running runs: ['1k0qyprq']
2024-05-20 04:26:58 INFO Cleaning up finished run: 1k0qyprq
2024-05-20 04:26:59 INFO Agent received command: run
2024-05-20 04:26:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:26:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:27:04 INFO Running runs: ['xsqonfr7']
2024-05-20 04:28:18 INFO Cleaning up finished run: xsqonfr7
2024-05-20 04:28:19 INFO Agent received command: run
2024-05-20 04:28:19 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:28:19 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 04:28:24 INFO Running runs: ['sac39qm1']
2024-05-20 04:31:03 INFO Cleaning up finished run: sac39qm1
2024-05-20 04:31:04 INFO Agent received command: run
2024-05-20 04:31:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 04:31:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 04:31:09 INFO Running runs: ['spu65f75']
2024-05-20 04:32:23 INFO Cleaning up finished run: spu65f75
2024-05-20 04:32:25 INFO Agent received command: run
2024-05-20 04:32:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 04:32:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 04:32:30 INFO Running runs: ['6gdxt0f1']
2024-05-20 04:34:37 INFO Cleaning up finished run: 6gdxt0f1
2024-05-20 04:34:38 INFO Agent received command: run
2024-05-20 04:34:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 04:34:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 04:34:43 INFO Running runs: ['7s6xrqaq']
2024-05-20 04:36:08 INFO Cleaning up finished run: 7s6xrqaq
2024-05-20 04:36:13 INFO Agent received command: run
2024-05-20 04:36:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:36:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 04:36:18 INFO Running runs: ['b78zsktw']
2024-05-20 04:37:48 INFO Cleaning up finished run: b78zsktw
2024-05-20 04:37:50 INFO Agent received command: run
2024-05-20 04:37:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:37:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 04:37:55 INFO Running runs: ['j3n628q1']
2024-05-20 04:39:46 INFO Cleaning up finished run: j3n628q1
2024-05-20 04:39:46 INFO Agent received command: run
2024-05-20 04:39:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 04:39:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 04:39:51 INFO Running runs: ['rw0cqr7m']
2024-05-20 04:41:49 INFO Cleaning up finished run: rw0cqr7m
2024-05-20 04:41:50 INFO Agent received command: run
2024-05-20 04:41:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 04:41:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 04:41:55 INFO Running runs: ['jh18qc37']
2024-05-20 04:43:51 INFO Cleaning up finished run: jh18qc37
2024-05-20 04:44:27 INFO Running runs: []
2024-05-20 04:44:27 INFO Agent received command: run
2024-05-20 04:44:27 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:44:27 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:44:32 INFO Running runs: ['aknrbsx9']
2024-05-20 04:46:55 INFO Cleaning up finished run: aknrbsx9
2024-05-20 04:46:56 INFO Agent received command: run
2024-05-20 04:46:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: random
2024-05-20 04:46:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=random
2024-05-20 04:47:01 INFO Running runs: ['xi5d8lcu']
2024-05-20 04:49:03 INFO Cleaning up finished run: xi5d8lcu
2024-05-20 04:49:04 INFO Agent received command: run
2024-05-20 04:49:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 04:49:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 04:49:09 INFO Running runs: ['lfq9ogjh']
2024-05-20 04:50:33 INFO Cleaning up finished run: lfq9ogjh
2024-05-20 04:50:35 INFO Agent received command: run
2024-05-20 04:50:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 04:50:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 04:50:40 INFO Running runs: ['tjeq6aqe']
2024-05-20 04:52:41 INFO Cleaning up finished run: tjeq6aqe
2024-05-20 04:52:42 INFO Agent received command: run
2024-05-20 04:52:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 04:52:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 04:52:47 INFO Running runs: ['w2ky5vir']
2024-05-20 04:55:10 INFO Cleaning up finished run: w2ky5vir
2024-05-20 04:55:11 INFO Agent received command: run
2024-05-20 04:55:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 04:55:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 04:55:16 INFO Running runs: ['718s969p']
2024-05-20 04:57:50 INFO Cleaning up finished run: 718s969p
2024-05-20 04:57:51 INFO Agent received command: run
2024-05-20 04:57:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 04:57:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 04:57:56 INFO Running runs: ['ypaa9l56']
2024-05-20 05:00:40 INFO Cleaning up finished run: ypaa9l56
2024-05-20 05:00:41 INFO Agent received command: run
2024-05-20 05:00:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 05:00:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 05:00:46 INFO Running runs: ['oqwg2g15']
2024-05-20 05:02:42 INFO Cleaning up finished run: oqwg2g15
2024-05-20 05:02:43 INFO Agent received command: run
2024-05-20 05:02:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 05:02:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 05:02:48 INFO Running runs: ['1qzoa4p7']
2024-05-20 05:05:11 INFO Cleaning up finished run: 1qzoa4p7
2024-05-20 05:05:12 INFO Agent received command: run
2024-05-20 05:05:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:05:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:05:17 INFO Running runs: ['i16ufggq']
2024-05-20 05:06:31 INFO Cleaning up finished run: i16ufggq
2024-05-20 05:06:32 INFO Agent received command: run
2024-05-20 05:06:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:06:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:06:37 INFO Running runs: ['d7c61hbf']
2024-05-20 05:08:12 INFO Cleaning up finished run: d7c61hbf
2024-05-20 05:08:14 INFO Agent received command: run
2024-05-20 05:08:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:08:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:08:19 INFO Running runs: ['9d5os5yz']
2024-05-20 05:10:10 INFO Cleaning up finished run: 9d5os5yz
2024-05-20 05:10:11 INFO Agent received command: run
2024-05-20 05:10:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 05:10:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 05:10:16 INFO Running runs: ['tqsshhag']
2024-05-20 05:12:29 INFO Cleaning up finished run: tqsshhag
2024-05-20 05:12:52 INFO Agent received command: run
2024-05-20 05:12:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 05:12:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 05:12:57 INFO Running runs: ['6m721dmg']
2024-05-20 05:15:14 INFO Cleaning up finished run: 6m721dmg
2024-05-20 05:15:22 INFO Agent received command: run
2024-05-20 05:15:22 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:15:22 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:15:27 INFO Running runs: ['33n47iqp']
2024-05-20 05:16:41 INFO Cleaning up finished run: 33n47iqp
2024-05-20 05:16:42 INFO Agent received command: run
2024-05-20 05:16:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 05:16:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 05:16:47 INFO Running runs: ['07qcz4nm']
2024-05-20 05:17:56 INFO Cleaning up finished run: 07qcz4nm
2024-05-20 05:17:57 INFO Agent received command: run
2024-05-20 05:17:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 05:17:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 05:18:02 INFO Running runs: ['knlcblm7']
2024-05-20 05:19:42 INFO Cleaning up finished run: knlcblm7
2024-05-20 05:19:43 INFO Agent received command: run
2024-05-20 05:19:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 05:19:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 05:19:48 INFO Running runs: ['nw35rqww']
2024-05-20 05:22:11 INFO Cleaning up finished run: nw35rqww
2024-05-20 05:22:12 INFO Agent received command: run
2024-05-20 05:22:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 05:22:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 05:22:17 INFO Running runs: ['kueb65b5']
2024-05-20 05:23:41 INFO Cleaning up finished run: kueb65b5
2024-05-20 05:23:42 INFO Agent received command: run
2024-05-20 05:23:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:23:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:23:47 INFO Running runs: ['1ehv1ky1']
2024-05-20 05:26:15 INFO Cleaning up finished run: 1ehv1ky1
2024-05-20 05:26:16 INFO Agent received command: run
2024-05-20 05:26:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 05:26:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 05:26:21 INFO Running runs: ['bd7ms2lt']
2024-05-20 05:28:01 INFO Cleaning up finished run: bd7ms2lt
2024-05-20 05:28:02 INFO Agent received command: run
2024-05-20 05:28:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 05:28:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 05:28:07 INFO Running runs: ['wa2wsjrh']
2024-05-20 05:30:46 INFO Cleaning up finished run: wa2wsjrh
2024-05-20 05:30:46 INFO Agent received command: run
2024-05-20 05:30:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 05:30:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 05:30:51 INFO Running runs: ['f5p8qfbl']
2024-05-20 05:33:51 INFO Cleaning up finished run: f5p8qfbl
2024-05-20 05:33:52 INFO Agent received command: run
2024-05-20 05:33:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 05:33:52 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 05:33:57 INFO Running runs: ['igp8o9lw']
2024-05-20 05:36:04 INFO Cleaning up finished run: igp8o9lw
2024-05-20 05:36:05 INFO Agent received command: run
2024-05-20 05:36:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-20 05:36:05 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=random
2024-05-20 05:36:10 INFO Running runs: ['14rxm1eu']
2024-05-20 05:38:28 INFO Cleaning up finished run: 14rxm1eu
2024-05-20 05:38:28 INFO Agent received command: run
2024-05-20 05:38:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 05:38:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 05:38:33 INFO Running runs: ['cjgtboej']
2024-05-20 05:41:18 INFO Cleaning up finished run: cjgtboej
2024-05-20 05:41:19 INFO Agent received command: run
2024-05-20 05:41:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 05:41:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 05:41:24 INFO Running runs: ['tebzfd7f']
2024-05-20 05:43:52 INFO Cleaning up finished run: tebzfd7f
2024-05-20 05:43:53 INFO Agent received command: run
2024-05-20 05:43:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 05:43:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 05:43:58 INFO Running runs: ['d8mmmjqs']
2024-05-20 05:46:05 INFO Cleaning up finished run: d8mmmjqs
2024-05-20 05:46:06 INFO Agent received command: run
2024-05-20 05:46:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 05:46:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 05:46:11 INFO Running runs: ['2xfkeytw']
2024-05-20 05:48:13 INFO Cleaning up finished run: 2xfkeytw
2024-05-20 05:48:13 INFO Agent received command: run
2024-05-20 05:48:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 05:48:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 05:48:18 INFO Running runs: ['5250clpo']
2024-05-20 05:50:04 INFO Cleaning up finished run: 5250clpo
2024-05-20 05:50:05 INFO Agent received command: run
2024-05-20 05:50:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 05:50:05 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 05:50:10 INFO Running runs: ['2l8y2wp8']
2024-05-20 05:53:57 INFO Cleaning up finished run: 2l8y2wp8
2024-05-20 05:53:58 INFO Agent received command: run
2024-05-20 05:53:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 05:53:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 05:54:03 INFO Running runs: ['1w3evs5f']
2024-05-20 05:56:00 INFO Cleaning up finished run: 1w3evs5f
2024-05-20 05:56:01 INFO Agent received command: run
2024-05-20 05:56:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 05:56:01 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 05:56:06 INFO Running runs: ['k877e2o5']
2024-05-20 05:58:12 INFO Cleaning up finished run: k877e2o5
2024-05-20 05:58:13 INFO Agent received command: run
2024-05-20 05:58:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 05:58:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 05:58:18 INFO Running runs: ['v6zxwq2r']
2024-05-20 06:00:14 INFO Cleaning up finished run: v6zxwq2r
2024-05-20 06:00:24 INFO Agent received command: run
2024-05-20 06:00:24 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:00:24 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:00:29 INFO Running runs: ['r91bbxil']
2024-05-20 06:01:43 INFO Cleaning up finished run: r91bbxil
2024-05-20 06:01:45 INFO Agent received command: run
2024-05-20 06:01:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 06:01:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 06:01:50 INFO Running runs: ['0n8ak30z']
2024-05-20 06:03:15 INFO Cleaning up finished run: 0n8ak30z
2024-05-20 06:03:17 INFO Agent received command: run
2024-05-20 06:03:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 06:03:17 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 06:03:22 INFO Running runs: ['tjezlrtq']
2024-05-20 06:05:18 INFO Cleaning up finished run: tjezlrtq
2024-05-20 06:05:19 INFO Agent received command: run
2024-05-20 06:05:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 06:05:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 06:05:24 INFO Running runs: ['0p2xatia']
2024-05-20 06:07:21 INFO Cleaning up finished run: 0p2xatia
2024-05-20 06:07:22 INFO Agent received command: run
2024-05-20 06:07:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 06:07:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 06:07:27 INFO Running runs: ['zuy4lm74']
2024-05-20 06:08:41 INFO Cleaning up finished run: zuy4lm74
2024-05-20 06:08:41 INFO Agent received command: run
2024-05-20 06:08:41 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 06:08:41 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 06:08:46 INFO Running runs: ['q9ppp2xz']
2024-05-20 06:09:50 INFO Cleaning up finished run: q9ppp2xz
2024-05-20 06:10:14 INFO Agent received command: run
2024-05-20 06:10:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:10:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:10:19 INFO Running runs: ['1xpbgjmj']
2024-05-20 06:11:28 INFO Cleaning up finished run: 1xpbgjmj
2024-05-20 06:11:29 INFO Agent received command: run
2024-05-20 06:11:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 06:11:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 06:11:34 INFO Running runs: ['tl0kc9hy']
2024-05-20 06:13:52 INFO Cleaning up finished run: tl0kc9hy
2024-05-20 06:13:53 INFO Agent received command: run
2024-05-20 06:13:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 06:13:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 06:13:59 INFO Running runs: ['aai7t47w']
2024-05-20 06:16:11 INFO Cleaning up finished run: aai7t47w
2024-05-20 06:16:11 INFO Agent received command: run
2024-05-20 06:16:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-20 06:16:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 06:16:17 INFO Running runs: ['8x36x25l']
2024-05-20 06:17:46 INFO Cleaning up finished run: 8x36x25l
2024-05-20 06:17:57 INFO Agent received command: run
2024-05-20 06:17:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 06:17:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 06:18:02 INFO Running runs: ['mivop47t']
2024-05-20 06:21:02 INFO Cleaning up finished run: mivop47t
2024-05-20 06:21:28 INFO Agent received command: run
2024-05-20 06:21:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:21:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:21:33 INFO Running runs: ['50802k64']
2024-05-20 06:23:51 INFO Cleaning up finished run: 50802k64
2024-05-20 06:23:53 INFO Agent received command: run
2024-05-20 06:23:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 06:23:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 06:23:58 INFO Running runs: ['9it2u36g']
2024-05-20 06:26:21 INFO Cleaning up finished run: 9it2u36g
2024-05-20 06:26:22 INFO Agent received command: run
2024-05-20 06:26:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 06:26:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 06:26:27 INFO Running runs: ['y4nv3jav']
2024-05-20 06:28:13 INFO Cleaning up finished run: y4nv3jav
2024-05-20 06:28:14 INFO Agent received command: run
2024-05-20 06:28:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 06:28:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 06:28:19 INFO Running runs: ['gcquxnno']
2024-05-20 06:30:15 INFO Cleaning up finished run: gcquxnno
2024-05-20 06:30:16 INFO Agent received command: run
2024-05-20 06:30:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:30:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:30:21 INFO Running runs: ['jkpaclpl']
2024-05-20 06:32:28 INFO Cleaning up finished run: jkpaclpl
2024-05-20 06:32:29 INFO Agent received command: run
2024-05-20 06:32:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 06:32:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 06:32:34 INFO Running runs: ['le3b7rag']
2024-05-20 06:36:21 INFO Cleaning up finished run: le3b7rag
2024-05-20 06:36:22 INFO Agent received command: run
2024-05-20 06:36:22 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 06:36:22 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 06:36:27 INFO Running runs: ['pjwpku2n']
2024-05-20 06:39:32 INFO Cleaning up finished run: pjwpku2n
2024-05-20 06:39:33 INFO Agent received command: run
2024-05-20 06:39:33 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 06:39:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 06:39:38 INFO Running runs: ['6m2ndg0y']
2024-05-20 06:41:45 INFO Cleaning up finished run: 6m2ndg0y
2024-05-20 06:41:54 INFO Agent received command: run
2024-05-20 06:41:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:41:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:41:59 INFO Running runs: ['m2d6c5p6']
2024-05-20 06:43:55 INFO Cleaning up finished run: m2d6c5p6
2024-05-20 06:43:56 INFO Agent received command: run
2024-05-20 06:43:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 06:43:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 06:44:01 INFO Running runs: ['1o6bv2cq']
2024-05-20 06:46:03 INFO Cleaning up finished run: 1o6bv2cq
2024-05-20 06:46:15 INFO Agent received command: run
2024-05-20 06:46:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 06:46:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 06:46:20 INFO Running runs: ['hqj1l12g']
2024-05-20 06:48:11 INFO Cleaning up finished run: hqj1l12g
2024-05-20 06:48:12 INFO Agent received command: run
2024-05-20 06:48:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:48:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:48:17 INFO Running runs: ['xvaj57ip']
2024-05-20 06:51:06 INFO Cleaning up finished run: xvaj57ip
2024-05-20 06:51:07 INFO Agent received command: run
2024-05-20 06:51:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 06:51:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 06:51:12 INFO Running runs: ['91i3un60']
2024-05-20 06:53:09 INFO Cleaning up finished run: 91i3un60
2024-05-20 06:53:10 INFO Agent received command: run
2024-05-20 06:53:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 06:53:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 06:53:15 INFO Running runs: ['315i7dn8']
2024-05-20 06:55:11 INFO Cleaning up finished run: 315i7dn8
2024-05-20 06:55:12 INFO Agent received command: run
2024-05-20 06:55:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 06:55:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 06:55:17 INFO Running runs: ['uftbqcrx']
2024-05-20 06:57:19 INFO Cleaning up finished run: uftbqcrx
2024-05-20 06:57:19 INFO Agent received command: run
2024-05-20 06:57:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 06:57:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 06:57:24 INFO Running runs: ['tq3c1t82']
2024-05-20 06:59:21 INFO Cleaning up finished run: tq3c1t82
2024-05-20 06:59:22 INFO Agent received command: run
2024-05-20 06:59:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 06:59:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 06:59:27 INFO Running runs: ['jyjntm67']
2024-05-20 07:01:23 INFO Cleaning up finished run: jyjntm67
2024-05-20 07:01:25 INFO Agent received command: run
2024-05-20 07:01:25 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 07:01:25 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 07:01:30 INFO Running runs: ['9j0jsqyq']
2024-05-20 07:03:32 INFO Cleaning up finished run: 9j0jsqyq
2024-05-20 07:03:32 INFO Agent received command: run
2024-05-20 07:03:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 07:03:32 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 07:03:37 INFO Running runs: ['qmxsd1pg']
2024-05-20 07:07:41 INFO Cleaning up finished run: qmxsd1pg
2024-05-20 07:07:42 INFO Agent received command: run
2024-05-20 07:07:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 07:07:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 07:07:47 INFO Running runs: ['vksqolf5']
2024-05-20 07:12:01 INFO Cleaning up finished run: vksqolf5
2024-05-20 07:12:01 INFO Agent received command: run
2024-05-20 07:12:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 07:12:01 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 07:12:06 INFO Running runs: ['5kuy1pcy']
2024-05-20 07:13:31 INFO Cleaning up finished run: 5kuy1pcy
2024-05-20 07:13:32 INFO Agent received command: run
2024-05-20 07:13:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:13:32 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:13:37 INFO Running runs: ['guxj6k6s']
2024-05-20 07:15:28 INFO Cleaning up finished run: guxj6k6s
2024-05-20 07:15:29 INFO Agent received command: run
2024-05-20 07:15:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 07:15:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 07:15:34 INFO Running runs: ['sb4vnmug']
2024-05-20 07:18:23 INFO Cleaning up finished run: sb4vnmug
2024-05-20 07:18:24 INFO Agent received command: run
2024-05-20 07:18:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 07:18:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 07:18:29 INFO Running runs: ['y4t4mk8u']
2024-05-20 07:21:50 INFO Cleaning up finished run: y4t4mk8u
2024-05-20 07:21:51 INFO Agent received command: run
2024-05-20 07:21:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 07:21:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 07:21:56 INFO Running runs: ['eo1m1bw4']
2024-05-20 07:24:24 INFO Cleaning up finished run: eo1m1bw4
2024-05-20 07:24:25 INFO Agent received command: run
2024-05-20 07:24:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 07:24:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 07:24:30 INFO Running runs: ['jol6o1e5']
2024-05-20 07:26:58 INFO Cleaning up finished run: jol6o1e5
2024-05-20 07:27:00 INFO Agent received command: run
2024-05-20 07:27:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 07:27:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 07:27:05 INFO Running runs: ['1kixlglj']
2024-05-20 07:29:22 INFO Cleaning up finished run: 1kixlglj
2024-05-20 07:29:24 INFO Agent received command: run
2024-05-20 07:29:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 07:29:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 07:29:29 INFO Running runs: ['e8aslzko']
2024-05-20 07:31:31 INFO Cleaning up finished run: e8aslzko
2024-05-20 07:32:06 INFO Running runs: []
2024-05-20 07:32:07 INFO Agent received command: run
2024-05-20 07:32:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 07:32:07 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 07:32:12 INFO Running runs: ['tqqzsvok']
2024-05-20 07:33:47 INFO Cleaning up finished run: tqqzsvok
2024-05-20 07:33:48 INFO Agent received command: run
2024-05-20 07:33:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:33:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:33:53 INFO Running runs: ['osmh8b00']
2024-05-20 07:35:39 INFO Cleaning up finished run: osmh8b00
2024-05-20 07:36:04 INFO Agent received command: run
2024-05-20 07:36:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:36:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:36:09 INFO Running runs: ['ujs5cl9y']
2024-05-20 07:38:05 INFO Cleaning up finished run: ujs5cl9y
2024-05-20 07:38:18 INFO Agent received command: run
2024-05-20 07:38:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:38:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:38:23 INFO Running runs: ['hsugy0qj']
2024-05-20 07:39:42 INFO Cleaning up finished run: hsugy0qj
2024-05-20 07:39:43 INFO Agent received command: run
2024-05-20 07:39:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 07:39:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 07:39:48 INFO Running runs: ['p5ku2rhi']
2024-05-20 07:41:55 INFO Cleaning up finished run: p5ku2rhi
2024-05-20 07:42:17 INFO Agent received command: run
2024-05-20 07:42:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 07:42:17 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 07:42:22 INFO Running runs: ['9kbjj6zi']
2024-05-20 07:44:44 INFO Cleaning up finished run: 9kbjj6zi
2024-05-20 07:44:45 INFO Agent received command: run
2024-05-20 07:44:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 07:44:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 07:44:50 INFO Running runs: ['4p587oya']
2024-05-20 07:47:18 INFO Cleaning up finished run: 4p587oya
2024-05-20 07:47:25 INFO Agent received command: run
2024-05-20 07:47:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:47:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:47:30 INFO Running runs: ['ysfz7si2']
2024-05-20 07:49:58 INFO Cleaning up finished run: ysfz7si2
2024-05-20 07:49:59 INFO Agent received command: run
2024-05-20 07:49:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 07:49:59 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 07:50:04 INFO Running runs: ['vbj3x5x0']
2024-05-20 07:53:09 INFO Cleaning up finished run: vbj3x5x0
2024-05-20 07:53:10 INFO Agent received command: run
2024-05-20 07:53:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 07:53:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 07:53:15 INFO Running runs: ['59g624r4']
2024-05-20 07:54:56 INFO Cleaning up finished run: 59g624r4
2024-05-20 07:54:57 INFO Agent received command: run
2024-05-20 07:54:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 07:54:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 07:55:02 INFO Running runs: ['wsk3zw1u']
2024-05-20 07:57:51 INFO Cleaning up finished run: wsk3zw1u
2024-05-20 07:57:52 INFO Agent received command: run
2024-05-20 07:57:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 07:57:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 07:57:57 INFO Running runs: ['kx81clym']
2024-05-20 08:00:30 INFO Cleaning up finished run: kx81clym
2024-05-20 08:00:31 INFO Agent received command: run
2024-05-20 08:00:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 08:00:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 08:00:36 INFO Running runs: ['bhka5wnx']
2024-05-20 08:02:43 INFO Cleaning up finished run: bhka5wnx
2024-05-20 08:02:44 INFO Agent received command: run
2024-05-20 08:02:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 08:02:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 08:02:49 INFO Running runs: ['dqt01gdb']
2024-05-20 08:05:02 INFO Cleaning up finished run: dqt01gdb
2024-05-20 08:05:02 INFO Agent received command: run
2024-05-20 08:05:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-20 08:05:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=random
2024-05-20 08:05:07 INFO Running runs: ['gb4nuv1x']
2024-05-20 08:07:25 INFO Cleaning up finished run: gb4nuv1x
2024-05-20 08:07:26 INFO Agent received command: run
2024-05-20 08:07:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 08:07:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 08:07:31 INFO Running runs: ['ez1uxbo8']
2024-05-20 08:10:20 INFO Cleaning up finished run: ez1uxbo8
2024-05-20 08:10:22 INFO Agent received command: run
2024-05-20 08:10:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 08:10:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 08:10:27 INFO Running runs: ['9vt5gqtu']
2024-05-20 08:13:06 INFO Cleaning up finished run: 9vt5gqtu
2024-05-20 08:13:08 INFO Agent received command: run
2024-05-20 08:13:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 08:13:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 08:13:13 INFO Running runs: ['2vu0rjdm']
2024-05-20 08:16:50 INFO Cleaning up finished run: 2vu0rjdm
2024-05-20 08:16:52 INFO Agent received command: run
2024-05-20 08:16:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 08:16:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 08:16:57 INFO Running runs: ['izoglzcv']
2024-05-20 08:18:43 INFO Cleaning up finished run: izoglzcv
2024-05-20 08:18:44 INFO Agent received command: run
2024-05-20 08:18:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 08:18:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 08:18:49 INFO Running runs: ['mzmco8mw']
2024-05-20 08:20:19 INFO Cleaning up finished run: mzmco8mw
2024-05-20 08:20:20 INFO Agent received command: run
2024-05-20 08:20:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 08:20:20 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 08:20:25 INFO Running runs: ['ffgcqahz']
2024-05-20 08:22:16 INFO Cleaning up finished run: ffgcqahz
2024-05-20 08:22:17 INFO Agent received command: run
2024-05-20 08:22:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 08:22:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 08:22:22 INFO Running runs: ['vkzmkolv']
2024-05-20 08:23:36 INFO Cleaning up finished run: vkzmkolv
2024-05-20 08:23:37 INFO Agent received command: run
2024-05-20 08:23:37 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 08:23:37 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 08:23:42 INFO Running runs: ['hz3grgth']
2024-05-20 08:25:13 INFO Cleaning up finished run: hz3grgth
2024-05-20 08:25:13 INFO Agent received command: run
2024-05-20 08:25:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-20 08:25:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=random
2024-05-20 08:25:18 INFO Running runs: ['fjjaidu1']
2024-05-20 08:26:59 INFO Cleaning up finished run: fjjaidu1
2024-05-20 08:27:00 INFO Agent received command: run
2024-05-20 08:27:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 08:27:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 08:27:05 INFO Running runs: ['5stof34o']
2024-05-20 08:29:07 INFO Cleaning up finished run: 5stof34o
2024-05-20 08:29:08 INFO Agent received command: run
2024-05-20 08:29:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 08:29:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 08:29:13 INFO Running runs: ['p9yoli6t']
2024-05-20 08:31:10 INFO Cleaning up finished run: p9yoli6t
2024-05-20 08:31:13 INFO Agent received command: run
2024-05-20 08:31:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: random
2024-05-20 08:31:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=random
2024-05-20 08:31:18 INFO Running runs: ['1v5zydw3']
2024-05-20 08:32:33 INFO Cleaning up finished run: 1v5zydw3
2024-05-20 08:32:43 INFO Agent received command: run
2024-05-20 08:32:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: random
2024-05-20 08:32:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=random
2024-05-20 08:32:48 INFO Running runs: ['clytxkr4']
2024-05-20 08:34:13 INFO Cleaning up finished run: clytxkr4
2024-05-20 08:34:14 INFO Agent received command: run
2024-05-20 08:34:14 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 08:34:14 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 08:34:19 INFO Running runs: ['741ot7hp']
2024-05-20 08:36:00 INFO Cleaning up finished run: 741ot7hp
2024-05-20 08:36:01 INFO Agent received command: run
2024-05-20 08:36:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-20 08:36:01 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-20 08:36:06 INFO Running runs: ['aud4j2s6']
2024-05-20 08:38:34 INFO Cleaning up finished run: aud4j2s6
2024-05-20 08:38:35 INFO Agent received command: run
2024-05-20 08:38:35 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 08:38:35 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 08:38:40 INFO Running runs: ['owsr0no9']
2024-05-20 08:39:33 INFO Cleaning up finished run: owsr0no9
2024-05-20 08:39:34 INFO Agent received command: run
2024-05-20 08:39:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 08:39:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 08:39:39 INFO Running runs: ['o9zsiv6k']
2024-05-20 08:41:20 INFO Cleaning up finished run: o9zsiv6k
2024-05-20 08:41:21 INFO Agent received command: run
2024-05-20 08:41:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 08:41:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 08:41:26 INFO Running runs: ['pnfku0id']
2024-05-20 08:43:23 INFO Cleaning up finished run: pnfku0id
2024-05-20 08:43:24 INFO Agent received command: run
2024-05-20 08:43:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: random
2024-05-20 08:43:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=random
2024-05-20 08:43:29 INFO Running runs: ['qlzg38w4']
2024-05-20 08:44:43 INFO Cleaning up finished run: qlzg38w4
2024-05-20 08:44:44 INFO Agent received command: run
2024-05-20 08:44:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 08:44:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 08:44:49 INFO Running runs: ['28mplzeq']
2024-05-20 08:47:17 INFO Cleaning up finished run: 28mplzeq
2024-05-20 08:47:19 INFO Agent received command: run
2024-05-20 08:47:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 08:47:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 08:47:24 INFO Running runs: ['ywvyzgzm']
2024-05-20 08:49:26 INFO Cleaning up finished run: ywvyzgzm
2024-05-20 08:50:01 INFO Running runs: []
2024-05-20 08:50:02 INFO Agent received command: run
2024-05-20 08:50:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 08:50:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 08:50:07 INFO Running runs: ['3m6q4oxp']
2024-05-20 08:52:09 INFO Cleaning up finished run: 3m6q4oxp
2024-05-20 08:52:12 INFO Agent received command: run
2024-05-20 08:52:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 08:52:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 08:52:17 INFO Running runs: ['fwh8rmuk']
2024-05-20 08:55:18 INFO Cleaning up finished run: fwh8rmuk
2024-05-20 08:55:31 INFO Agent received command: run
2024-05-20 08:55:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 08:55:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 08:55:36 INFO Running runs: ['1zk5rf5z']
2024-05-20 08:58:36 INFO Cleaning up finished run: 1zk5rf5z
2024-05-20 08:58:37 INFO Agent received command: run
2024-05-20 08:58:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 08:58:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 08:58:42 INFO Running runs: ['w9znna61']
2024-05-20 09:00:56 INFO Cleaning up finished run: w9znna61
2024-05-20 09:00:57 INFO Agent received command: run
2024-05-20 09:00:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 09:00:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 09:01:02 INFO Running runs: ['sx4um0z4']
2024-05-20 09:02:21 INFO Cleaning up finished run: sx4um0z4
2024-05-20 09:02:23 INFO Agent received command: run
2024-05-20 09:02:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 09:02:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 09:02:28 INFO Running runs: ['ajdbsab5']
2024-05-20 09:05:33 INFO Cleaning up finished run: ajdbsab5
2024-05-20 09:05:34 INFO Agent received command: run
2024-05-20 09:05:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 09:05:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 09:05:39 INFO Running runs: ['khuztic7']
2024-05-20 09:08:08 INFO Cleaning up finished run: khuztic7
2024-05-20 09:08:09 INFO Agent received command: run
2024-05-20 09:08:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 09:08:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 09:08:14 INFO Running runs: ['m85x4umu']
2024-05-20 09:10:27 INFO Cleaning up finished run: m85x4umu
2024-05-20 09:10:27 INFO Agent received command: run
2024-05-20 09:10:27 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 09:10:27 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 09:10:32 INFO Running runs: ['gnd1g3e8']
2024-05-20 09:11:41 INFO Cleaning up finished run: gnd1g3e8
2024-05-20 09:11:42 INFO Agent received command: run
2024-05-20 09:11:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 09:11:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 09:11:47 INFO Running runs: ['oieal5o1']
2024-05-20 09:13:33 INFO Cleaning up finished run: oieal5o1
2024-05-20 09:13:35 INFO Agent received command: run
2024-05-20 09:13:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 09:13:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 09:13:40 INFO Running runs: ['7bi77ejb']
2024-05-20 09:15:47 INFO Cleaning up finished run: 7bi77ejb
2024-05-20 09:15:48 INFO Agent received command: run
2024-05-20 09:15:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 09:15:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 09:15:53 INFO Running runs: ['vs2oidi0']
2024-05-20 09:17:29 INFO Cleaning up finished run: vs2oidi0
2024-05-20 09:17:35 INFO Agent received command: run
2024-05-20 09:17:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 09:17:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 09:17:40 INFO Running runs: ['esx4tjso']
2024-05-20 09:20:03 INFO Cleaning up finished run: esx4tjso
2024-05-20 09:20:04 INFO Agent received command: run
2024-05-20 09:20:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 09:20:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 09:20:09 INFO Running runs: ['2qc7zewf']
2024-05-20 09:24:08 INFO Cleaning up finished run: 2qc7zewf
2024-05-20 09:24:09 INFO Agent received command: run
2024-05-20 09:24:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 09:24:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 09:24:14 INFO Running runs: ['s665343q']
2024-05-20 09:26:27 INFO Cleaning up finished run: s665343q
2024-05-20 09:26:28 INFO Agent received command: run
2024-05-20 09:26:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 09:26:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 09:26:33 INFO Running runs: ['b68w64mz']
2024-05-20 09:29:54 INFO Cleaning up finished run: b68w64mz
2024-05-20 09:29:55 INFO Agent received command: run
2024-05-20 09:29:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 09:29:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 09:30:00 INFO Running runs: ['ml3tg7v3']
2024-05-20 09:32:18 INFO Cleaning up finished run: ml3tg7v3
2024-05-20 09:32:19 INFO Agent received command: run
2024-05-20 09:32:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 09:32:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 09:32:24 INFO Running runs: ['sj5a56i9']
2024-05-20 09:34:21 INFO Cleaning up finished run: sj5a56i9
2024-05-20 09:34:56 INFO Running runs: []
2024-05-20 09:35:20 INFO Agent received command: run
2024-05-20 09:35:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 09:35:20 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 09:35:25 INFO Running runs: ['2h8tnam5']
2024-05-20 09:38:36 INFO Cleaning up finished run: 2h8tnam5
2024-05-20 09:38:37 INFO Agent received command: run
2024-05-20 09:38:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 09:38:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 09:38:42 INFO Running runs: ['v3jfe06u']
2024-05-20 09:41:37 INFO Cleaning up finished run: v3jfe06u
2024-05-20 09:41:38 INFO Agent received command: run
2024-05-20 09:41:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 09:41:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 09:41:44 INFO Running runs: ['2z75mejh']
2024-05-20 09:43:24 INFO Cleaning up finished run: 2z75mejh
2024-05-20 09:43:25 INFO Agent received command: run
2024-05-20 09:43:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 09:43:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 09:43:30 INFO Running runs: ['xzwuuwv5']
2024-05-20 09:44:55 INFO Cleaning up finished run: xzwuuwv5
2024-05-20 09:44:56 INFO Agent received command: run
2024-05-20 09:44:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 09:44:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 09:45:01 INFO Running runs: ['3jvrkyr0']
2024-05-20 09:46:42 INFO Cleaning up finished run: 3jvrkyr0
2024-05-20 09:46:43 INFO Agent received command: run
2024-05-20 09:46:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 09:46:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 09:46:48 INFO Running runs: ['tuaioxzj']
2024-05-20 09:48:23 INFO Cleaning up finished run: tuaioxzj
2024-05-20 09:48:24 INFO Agent received command: run
2024-05-20 09:48:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 09:48:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 09:48:29 INFO Running runs: ['a5si0crk']
2024-05-20 09:50:53 INFO Cleaning up finished run: a5si0crk
2024-05-20 09:50:54 INFO Agent received command: run
2024-05-20 09:50:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 09:50:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 09:50:59 INFO Running runs: ['fmkhzflx']
2024-05-20 09:52:29 INFO Cleaning up finished run: fmkhzflx
2024-05-20 09:52:30 INFO Agent received command: run
2024-05-20 09:52:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 09:52:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 09:52:35 INFO Running runs: ['b4z2t2u2']
2024-05-20 09:54:16 INFO Cleaning up finished run: b4z2t2u2
2024-05-20 09:54:17 INFO Agent received command: run
2024-05-20 09:54:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 09:54:17 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 09:54:22 INFO Running runs: ['zzo3vt99']
2024-05-20 09:55:15 INFO Cleaning up finished run: zzo3vt99
2024-05-20 09:55:16 INFO Agent received command: run
2024-05-20 09:55:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 09:55:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 09:55:21 INFO Running runs: ['b6kjxftw']
2024-05-20 09:58:00 INFO Cleaning up finished run: b6kjxftw
2024-05-20 09:58:01 INFO Agent received command: run
2024-05-20 09:58:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 09:58:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 09:58:06 INFO Running runs: ['kufdsfkv']
2024-05-20 09:59:15 INFO Cleaning up finished run: kufdsfkv
2024-05-20 09:59:16 INFO Agent received command: run
2024-05-20 09:59:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 09:59:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 09:59:21 INFO Running runs: ['ln8yj2f6']
2024-05-20 10:03:10 INFO Cleaning up finished run: ln8yj2f6
2024-05-20 10:03:10 INFO Agent received command: run
2024-05-20 10:03:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 10:03:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 10:03:15 INFO Running runs: ['ojxgi0cy']
2024-05-20 10:06:16 INFO Cleaning up finished run: ojxgi0cy
2024-05-20 10:06:17 INFO Agent received command: run
2024-05-20 10:06:17 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 10:06:17 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 10:06:22 INFO Running runs: ['jmwqcf79']
2024-05-20 10:09:12 INFO Cleaning up finished run: jmwqcf79
2024-05-20 10:09:13 INFO Agent received command: run
2024-05-20 10:09:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 10:09:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 10:09:18 INFO Running runs: ['wfaardtk']
2024-05-20 10:11:31 INFO Cleaning up finished run: wfaardtk
2024-05-20 10:11:32 INFO Agent received command: run
2024-05-20 10:11:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 10:11:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 10:11:37 INFO Running runs: ['o8flrzun']
2024-05-20 10:14:28 INFO Cleaning up finished run: o8flrzun
2024-05-20 10:14:28 INFO Agent received command: run
2024-05-20 10:14:28 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: random
2024-05-20 10:14:28 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=random
2024-05-20 10:14:33 INFO Running runs: ['pbarsecg']
2024-05-20 10:16:09 INFO Cleaning up finished run: pbarsecg
2024-05-20 10:16:10 INFO Agent received command: run
2024-05-20 10:16:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 10:16:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 10:16:15 INFO Running runs: ['a6i5gy1i']
2024-05-20 10:18:06 INFO Cleaning up finished run: a6i5gy1i
2024-05-20 10:18:08 INFO Agent received command: run
2024-05-20 10:18:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 10:18:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 10:18:13 INFO Running runs: ['yagpv4d8']
2024-05-20 10:20:04 INFO Cleaning up finished run: yagpv4d8
2024-05-20 10:20:06 INFO Agent received command: run
2024-05-20 10:20:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 10:20:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 10:20:11 INFO Running runs: ['n02tq0zw']
2024-05-20 10:22:55 INFO Cleaning up finished run: n02tq0zw
2024-05-20 10:23:10 INFO Agent received command: run
2024-05-20 10:23:10 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 10:23:10 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 10:23:15 INFO Running runs: ['9gkzr6rb']
2024-05-20 10:25:54 INFO Cleaning up finished run: 9gkzr6rb
2024-05-20 10:25:55 INFO Agent received command: run
2024-05-20 10:25:55 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 10:25:55 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 10:26:00 INFO Running runs: ['hoviu7at']
2024-05-20 10:27:41 INFO Cleaning up finished run: hoviu7at
2024-05-20 10:27:42 INFO Agent received command: run
2024-05-20 10:27:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 10:27:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 10:27:47 INFO Running runs: ['hxcb8g4e']
2024-05-20 10:29:28 INFO Cleaning up finished run: hxcb8g4e
2024-05-20 10:29:29 INFO Agent received command: run
2024-05-20 10:29:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 10:29:29 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 10:29:34 INFO Running runs: ['ihb2tg9i']
2024-05-20 10:31:42 INFO Cleaning up finished run: ihb2tg9i
2024-05-20 10:31:42 INFO Agent received command: run
2024-05-20 10:31:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 10:31:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 10:31:47 INFO Running runs: ['pl79lz3b']
2024-05-20 10:34:43 INFO Cleaning up finished run: pl79lz3b
2024-05-20 10:34:44 INFO Agent received command: run
2024-05-20 10:34:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 10:34:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 10:34:49 INFO Running runs: ['alb5wv2r']
2024-05-20 10:37:17 INFO Cleaning up finished run: alb5wv2r
2024-05-20 10:37:18 INFO Agent received command: run
2024-05-20 10:37:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 10:37:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 10:37:23 INFO Running runs: ['nkytdsct']
2024-05-20 10:41:12 INFO Cleaning up finished run: nkytdsct
2024-05-20 10:41:13 INFO Agent received command: run
2024-05-20 10:41:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 10:41:13 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 10:41:18 INFO Running runs: ['n6l6bmit']
2024-05-20 10:44:13 INFO Cleaning up finished run: n6l6bmit
2024-05-20 10:44:14 INFO Agent received command: run
2024-05-20 10:44:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 10:44:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 10:44:19 INFO Running runs: ['f2ieo5ij']
2024-05-20 10:47:04 INFO Cleaning up finished run: f2ieo5ij
2024-05-20 10:47:26 ERROR 500 response executing GraphQL.
2024-05-20 10:47:26 ERROR {"errors":[{"message":"Post \"http://anaconda2.default.svc.cluster.local/search\": read tcp 10.52.90.2:60000-\u003e10.55.247.53:80: read: connection reset by peer","path":["agentHeartbeat"]}],"data":{"agentHeartbeat":null}}
2024-05-20 10:47:28 INFO Agent received command: run
2024-05-20 10:47:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 10:47:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 10:47:33 INFO Running runs: ['pqelezua']
2024-05-20 10:48:53 INFO Cleaning up finished run: pqelezua
2024-05-20 10:48:54 INFO Agent received command: run
2024-05-20 10:48:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 10:48:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 10:48:59 INFO Running runs: ['hxcx0bs1']
2024-05-20 10:50:34 INFO Cleaning up finished run: hxcx0bs1
2024-05-20 10:50:36 INFO Agent received command: run
2024-05-20 10:50:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 10:50:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 10:50:41 INFO Running runs: ['7pxizq6u']
2024-05-20 10:52:32 INFO Cleaning up finished run: 7pxizq6u
2024-05-20 10:52:39 INFO Agent received command: run
2024-05-20 10:52:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 10:52:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 10:52:44 INFO Running runs: ['goi61iim']
2024-05-20 10:55:29 INFO Cleaning up finished run: goi61iim
2024-05-20 10:55:37 INFO Agent received command: run
2024-05-20 10:55:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 10:55:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 10:55:42 INFO Running runs: ['56t5h9dk']
2024-05-20 10:58:38 INFO Cleaning up finished run: 56t5h9dk
2024-05-20 10:58:38 INFO Agent received command: run
2024-05-20 10:58:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 10:58:38 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 10:58:43 INFO Running runs: ['1tunuhyw']
2024-05-20 11:00:51 INFO Cleaning up finished run: 1tunuhyw
2024-05-20 11:00:56 INFO Agent received command: run
2024-05-20 11:00:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 11:00:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 11:01:01 INFO Running runs: ['ik5s3g8x']
2024-05-20 11:03:03 INFO Cleaning up finished run: ik5s3g8x
2024-05-20 11:03:04 INFO Agent received command: run
2024-05-20 11:03:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 11:03:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 11:03:09 INFO Running runs: ['m3urxbl6']
2024-05-20 11:04:55 INFO Cleaning up finished run: m3urxbl6
2024-05-20 11:04:57 INFO Agent received command: run
2024-05-20 11:04:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 11:04:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 11:05:02 INFO Running runs: ['t5yg22m6']
2024-05-20 11:07:09 INFO Cleaning up finished run: t5yg22m6
2024-05-20 11:07:10 INFO Agent received command: run
2024-05-20 11:07:10 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 11:07:10 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 11:07:15 INFO Running runs: ['a25bezsz']
2024-05-20 11:09:23 INFO Cleaning up finished run: a25bezsz
2024-05-20 11:09:23 INFO Agent received command: run
2024-05-20 11:09:23 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 11:09:23 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 11:09:28 INFO Running runs: ['5vq59sww']
2024-05-20 11:13:01 INFO Cleaning up finished run: 5vq59sww
2024-05-20 11:13:02 INFO Agent received command: run
2024-05-20 11:13:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:13:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:13:07 INFO Running runs: ['gl6cj6jd']
2024-05-20 11:15:20 INFO Cleaning up finished run: gl6cj6jd
2024-05-20 11:15:21 INFO Agent received command: run
2024-05-20 11:15:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 11:15:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 11:15:26 INFO Running runs: ['jtfqsxja']
2024-05-20 11:18:10 INFO Cleaning up finished run: jtfqsxja
2024-05-20 11:18:11 INFO Agent received command: run
2024-05-20 11:18:11 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 11:18:11 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 11:18:16 INFO Running runs: ['9hthnuv2']
2024-05-20 11:20:13 INFO Cleaning up finished run: 9hthnuv2
2024-05-20 11:20:14 INFO Agent received command: run
2024-05-20 11:20:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-20 11:20:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=random
2024-05-20 11:20:20 INFO Running runs: ['xe6v2hy6']
2024-05-20 11:22:06 INFO Cleaning up finished run: xe6v2hy6
2024-05-20 11:22:06 INFO Agent received command: run
2024-05-20 11:22:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 11:22:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 11:22:11 INFO Running runs: ['6jqvybjz']
2024-05-20 11:23:26 INFO Cleaning up finished run: 6jqvybjz
2024-05-20 11:23:27 INFO Agent received command: run
2024-05-20 11:23:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 11:23:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 11:23:32 INFO Running runs: ['eomztuj3']
2024-05-20 11:25:07 INFO Cleaning up finished run: eomztuj3
2024-05-20 11:25:08 INFO Agent received command: run
2024-05-20 11:25:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 11:25:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 11:25:13 INFO Running runs: ['207s0qoc']
2024-05-20 11:26:38 INFO Cleaning up finished run: 207s0qoc
2024-05-20 11:26:39 INFO Agent received command: run
2024-05-20 11:26:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 11:26:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 11:26:44 INFO Running runs: ['rs8izvrb']
2024-05-20 11:28:40 INFO Cleaning up finished run: rs8izvrb
2024-05-20 11:28:41 INFO Agent received command: run
2024-05-20 11:28:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:28:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:28:46 INFO Running runs: ['1zxdoxeu']
2024-05-20 11:30:00 INFO Cleaning up finished run: 1zxdoxeu
2024-05-20 11:30:08 INFO Agent received command: run
2024-05-20 11:30:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 11:30:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 11:30:13 INFO Running runs: ['1r6nv69q']
2024-05-20 11:33:50 INFO Cleaning up finished run: 1r6nv69q
2024-05-20 11:33:52 INFO Agent received command: run
2024-05-20 11:33:52 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 11:33:52 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 11:33:57 INFO Running runs: ['u5ds3ndc']
2024-05-20 11:35:43 INFO Cleaning up finished run: u5ds3ndc
2024-05-20 11:35:43 INFO Agent received command: run
2024-05-20 11:35:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 11:35:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 11:35:48 INFO Running runs: ['r9eifi2e']
2024-05-20 11:38:17 INFO Cleaning up finished run: r9eifi2e
2024-05-20 11:38:18 INFO Agent received command: run
2024-05-20 11:38:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 11:38:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 11:38:23 INFO Running runs: ['76ky5jf9']
2024-05-20 11:40:19 INFO Cleaning up finished run: 76ky5jf9
2024-05-20 11:40:20 INFO Agent received command: run
2024-05-20 11:40:20 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 11:40:20 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 11:40:25 INFO Running runs: ['p3jbabp6']
2024-05-20 11:42:22 INFO Cleaning up finished run: p3jbabp6
2024-05-20 11:42:23 INFO Agent received command: run
2024-05-20 11:42:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 11:42:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 11:42:28 INFO Running runs: ['q1mph7xv']
2024-05-20 11:44:30 INFO Cleaning up finished run: q1mph7xv
2024-05-20 11:44:31 INFO Agent received command: run
2024-05-20 11:44:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 11:44:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 11:44:36 INFO Running runs: ['8s40neas']
2024-05-20 11:45:50 INFO Cleaning up finished run: 8s40neas
2024-05-20 11:46:12 INFO Agent received command: run
2024-05-20 11:46:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:46:12 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:46:17 INFO Running runs: ['vfrna30b']
2024-05-20 11:48:09 INFO Cleaning up finished run: vfrna30b
2024-05-20 11:48:10 INFO Agent received command: run
2024-05-20 11:48:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 11:48:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 11:48:15 INFO Running runs: ['65or34dr']
2024-05-20 11:49:40 INFO Cleaning up finished run: 65or34dr
2024-05-20 11:49:41 INFO Agent received command: run
2024-05-20 11:49:41 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 11:49:41 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 11:49:46 INFO Running runs: ['74pltbr4']
2024-05-20 11:50:39 INFO Cleaning up finished run: 74pltbr4
2024-05-20 11:50:40 INFO Agent received command: run
2024-05-20 11:50:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 11:50:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 11:50:45 INFO Running runs: ['fwvqwtus']
2024-05-20 11:52:09 INFO Cleaning up finished run: fwvqwtus
2024-05-20 11:52:10 INFO Agent received command: run
2024-05-20 11:52:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:52:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:52:15 INFO Running runs: ['n7lnogqr']
2024-05-20 11:54:49 INFO Cleaning up finished run: n7lnogqr
2024-05-20 11:54:50 INFO Agent received command: run
2024-05-20 11:54:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 11:54:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 11:54:55 INFO Running runs: ['0lv609cx']
2024-05-20 11:56:52 INFO Cleaning up finished run: 0lv609cx
2024-05-20 11:57:03 INFO Agent received command: run
2024-05-20 11:57:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:57:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:57:08 INFO Running runs: ['sipyiuom']
2024-05-20 11:58:38 INFO Cleaning up finished run: sipyiuom
2024-05-20 11:58:39 INFO Agent received command: run
2024-05-20 11:58:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 11:58:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 11:58:44 INFO Running runs: ['bkt2ovqo']
2024-05-20 11:59:47 INFO Cleaning up finished run: bkt2ovqo
2024-05-20 11:59:48 INFO Agent received command: run
2024-05-20 11:59:48 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 11:59:48 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 11:59:53 INFO Running runs: ['fi3ll2sv']
2024-05-20 12:02:22 INFO Cleaning up finished run: fi3ll2sv
2024-05-20 12:02:23 INFO Agent received command: run
2024-05-20 12:02:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 12:02:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 12:02:28 INFO Running runs: ['tr1anu4v']
2024-05-20 12:06:02 INFO Cleaning up finished run: tr1anu4v
2024-05-20 12:06:03 INFO Agent received command: run
2024-05-20 12:06:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 12:06:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 12:06:08 INFO Running runs: ['jmvzv6rj']
2024-05-20 12:09:34 INFO Cleaning up finished run: jmvzv6rj
2024-05-20 12:09:35 INFO Agent received command: run
2024-05-20 12:09:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 12:09:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 12:09:40 INFO Running runs: ['0ghqwxgz']
2024-05-20 12:12:19 INFO Cleaning up finished run: 0ghqwxgz
2024-05-20 12:12:21 INFO Agent received command: run
2024-05-20 12:12:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 12:12:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 12:12:26 INFO Running runs: ['clwpoekn']
2024-05-20 12:14:06 INFO Cleaning up finished run: clwpoekn
2024-05-20 12:14:08 INFO Agent received command: run
2024-05-20 12:14:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 12:14:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 12:14:13 INFO Running runs: ['skxqbvuc']
2024-05-20 12:15:16 INFO Cleaning up finished run: skxqbvuc
2024-05-20 12:15:17 INFO Agent received command: run
2024-05-20 12:15:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 12:15:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 12:15:22 INFO Running runs: ['z5zt12r6']
2024-05-20 12:18:17 INFO Cleaning up finished run: z5zt12r6
2024-05-20 12:18:18 INFO Agent received command: run
2024-05-20 12:18:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 12:18:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 12:18:23 INFO Running runs: ['5wbbr5nu']
2024-05-20 12:21:34 INFO Cleaning up finished run: 5wbbr5nu
2024-05-20 12:21:36 INFO Agent received command: run
2024-05-20 12:21:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-20 12:21:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 12:21:41 INFO Running runs: ['4z55kzwd']
2024-05-20 12:23:49 INFO Cleaning up finished run: 4z55kzwd
2024-05-20 12:23:50 INFO Agent received command: run
2024-05-20 12:23:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: random
2024-05-20 12:23:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=random
2024-05-20 12:23:55 INFO Running runs: ['gc2ohioz']
2024-05-20 12:26:55 INFO Cleaning up finished run: gc2ohioz
2024-05-20 12:27:14 INFO Agent received command: run
2024-05-20 12:27:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 12:27:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 12:27:19 INFO Running runs: ['6gwlllha']
2024-05-20 12:29:32 INFO Cleaning up finished run: 6gwlllha
2024-05-20 12:29:33 INFO Agent received command: run
2024-05-20 12:29:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 12:29:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 12:29:38 INFO Running runs: ['ugy52rim']
2024-05-20 12:31:29 INFO Cleaning up finished run: ugy52rim
2024-05-20 12:31:30 INFO Agent received command: run
2024-05-20 12:31:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 12:31:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 12:31:35 INFO Running runs: ['mbep2d8b']
2024-05-20 12:34:03 INFO Cleaning up finished run: mbep2d8b
2024-05-20 12:34:04 INFO Agent received command: run
2024-05-20 12:34:04 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 12:34:04 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 12:34:09 INFO Running runs: ['sa3siy3d']
2024-05-20 12:35:50 INFO Cleaning up finished run: sa3siy3d
2024-05-20 12:35:51 INFO Agent received command: run
2024-05-20 12:35:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 12:35:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 12:35:56 INFO Running runs: ['f27zwaro']
2024-05-20 12:38:29 INFO Cleaning up finished run: f27zwaro
2024-05-20 12:38:30 INFO Agent received command: run
2024-05-20 12:38:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 12:38:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 12:38:35 INFO Running runs: ['c5asenp3']
2024-05-20 12:39:55 INFO Cleaning up finished run: c5asenp3
2024-05-20 12:39:56 INFO Agent received command: run
2024-05-20 12:39:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 12:39:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 12:40:01 INFO Running runs: ['ht16u3vz']
2024-05-20 12:42:04 INFO Cleaning up finished run: ht16u3vz
2024-05-20 12:42:04 INFO Agent received command: run
2024-05-20 12:42:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 12:42:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 12:42:09 INFO Running runs: ['62jspmfe']
2024-05-20 12:44:43 INFO Cleaning up finished run: 62jspmfe
2024-05-20 12:44:56 INFO Agent received command: run
2024-05-20 12:44:56 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 12:44:56 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 12:45:01 INFO Running runs: ['fv3qr7tr']
2024-05-20 12:46:42 INFO Cleaning up finished run: fv3qr7tr
2024-05-20 12:46:42 INFO Agent received command: run
2024-05-20 12:46:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 12:46:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 12:46:47 INFO Running runs: ['zaud21je']
2024-05-20 12:49:54 INFO Cleaning up finished run: zaud21je
2024-05-20 12:49:54 INFO Agent received command: run
2024-05-20 12:49:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 12:49:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 12:49:59 INFO Running runs: ['5pjcllvs']
2024-05-20 12:52:07 INFO Cleaning up finished run: 5pjcllvs
2024-05-20 12:52:10 INFO Agent received command: run
2024-05-20 12:52:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 12:52:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 12:52:15 INFO Running runs: ['seoduy0p']
2024-05-20 12:54:33 INFO Cleaning up finished run: seoduy0p
2024-05-20 12:54:34 INFO Agent received command: run
2024-05-20 12:54:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 12:54:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 12:54:39 INFO Running runs: ['c5vg49ad']
2024-05-20 12:55:53 INFO Cleaning up finished run: c5vg49ad
2024-05-20 12:55:55 INFO Agent received command: run
2024-05-20 12:55:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 12:55:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 12:56:00 INFO Running runs: ['ibd4ohmr']
2024-05-20 12:59:16 INFO Cleaning up finished run: ibd4ohmr
2024-05-20 12:59:17 INFO Agent received command: run
2024-05-20 12:59:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 12:59:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 12:59:22 INFO Running runs: ['7i2cdwx5']
2024-05-20 13:01:45 INFO Cleaning up finished run: 7i2cdwx5
2024-05-20 13:02:03 INFO Agent received command: run
2024-05-20 13:02:03 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 13:02:03 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 13:02:08 INFO Running runs: ['hwvmmcv8']
2024-05-20 13:04:16 INFO Cleaning up finished run: hwvmmcv8
2024-05-20 13:04:17 INFO Agent received command: run
2024-05-20 13:04:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 13:04:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 13:04:22 INFO Running runs: ['lb0nisxp']
2024-05-20 13:07:06 INFO Cleaning up finished run: lb0nisxp
2024-05-20 13:07:36 INFO Agent received command: run
2024-05-20 13:07:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 13:07:36 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 13:07:41 INFO Running runs: ['uagphh7r']
2024-05-20 13:10:57 INFO Cleaning up finished run: uagphh7r
2024-05-20 13:10:58 INFO Agent received command: run
2024-05-20 13:10:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 13:10:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 13:11:03 INFO Running runs: ['wjmn4gm0']
2024-05-20 13:13:10 INFO Cleaning up finished run: wjmn4gm0
2024-05-20 13:13:11 INFO Agent received command: run
2024-05-20 13:13:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 13:13:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 13:13:16 INFO Running runs: ['fbkh5gxz']
2024-05-20 13:16:00 INFO Cleaning up finished run: fbkh5gxz
2024-05-20 13:16:01 INFO Agent received command: run
2024-05-20 13:16:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:16:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:16:06 INFO Running runs: ['7iixs2s3']
2024-05-20 13:17:25 INFO Cleaning up finished run: 7iixs2s3
2024-05-20 13:17:27 INFO Agent received command: run
2024-05-20 13:17:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:17:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:17:32 INFO Running runs: ['743r901m']
2024-05-20 13:20:05 INFO Cleaning up finished run: 743r901m
2024-05-20 13:20:10 INFO Agent received command: run
2024-05-20 13:20:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 13:20:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 13:20:15 INFO Running runs: ['2iani5ka']
2024-05-20 13:23:05 INFO Cleaning up finished run: 2iani5ka
2024-05-20 13:23:06 INFO Agent received command: run
2024-05-20 13:23:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 13:23:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 13:23:11 INFO Running runs: ['px05j6px']
2024-05-20 13:26:00 INFO Cleaning up finished run: px05j6px
2024-05-20 13:26:24 INFO Agent received command: run
2024-05-20 13:26:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 13:26:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 13:26:29 INFO Running runs: ['v6osg3mg']
2024-05-20 13:27:53 INFO Cleaning up finished run: v6osg3mg
2024-05-20 13:28:08 INFO Agent received command: run
2024-05-20 13:28:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 13:28:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 13:28:13 INFO Running runs: ['4248ju2o']
2024-05-20 13:29:27 INFO Cleaning up finished run: 4248ju2o
2024-05-20 13:29:28 INFO Agent received command: run
2024-05-20 13:29:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 13:29:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 13:29:33 INFO Running runs: ['red00wb5']
2024-05-20 13:31:08 INFO Cleaning up finished run: red00wb5
2024-05-20 13:31:09 INFO Agent received command: run
2024-05-20 13:31:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:31:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:31:14 INFO Running runs: ['lhaps2ha']
2024-05-20 13:32:34 INFO Cleaning up finished run: lhaps2ha
2024-05-20 13:32:35 INFO Agent received command: run
2024-05-20 13:32:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:32:35 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:32:40 INFO Running runs: ['rqce3xs4']
2024-05-20 13:34:47 INFO Cleaning up finished run: rqce3xs4
2024-05-20 13:34:51 INFO Agent received command: run
2024-05-20 13:34:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 13:34:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 13:34:56 INFO Running runs: ['eppmbh72']
2024-05-20 13:37:30 INFO Cleaning up finished run: eppmbh72
2024-05-20 13:37:31 INFO Agent received command: run
2024-05-20 13:37:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:37:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:37:36 INFO Running runs: ['f2ul8aby']
2024-05-20 13:39:11 INFO Cleaning up finished run: f2ul8aby
2024-05-20 13:39:12 INFO Agent received command: run
2024-05-20 13:39:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 13:39:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 13:39:17 INFO Running runs: ['jo9amjl0']
2024-05-20 13:40:42 INFO Cleaning up finished run: jo9amjl0
2024-05-20 13:40:43 INFO Agent received command: run
2024-05-20 13:40:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 13:40:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 13:40:48 INFO Running runs: ['xqfconue']
2024-05-20 13:42:18 INFO Cleaning up finished run: xqfconue
2024-05-20 13:42:19 INFO Agent received command: run
2024-05-20 13:42:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:42:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:42:24 INFO Running runs: ['asm69vbu']
2024-05-20 13:45:29 INFO Cleaning up finished run: asm69vbu
2024-05-20 13:45:30 INFO Agent received command: run
2024-05-20 13:45:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 13:45:30 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 13:45:35 INFO Running runs: ['1t2xnabi']
2024-05-20 13:46:54 INFO Cleaning up finished run: 1t2xnabi
2024-05-20 13:47:30 INFO Running runs: []
2024-05-20 13:47:55 INFO Agent received command: run
2024-05-20 13:47:55 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 13:47:55 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 13:48:00 INFO Running runs: ['tk66jbcp']
2024-05-20 13:50:28 INFO Cleaning up finished run: tk66jbcp
2024-05-20 13:50:29 INFO Agent received command: run
2024-05-20 13:50:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:50:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:50:34 INFO Running runs: ['n88tb6yk']
2024-05-20 13:53:02 INFO Cleaning up finished run: n88tb6yk
2024-05-20 13:53:03 INFO Agent received command: run
2024-05-20 13:53:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:53:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:53:08 INFO Running runs: ['qyjnyp4k']
2024-05-20 13:56:14 INFO Cleaning up finished run: qyjnyp4k
2024-05-20 13:56:15 INFO Agent received command: run
2024-05-20 13:56:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 13:56:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 13:56:20 INFO Running runs: ['erfkh4c8']
2024-05-20 13:58:22 INFO Cleaning up finished run: erfkh4c8
2024-05-20 13:58:23 INFO Agent received command: run
2024-05-20 13:58:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 13:58:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 13:58:28 INFO Running runs: ['erhrqwnf']
2024-05-20 14:01:01 INFO Cleaning up finished run: erhrqwnf
2024-05-20 14:01:02 INFO Agent received command: run
2024-05-20 14:01:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 14:01:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 14:01:07 INFO Running runs: ['ew1l7ba8']
2024-05-20 14:02:27 INFO Cleaning up finished run: ew1l7ba8
2024-05-20 14:02:28 INFO Agent received command: run
2024-05-20 14:02:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 14:02:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 14:02:33 INFO Running runs: ['tl2uy82z']
2024-05-20 14:04:50 INFO Cleaning up finished run: tl2uy82z
2024-05-20 14:04:52 INFO Agent received command: run
2024-05-20 14:04:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 14:04:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 14:04:57 INFO Running runs: ['xpr70hef']
2024-05-20 14:06:37 INFO Cleaning up finished run: xpr70hef
2024-05-20 14:06:49 INFO Agent received command: run
2024-05-20 14:06:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 14:06:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 14:06:54 INFO Running runs: ['ipvf3010']
2024-05-20 14:08:19 INFO Cleaning up finished run: ipvf3010
2024-05-20 14:08:19 INFO Agent received command: run
2024-05-20 14:08:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 14:08:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 14:08:24 INFO Running runs: ['amrhf9g1']
2024-05-20 14:10:48 INFO Cleaning up finished run: amrhf9g1
2024-05-20 14:11:23 INFO Running runs: []
2024-05-20 14:11:24 INFO Agent received command: run
2024-05-20 14:11:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 14:11:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 14:11:29 INFO Running runs: ['4q8uv35m']
2024-05-20 14:15:28 INFO Cleaning up finished run: 4q8uv35m
2024-05-20 14:15:29 INFO Agent received command: run
2024-05-20 14:15:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 14:15:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 14:15:34 INFO Running runs: ['gj4o2ztp']
2024-05-20 14:17:20 INFO Cleaning up finished run: gj4o2ztp
2024-05-20 14:17:20 INFO Agent received command: run
2024-05-20 14:17:20 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 14:17:20 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 14:17:25 INFO Running runs: ['jap1yp87']
2024-05-20 14:19:43 INFO Cleaning up finished run: jap1yp87
2024-05-20 14:19:44 INFO Agent received command: run
2024-05-20 14:19:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 14:19:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 14:19:49 INFO Running runs: ['q4e46oqe']
2024-05-20 14:22:50 INFO Cleaning up finished run: q4e46oqe
2024-05-20 14:22:51 INFO Agent received command: run
2024-05-20 14:22:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 14:22:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 14:22:56 INFO Running runs: ['k8lapwcq']
2024-05-20 14:25:24 INFO Cleaning up finished run: k8lapwcq
2024-05-20 14:25:25 INFO Agent received command: run
2024-05-20 14:25:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 14:25:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 14:25:30 INFO Running runs: ['kyybxfgx']
2024-05-20 14:27:37 INFO Cleaning up finished run: kyybxfgx
2024-05-20 14:27:38 INFO Agent received command: run
2024-05-20 14:27:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: random
2024-05-20 14:27:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=random
2024-05-20 14:27:43 INFO Running runs: ['4nhjd1bj']
2024-05-20 14:31:00 INFO Cleaning up finished run: 4nhjd1bj
2024-05-20 14:31:00 INFO Agent received command: run
2024-05-20 14:31:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 14:31:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 14:31:05 INFO Running runs: ['kx8psgpq']
2024-05-20 14:33:34 INFO Cleaning up finished run: kx8psgpq
2024-05-20 14:33:35 INFO Agent received command: run
2024-05-20 14:33:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 14:33:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 14:33:40 INFO Running runs: ['ahnd1bng']
2024-05-20 14:36:30 INFO Cleaning up finished run: ahnd1bng
2024-05-20 14:36:30 INFO Agent received command: run
2024-05-20 14:36:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 14:36:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 14:36:35 INFO Running runs: ['wpa3ysiw']
2024-05-20 14:37:39 INFO Cleaning up finished run: wpa3ysiw
2024-05-20 14:37:40 INFO Agent received command: run
2024-05-20 14:37:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 14:37:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 14:37:45 INFO Running runs: ['w651h72l']
2024-05-20 14:39:31 INFO Cleaning up finished run: w651h72l
2024-05-20 14:39:32 INFO Agent received command: run
2024-05-20 14:39:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 14:39:32 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 14:39:37 INFO Running runs: ['d7brdg51']
2024-05-20 14:41:55 INFO Cleaning up finished run: d7brdg51
2024-05-20 14:41:56 INFO Agent received command: run
2024-05-20 14:41:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 14:41:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 14:42:01 INFO Running runs: ['kyr568f5']
2024-05-20 14:44:51 INFO Cleaning up finished run: kyr568f5
2024-05-20 14:44:54 INFO Agent received command: run
2024-05-20 14:44:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 14:44:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 14:44:59 INFO Running runs: ['ap9ta32y']
2024-05-20 14:46:07 INFO Cleaning up finished run: ap9ta32y
2024-05-20 14:46:43 INFO Running runs: []
2024-05-20 14:46:44 INFO Agent received command: run
2024-05-20 14:46:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 14:46:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 14:46:49 INFO Running runs: ['e9206y3b']
2024-05-20 14:48:13 INFO Cleaning up finished run: e9206y3b
2024-05-20 14:48:14 INFO Agent received command: run
2024-05-20 14:48:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 14:48:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 14:48:19 INFO Running runs: ['cped49kx']
2024-05-20 14:52:44 INFO Cleaning up finished run: cped49kx
2024-05-20 14:52:45 INFO Agent received command: run
2024-05-20 14:52:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 14:52:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 14:52:50 INFO Running runs: ['6496bt5t']
2024-05-20 14:55:08 INFO Cleaning up finished run: 6496bt5t
2024-05-20 14:55:09 INFO Agent received command: run
2024-05-20 14:55:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 14:55:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 14:55:14 INFO Running runs: ['u1x0fycd']
2024-05-20 14:57:32 INFO Cleaning up finished run: u1x0fycd
2024-05-20 14:57:33 INFO Agent received command: run
2024-05-20 14:57:33 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 14:57:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 14:57:38 INFO Running runs: ['pxwa70yg']
2024-05-20 14:59:30 INFO Cleaning up finished run: pxwa70yg
2024-05-20 14:59:31 INFO Agent received command: run
2024-05-20 14:59:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 14:59:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 14:59:36 INFO Running runs: ['orqcza8p']
2024-05-20 15:01:27 INFO Cleaning up finished run: orqcza8p
2024-05-20 15:01:28 INFO Agent received command: run
2024-05-20 15:01:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:01:28 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:01:33 INFO Running runs: ['rinp3xvd']
2024-05-20 15:03:40 INFO Cleaning up finished run: rinp3xvd
2024-05-20 15:03:43 INFO Agent received command: run
2024-05-20 15:03:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 15:03:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 15:03:48 INFO Running runs: ['lygzx83d']
2024-05-20 15:05:56 INFO Cleaning up finished run: lygzx83d
2024-05-20 15:05:57 INFO Agent received command: run
2024-05-20 15:05:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 15:05:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 15:06:02 INFO Running runs: ['41s9pgmu']
2024-05-20 15:06:49 INFO Cleaning up finished run: 41s9pgmu
2024-05-20 15:06:50 INFO Agent received command: run
2024-05-20 15:06:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 15:06:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 15:06:55 INFO Running runs: ['ntjungg7']
2024-05-20 15:08:20 INFO Cleaning up finished run: ntjungg7
2024-05-20 15:08:21 INFO Agent received command: run
2024-05-20 15:08:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 15:08:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 15:08:26 INFO Running runs: ['7acohovi']
2024-05-20 15:12:46 INFO Cleaning up finished run: 7acohovi
2024-05-20 15:12:47 INFO Agent received command: run
2024-05-20 15:12:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 15:12:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 15:12:52 INFO Running runs: ['767xy7l1']
2024-05-20 15:15:04 INFO Cleaning up finished run: 767xy7l1
2024-05-20 15:15:05 INFO Agent received command: run
2024-05-20 15:15:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 15:15:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-20 15:15:10 INFO Running runs: ['wqlbjoyn']
2024-05-20 15:16:56 INFO Cleaning up finished run: wqlbjoyn
2024-05-20 15:16:57 INFO Agent received command: run
2024-05-20 15:16:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:16:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:17:02 INFO Running runs: ['khuo00d8']
2024-05-20 15:18:06 INFO Cleaning up finished run: khuo00d8
2024-05-20 15:18:09 INFO Agent received command: run
2024-05-20 15:18:09 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 15:18:09 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 15:18:14 INFO Running runs: ['xotdhyir']
2024-05-20 15:20:58 INFO Cleaning up finished run: xotdhyir
2024-05-20 15:20:59 INFO Agent received command: run
2024-05-20 15:20:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:20:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:21:04 INFO Running runs: ['p08khbak']
2024-05-20 15:23:22 INFO Cleaning up finished run: p08khbak
2024-05-20 15:23:22 INFO Agent received command: run
2024-05-20 15:23:22 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 15:23:22 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 15:23:27 INFO Running runs: ['41m1bfi7']
2024-05-20 15:24:26 INFO Cleaning up finished run: 41m1bfi7
2024-05-20 15:24:27 INFO Agent received command: run
2024-05-20 15:24:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:24:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:24:32 INFO Running runs: ['g8f3e0dw']
2024-05-20 15:26:34 INFO Cleaning up finished run: g8f3e0dw
2024-05-20 15:26:35 INFO Agent received command: run
2024-05-20 15:26:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 15:26:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 15:26:40 INFO Running runs: ['c0cob7i4']
2024-05-20 15:30:43 INFO Cleaning up finished run: c0cob7i4
2024-05-20 15:30:44 INFO Agent received command: run
2024-05-20 15:30:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 15:30:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 15:30:50 INFO Running runs: ['n8ckp0qr']
2024-05-20 15:34:22 INFO Cleaning up finished run: n8ckp0qr
2024-05-20 15:34:23 INFO Agent received command: run
2024-05-20 15:34:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 15:34:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 15:34:28 INFO Running runs: ['mfz3n04r']
2024-05-20 15:37:28 INFO Cleaning up finished run: mfz3n04r
2024-05-20 15:37:36 INFO Agent received command: run
2024-05-20 15:37:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 15:37:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 15:37:41 INFO Running runs: ['pfjgoqw2']
2024-05-20 15:40:31 INFO Cleaning up finished run: pfjgoqw2
2024-05-20 15:40:31 INFO Agent received command: run
2024-05-20 15:40:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:40:31 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:40:36 INFO Running runs: ['7zzve19t']
2024-05-20 15:42:44 INFO Cleaning up finished run: 7zzve19t
2024-05-20 15:42:44 INFO Agent received command: run
2024-05-20 15:42:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 15:42:44 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 15:42:49 INFO Running runs: ['i4kxxcym']
2024-05-20 15:45:28 INFO Cleaning up finished run: i4kxxcym
2024-05-20 15:45:29 INFO Agent received command: run
2024-05-20 15:45:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 15:45:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 15:45:34 INFO Running runs: ['iff4xiig']
2024-05-20 15:47:36 INFO Cleaning up finished run: iff4xiig
2024-05-20 15:47:37 INFO Agent received command: run
2024-05-20 15:47:37 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 15:47:37 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 15:47:42 INFO Running runs: ['mo9vdwy2']
2024-05-20 15:48:51 INFO Cleaning up finished run: mo9vdwy2
2024-05-20 15:48:53 INFO Agent received command: run
2024-05-20 15:48:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 15:48:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-20 15:48:58 INFO Running runs: ['phywq9y5']
2024-05-20 15:50:07 INFO Cleaning up finished run: phywq9y5
2024-05-20 15:50:08 INFO Agent received command: run
2024-05-20 15:50:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 15:50:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 15:50:13 INFO Running runs: ['95eocup9']
2024-05-20 15:54:16 INFO Cleaning up finished run: 95eocup9
2024-05-20 15:54:17 INFO Agent received command: run
2024-05-20 15:54:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 15:54:17 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 15:54:22 INFO Running runs: ['k1hfbf2d']
2024-05-20 15:56:24 INFO Cleaning up finished run: k1hfbf2d
2024-05-20 15:56:26 INFO Agent received command: run
2024-05-20 15:56:26 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 15:56:26 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 15:56:31 INFO Running runs: ['0rnw5fey']
2024-05-20 15:58:22 INFO Cleaning up finished run: 0rnw5fey
2024-05-20 15:58:23 INFO Agent received command: run
2024-05-20 15:58:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 15:58:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-20 15:58:28 INFO Running runs: ['g835xynn']
2024-05-20 15:59:58 INFO Cleaning up finished run: g835xynn
2024-05-20 16:00:00 INFO Agent received command: run
2024-05-20 16:00:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 16:00:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 16:00:05 INFO Running runs: ['2ixeh6rs']
2024-05-20 16:01:57 INFO Cleaning up finished run: 2ixeh6rs
2024-05-20 16:01:58 INFO Agent received command: run
2024-05-20 16:01:58 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 16:01:58 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 16:02:03 INFO Running runs: ['3wntl18f']
2024-05-20 16:04:05 INFO Cleaning up finished run: 3wntl18f
2024-05-20 16:04:06 INFO Agent received command: run
2024-05-20 16:04:06 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 16:04:06 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 16:04:11 INFO Running runs: ['hcc7tiww']
2024-05-20 16:05:30 INFO Cleaning up finished run: hcc7tiww
2024-05-20 16:05:31 INFO Agent received command: run
2024-05-20 16:05:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 16:05:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 16:05:36 INFO Running runs: ['7r2why9j']
2024-05-20 16:07:33 INFO Cleaning up finished run: 7r2why9j
2024-05-20 16:07:34 INFO Agent received command: run
2024-05-20 16:07:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 16:07:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 16:07:39 INFO Running runs: ['pok6chrz']
2024-05-20 16:09:04 INFO Cleaning up finished run: pok6chrz
2024-05-20 16:09:05 INFO Agent received command: run
2024-05-20 16:09:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 16:09:05 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 16:09:10 INFO Running runs: ['2bcvktwx']
2024-05-20 16:11:01 INFO Cleaning up finished run: 2bcvktwx
2024-05-20 16:11:11 INFO Agent received command: run
2024-05-20 16:11:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 16:11:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 16:11:16 INFO Running runs: ['s1y18721']
2024-05-20 16:13:25 INFO Cleaning up finished run: s1y18721
2024-05-20 16:13:26 INFO Agent received command: run
2024-05-20 16:13:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 16:13:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 16:13:31 INFO Running runs: ['vk1xok16']
2024-05-20 16:15:28 INFO Cleaning up finished run: vk1xok16
2024-05-20 16:15:29 INFO Agent received command: run
2024-05-20 16:15:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 16:15:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 16:15:34 INFO Running runs: ['dvfc9wub']
2024-05-20 16:17:46 INFO Cleaning up finished run: dvfc9wub
2024-05-20 16:18:16 INFO Agent received command: run
2024-05-20 16:18:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 16:18:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 16:18:21 INFO Running runs: ['q0141cr9']
2024-05-20 16:20:39 INFO Cleaning up finished run: q0141cr9
2024-05-20 16:20:40 INFO Agent received command: run
2024-05-20 16:20:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 16:20:40 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 16:20:45 INFO Running runs: ['t13n8pn7']
2024-05-20 16:22:10 INFO Cleaning up finished run: t13n8pn7
2024-05-20 16:22:11 INFO Agent received command: run
2024-05-20 16:22:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 16:22:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 16:22:16 INFO Running runs: ['1qem9wtu']
2024-05-20 16:25:21 INFO Cleaning up finished run: 1qem9wtu
2024-05-20 16:25:22 INFO Agent received command: run
2024-05-20 16:25:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 16:25:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 16:25:27 INFO Running runs: ['vx4r8vgu']
2024-05-20 16:26:46 INFO Cleaning up finished run: vx4r8vgu
2024-05-20 16:26:47 INFO Agent received command: run
2024-05-20 16:26:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 16:26:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 16:26:52 INFO Running runs: ['y8l6bq7o']
2024-05-20 16:29:46 INFO Cleaning up finished run: y8l6bq7o
2024-05-20 16:29:47 INFO Agent received command: run
2024-05-20 16:29:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 16:29:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 16:29:52 INFO Running runs: ['w6ncyh5x']
2024-05-20 16:32:16 INFO Cleaning up finished run: w6ncyh5x
2024-05-20 16:32:16 INFO Agent received command: run
2024-05-20 16:32:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 16:32:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 16:32:21 INFO Running runs: ['jcnwg8w5']
2024-05-20 16:33:57 INFO Cleaning up finished run: jcnwg8w5
2024-05-20 16:33:58 INFO Agent received command: run
2024-05-20 16:33:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 16:33:58 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 16:34:03 INFO Running runs: ['1tp4l54s']
2024-05-20 16:35:17 INFO Cleaning up finished run: 1tp4l54s
2024-05-20 16:35:19 INFO Agent received command: run
2024-05-20 16:35:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 16:35:19 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 16:35:24 INFO Running runs: ['j5rgpu1g']
2024-05-20 16:38:24 INFO Cleaning up finished run: j5rgpu1g
2024-05-20 16:38:25 INFO Agent received command: run
2024-05-20 16:38:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 16:38:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 16:38:30 INFO Running runs: ['d8ul5j71']
2024-05-20 16:40:47 INFO Cleaning up finished run: d8ul5j71
2024-05-20 16:40:48 INFO Agent received command: run
2024-05-20 16:40:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 16:40:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 16:40:53 INFO Running runs: ['y94glxvk']
2024-05-20 16:43:10 INFO Cleaning up finished run: y94glxvk
2024-05-20 16:43:12 INFO Agent received command: run
2024-05-20 16:43:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 16:43:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 16:43:17 INFO Running runs: ['t400eh3o']
2024-05-20 16:46:54 INFO Cleaning up finished run: t400eh3o
2024-05-20 16:46:54 INFO Agent received command: run
2024-05-20 16:46:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 16:46:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 16:46:59 INFO Running runs: ['bmeb9o2c']
2024-05-20 16:49:02 INFO Cleaning up finished run: bmeb9o2c
2024-05-20 16:49:02 INFO Agent received command: run
2024-05-20 16:49:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 16:49:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 16:49:07 INFO Running runs: ['wjdb50yr']
2024-05-20 16:53:01 INFO Cleaning up finished run: wjdb50yr
2024-05-20 16:53:02 INFO Agent received command: run
2024-05-20 16:53:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 16:53:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 16:53:07 INFO Running runs: ['lg2q0gnm']
2024-05-20 16:55:45 INFO Cleaning up finished run: lg2q0gnm
2024-05-20 16:55:46 INFO Agent received command: run
2024-05-20 16:55:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 16:55:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 16:55:51 INFO Running runs: ['y22f5ora']
2024-05-20 16:58:09 INFO Cleaning up finished run: y22f5ora
2024-05-20 16:58:10 INFO Agent received command: run
2024-05-20 16:58:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 16:58:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 16:58:15 INFO Running runs: ['ggt5hmwo']
2024-05-20 17:00:22 INFO Cleaning up finished run: ggt5hmwo
2024-05-20 17:00:23 INFO Agent received command: run
2024-05-20 17:00:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:00:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 17:00:28 INFO Running runs: ['em6xbjc2']
2024-05-20 17:01:27 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:27 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:27 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:27 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:27 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:27 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:01:42 INFO Cleaning up finished run: em6xbjc2
2024-05-20 17:01:44 INFO Agent received command: run
2024-05-20 17:01:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:01:44 ERROR Exception while processing command: {'run_id': 'ns1u1bpp', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTI5Mw==', 'logs': ['expected_improvement: 5.594213e-02', 'predicted_value: -5.575950e-01', 'predicted_value_std_dev: 2.550231e-01', 'success_probability: 1.186283e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm5zMXUxYnBwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:01:49 INFO Running runs: []
2024-05-20 17:01:50 INFO Agent received command: run
2024-05-20 17:01:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:01:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 17:01:55 INFO Running runs: ['qrocatil']
2024-05-20 17:02:32 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:32 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:32 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:32 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:32 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:32 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:43 INFO Cleaning up finished run: qrocatil
2024-05-20 17:02:44 INFO Agent received command: run
2024-05-20 17:02:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:02:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 17:02:49 INFO Running runs: ['jq3zg2bh']
2024-05-20 17:02:52 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:52 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:52 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:52 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:52 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:02:52 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-20 17:03:10 INFO Cleaning up finished run: jq3zg2bh
2024-05-20 17:03:17 INFO Agent received command: run
2024-05-20 17:03:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:03:17 ERROR Exception while processing command: {'run_id': 'p1927gpl', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTU0NQ==', 'logs': ['expected_improvement: 6.195698e-02', 'predicted_value: -5.190943e-01', 'predicted_value_std_dev: 2.578895e-01', 'success_probability: 1.261406e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnAxOTI3Z3BsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:23 INFO Running runs: []
2024-05-20 17:03:23 INFO Agent received command: run
2024-05-20 17:03:23 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:03:23 ERROR Exception while processing command: {'run_id': 'tjg7mh3k', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTU2NA==', 'logs': ['expected_improvement: 5.702225e-02', 'predicted_value: -5.320546e-01', 'predicted_value_std_dev: 2.461644e-01', 'success_probability: 1.172819e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnRqZzdtaDNrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:30 INFO Agent received command: run
2024-05-20 17:03:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:03:30 ERROR Exception while processing command: {'run_id': 'd4ovuaxi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTYwOQ==', 'logs': ['expected_improvement: 5.250091e-02', 'predicted_value: -5.245435e-01', 'predicted_value_std_dev: 2.537572e-01', 'success_probability: 1.102107e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmQ0b3Z1YXhpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:36 INFO Agent received command: run
2024-05-20 17:03:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:03:36 ERROR Exception while processing command: {'run_id': '0wdnn9cy', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTYyNg==', 'logs': ['expected_improvement: 4.299443e-02', 'predicted_value: -4.878065e-01', 'predicted_value_std_dev: 2.723548e-01', 'success_probability: 9.259185e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjB3ZG5uOWN5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:42 INFO Agent received command: run
2024-05-20 17:03:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:03:42 ERROR Exception while processing command: {'run_id': '9xxheo5y', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTY2Mg==', 'logs': ['expected_improvement: 4.257071e-02', 'predicted_value: -5.235914e-01', 'predicted_value_std_dev: 2.523344e-01', 'success_probability: 9.188750e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjl4eGhlbzV5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:48 INFO Agent received command: run
2024-05-20 17:03:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:03:48 ERROR Exception while processing command: {'run_id': 'pojguk9s', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTY4MA==', 'logs': ['expected_improvement: 6.989027e-02', 'predicted_value: -5.519493e-01', 'predicted_value_std_dev: 2.523058e-01', 'success_probability: 1.440264e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnBvamd1azlzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:03:54 INFO Agent received command: run
2024-05-20 17:03:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:03:54 ERROR Exception while processing command: {'run_id': 'jmflq7uw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTY5MQ==', 'logs': ['expected_improvement: 4.463344e-02', 'predicted_value: -5.186581e-01', 'predicted_value_std_dev: 2.600751e-01', 'success_probability: 9.533021e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmptZmxxN3V3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:00 INFO Agent received command: run
2024-05-20 17:04:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:04:00 ERROR Exception while processing command: {'run_id': '0qvabc3j', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTcxNQ==', 'logs': ['expected_improvement: 4.890899e-02', 'predicted_value: -5.280237e-01', 'predicted_value_std_dev: 2.649914e-01', 'success_probability: 1.034358e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjBxdmFiYzNqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:06 INFO Agent received command: run
2024-05-20 17:04:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:04:06 ERROR Exception while processing command: {'run_id': 'c0ndtr4x', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTc1Mw==', 'logs': ['expected_improvement: 4.885939e-02', 'predicted_value: -5.260477e-01', 'predicted_value_std_dev: 2.549111e-01', 'success_probability: 1.028259e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmMwbmR0cjR4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:12 INFO Agent received command: run
2024-05-20 17:04:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:04:12 ERROR Exception while processing command: {'run_id': 'vlev4skw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTc3Mg==', 'logs': ['expected_improvement: 6.199275e-02', 'predicted_value: -5.618832e-01', 'predicted_value_std_dev: 2.522016e-01', 'success_probability: 1.266428e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnZsZXY0c2t3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:18 INFO Agent received command: run
2024-05-20 17:04:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:04:18 ERROR Exception while processing command: {'run_id': 'keslfqn4', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTc4OQ==', 'logs': ['expected_improvement: 5.924545e-02', 'predicted_value: -5.454863e-01', 'predicted_value_std_dev: 2.509897e-01', 'success_probability: 1.209828e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmtlc2xmcW40OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:25 INFO Agent received command: run
2024-05-20 17:04:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:04:25 ERROR Exception while processing command: {'run_id': '87be79jh', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTc5NQ==', 'logs': ['expected_improvement: 5.243337e-02', 'predicted_value: -5.368814e-01', 'predicted_value_std_dev: 2.508426e-01', 'success_probability: 1.090389e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjg3YmU3OWpoOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:32 INFO Agent received command: run
2024-05-20 17:04:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:04:32 ERROR Exception while processing command: {'run_id': 'ag5h837m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTgxMQ==', 'logs': ['expected_improvement: 3.646087e-02', 'predicted_value: -4.960418e-01', 'predicted_value_std_dev: 2.616164e-01', 'success_probability: 8.064520e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmFnNWg4MzdtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:38 INFO Agent received command: run
2024-05-20 17:04:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:04:38 ERROR Exception while processing command: {'run_id': 'xa2yn0vu', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTg3Ng==', 'logs': ['expected_improvement: 7.081599e-02', 'predicted_value: -6.029969e-01', 'predicted_value_std_dev: 2.416122e-01', 'success_probability: 1.445152e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnhhMnluMHZ1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:43 INFO Agent received command: run
2024-05-20 17:04:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:04:43 ERROR Exception while processing command: {'run_id': '0t2kdjos', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTg4Mg==', 'logs': ['expected_improvement: 8.675319e-02', 'predicted_value: -6.772532e-01', 'predicted_value_std_dev: 2.087744e-01', 'success_probability: 1.920025e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjB0Mmtkam9zOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:49 INFO Agent received command: run
2024-05-20 17:04:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:04:49 ERROR Exception while processing command: {'run_id': 'kaovwa0s', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTg4OA==', 'logs': ['expected_improvement: 5.862896e-02', 'predicted_value: -5.792580e-01', 'predicted_value_std_dev: 2.411205e-01', 'success_probability: 1.228483e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmthb3Z3YTBzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:04:55 INFO Agent received command: run
2024-05-20 17:04:55 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:04:55 ERROR Exception while processing command: {'run_id': 'tjwuijkn', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTkxMw==', 'logs': ['expected_improvement: 3.962249e-02', 'predicted_value: -4.822874e-01', 'predicted_value_std_dev: 2.595729e-01', 'success_probability: 8.618996e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnRqd3VpamtuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:01 INFO Agent received command: run
2024-05-20 17:05:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:05:01 ERROR Exception while processing command: {'run_id': '4ko6k7iv', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTkzMQ==', 'logs': ['expected_improvement: 5.624036e-02', 'predicted_value: -5.602241e-01', 'predicted_value_std_dev: 2.462775e-01', 'success_probability: 1.156680e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjRrbzZrN2l2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:07 INFO Agent received command: run
2024-05-20 17:05:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:05:07 ERROR Exception while processing command: {'run_id': '2jgkjxix', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MTk4Mg==', 'logs': ['expected_improvement: 4.036384e-02', 'predicted_value: -5.167007e-01', 'predicted_value_std_dev: 2.526786e-01', 'success_probability: 8.765447e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjJqZ2tqeGl4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:13 INFO Agent received command: run
2024-05-20 17:05:13 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:05:13 ERROR Exception while processing command: {'run_id': 'z22ss75k', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjAwNg==', 'logs': ['expected_improvement: 4.520835e-02', 'predicted_value: -4.997203e-01', 'predicted_value_std_dev: 2.684008e-01', 'success_probability: 9.678456e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnoyMnNzNzVrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:19 INFO Agent received command: run
2024-05-20 17:05:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:05:20 ERROR Exception while processing command: {'run_id': 'ivnvpg3m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjAyNg==', 'logs': ['expected_improvement: 5.547316e-02', 'predicted_value: -5.322801e-01', 'predicted_value_std_dev: 2.552787e-01', 'success_probability: 1.146505e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOml2bnZwZzNtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:25 INFO Agent received command: run
2024-05-20 17:05:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:05:25 ERROR Exception while processing command: {'run_id': 'o6ffqaj8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjA1MA==', 'logs': ['expected_improvement: 5.434947e-02', 'predicted_value: -5.541732e-01', 'predicted_value_std_dev: 2.543465e-01', 'success_probability: 1.127121e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm82ZmZxYWo4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:31 INFO Agent received command: run
2024-05-20 17:05:31 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 17:05:31 ERROR Exception while processing command: {'run_id': 'rcyzwv8m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjA2Ng==', 'logs': ['expected_improvement: 3.232931e-02', 'predicted_value: -4.988747e-01', 'predicted_value_std_dev: 2.404147e-01', 'success_probability: 7.284142e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnJjeXp3djhtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:37 INFO Agent received command: run
2024-05-20 17:05:37 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:05:37 ERROR Exception while processing command: {'run_id': 'dow887te', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjA2Nw==', 'logs': ['expected_improvement: 9.227269e-02', 'predicted_value: -5.880892e-01', 'predicted_value_std_dev: 2.666324e-01', 'success_probability: 1.757563e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmRvdzg4N3RlOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:43 INFO Agent received command: run
2024-05-20 17:05:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:05:43 ERROR Exception while processing command: {'run_id': 'ftd0pj63', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjEwOA==', 'logs': ['expected_improvement: 7.363814e-02', 'predicted_value: -5.475104e-01', 'predicted_value_std_dev: 2.715339e-01', 'success_probability: 1.444355e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmZ0ZDBwajYzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:50 INFO Agent received command: run
2024-05-20 17:05:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:05:50 ERROR Exception while processing command: {'run_id': 'y20thw8f', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjEyMQ==', 'logs': ['expected_improvement: 5.984852e-02', 'predicted_value: -5.530752e-01', 'predicted_value_std_dev: 2.632880e-01', 'success_probability: 1.226302e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnkyMHRodzhmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:05:56 INFO Agent received command: run
2024-05-20 17:05:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:05:56 ERROR Exception while processing command: {'run_id': 'ytynlhna', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjEzNw==', 'logs': ['expected_improvement: 7.247682e-02', 'predicted_value: -5.910188e-01', 'predicted_value_std_dev: 2.463334e-01', 'success_probability: 1.490498e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnl0eW5saG5hOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:01 INFO Agent received command: run
2024-05-20 17:06:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:06:01 ERROR Exception while processing command: {'run_id': 'r3rddsz5', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjEzOQ==', 'logs': ['expected_improvement: 6.382595e-02', 'predicted_value: -5.615114e-01', 'predicted_value_std_dev: 2.575511e-01', 'success_probability: 1.313312e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnIzcmRkc3o1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:07 INFO Agent received command: run
2024-05-20 17:06:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:06:07 ERROR Exception while processing command: {'run_id': 'pahrt2kf', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjE3NA==', 'logs': ['expected_improvement: 6.398171e-02', 'predicted_value: -5.764646e-01', 'predicted_value_std_dev: 2.513276e-01', 'success_probability: 1.304703e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnBhaHJ0MmtmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:19 INFO Agent received command: run
2024-05-20 17:06:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:06:19 ERROR Exception while processing command: {'run_id': 'xn70mwpi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjIyMw==', 'logs': ['expected_improvement: 6.707226e-02', 'predicted_value: -5.464321e-01', 'predicted_value_std_dev: 2.552523e-01', 'success_probability: 1.351347e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnhuNzBtd3BpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:25 INFO Agent received command: run
2024-05-20 17:06:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:06:25 ERROR Exception while processing command: {'run_id': '0eegcdtm', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjI0OQ==', 'logs': ['expected_improvement: 4.848956e-02', 'predicted_value: -5.321052e-01', 'predicted_value_std_dev: 2.497205e-01', 'success_probability: 1.024594e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjBlZWdjZHRtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:31 INFO Agent received command: run
2024-05-20 17:06:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:06:31 ERROR Exception while processing command: {'run_id': '8wtu2m3e', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjI1NA==', 'logs': ['expected_improvement: 8.302173e-02', 'predicted_value: -5.833942e-01', 'predicted_value_std_dev: 2.546260e-01', 'success_probability: 1.607426e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjh3dHUybTNlOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:38 INFO Agent received command: run
2024-05-20 17:06:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:06:38 ERROR Exception while processing command: {'run_id': 'rmxcr957', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjI2OQ==', 'logs': ['expected_improvement: 6.642135e-02', 'predicted_value: -5.274145e-01', 'predicted_value_std_dev: 2.599323e-01', 'success_probability: 1.344187e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnJteGNyOTU3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:44 INFO Agent received command: run
2024-05-20 17:06:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:06:44 ERROR Exception while processing command: {'run_id': '3sajrwt5', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjI4OQ==', 'logs': ['expected_improvement: 7.525024e-02', 'predicted_value: -6.369080e-01', 'predicted_value_std_dev: 2.171213e-01', 'success_probability: 1.647057e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjNzYWpyd3Q1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:50 INFO Agent received command: run
2024-05-20 17:06:50 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:06:50 ERROR Exception while processing command: {'run_id': 'ds2k5hqi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjMyNg==', 'logs': ['expected_improvement: 5.715338e-02', 'predicted_value: -5.705462e-01', 'predicted_value_std_dev: 2.433187e-01', 'success_probability: 1.179105e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmRzMms1aHFpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:06:56 INFO Agent received command: run
2024-05-20 17:06:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:06:56 ERROR Exception while processing command: {'run_id': 'cb23noj0', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjM1NQ==', 'logs': ['expected_improvement: 5.428885e-02', 'predicted_value: -5.272097e-01', 'predicted_value_std_dev: 2.582427e-01', 'success_probability: 1.155224e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmNiMjNub2owOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:02 INFO Agent received command: run
2024-05-20 17:07:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:07:02 ERROR Exception while processing command: {'run_id': 'cjc8zgtk', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjM3OQ==', 'logs': ['expected_improvement: 5.372633e-02', 'predicted_value: -5.495701e-01', 'predicted_value_std_dev: 2.436178e-01', 'success_probability: 1.122347e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmNqYzh6Z3RrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:08 INFO Agent received command: run
2024-05-20 17:07:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:07:08 ERROR Exception while processing command: {'run_id': '66ymk3vt', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjQyMw==', 'logs': ['expected_improvement: 6.448695e-02', 'predicted_value: -5.382185e-01', 'predicted_value_std_dev: 2.760182e-01', 'success_probability: 1.340981e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjY2eW1rM3Z0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:14 INFO Agent received command: run
2024-05-20 17:07:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:07:14 ERROR Exception while processing command: {'run_id': 'ao5zkia3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjQ0MA==', 'logs': ['expected_improvement: 4.518098e-02', 'predicted_value: -5.304499e-01', 'predicted_value_std_dev: 2.522631e-01', 'success_probability: 9.638829e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmFvNXpraWEzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:28 INFO Agent received command: run
2024-05-20 17:07:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:07:28 ERROR Exception while processing command: {'run_id': 'gh8huha4', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjQ3NQ==', 'logs': ['expected_improvement: 7.366633e-02', 'predicted_value: -5.846718e-01', 'predicted_value_std_dev: 2.337429e-01', 'success_probability: 1.445135e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmdoOGh1aGE0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:34 INFO Agent received command: run
2024-05-20 17:07:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:07:34 ERROR Exception while processing command: {'run_id': 'wylriu4c', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjQ5Mw==', 'logs': ['expected_improvement: 6.362365e-02', 'predicted_value: -5.441773e-01', 'predicted_value_std_dev: 2.639539e-01', 'success_probability: 1.281336e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnd5bHJpdTRjOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:40 INFO Agent received command: run
2024-05-20 17:07:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:07:40 ERROR Exception while processing command: {'run_id': '5rn08zgj', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjUwMw==', 'logs': ['expected_improvement: 6.178739e-02', 'predicted_value: -5.579085e-01', 'predicted_value_std_dev: 2.536571e-01', 'success_probability: 1.258430e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVybjA4emdqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:46 INFO Agent received command: run
2024-05-20 17:07:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:07:46 ERROR Exception while processing command: {'run_id': 'ti45wql6', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjUxOQ==', 'logs': ['expected_improvement: 6.245613e-02', 'predicted_value: -5.669641e-01', 'predicted_value_std_dev: 2.574494e-01', 'success_probability: 1.281899e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnRpNDV3cWw2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:52 INFO Agent received command: run
2024-05-20 17:07:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:07:52 ERROR Exception while processing command: {'run_id': '1z9bwcsy', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjUyMw==', 'logs': ['expected_improvement: 5.670126e-02', 'predicted_value: -5.334237e-01', 'predicted_value_std_dev: 2.655339e-01', 'success_probability: 1.196910e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjF6OWJ3Y3N5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:07:58 INFO Agent received command: run
2024-05-20 17:07:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:07:58 ERROR Exception while processing command: {'run_id': '38tn1rtq', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjUzMQ==', 'logs': ['expected_improvement: 8.492473e-02', 'predicted_value: -6.168602e-01', 'predicted_value_std_dev: 2.232560e-01', 'success_probability: 1.633419e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjM4dG4xcnRxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:08:04 INFO Agent received command: run
2024-05-20 17:08:04 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:08:04 ERROR Exception while processing command: {'run_id': 'myphmkoc', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjU1NA==', 'logs': ['expected_improvement: 5.377262e-02', 'predicted_value: -5.401470e-01', 'predicted_value_std_dev: 2.506625e-01', 'success_probability: 1.113249e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm15cGhta29jOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:08:28 INFO Agent received command: run
2024-05-20 17:08:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:08:28 ERROR Exception while processing command: {'run_id': '3ff2litg', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjY1OQ==', 'logs': ['expected_improvement: 4.966505e-02', 'predicted_value: -5.482245e-01', 'predicted_value_std_dev: 2.470732e-01', 'success_probability: 1.041053e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjNmZjJsaXRnOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:08:34 INFO Agent received command: run
2024-05-20 17:08:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:08:34 ERROR Exception while processing command: {'run_id': 'ot9sny1b', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjY4NA==', 'logs': ['expected_improvement: 4.890882e-02', 'predicted_value: -5.159676e-01', 'predicted_value_std_dev: 2.600702e-01', 'success_probability: 1.029059e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm90OXNueTFiOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:02 INFO Agent received command: run
2024-05-20 17:09:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:09:02 ERROR Exception while processing command: {'run_id': '10e0ig8a', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjgyNg==', 'logs': ['expected_improvement: 7.300490e-02', 'predicted_value: -5.738413e-01', 'predicted_value_std_dev: 2.579931e-01', 'success_probability: 1.458820e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjEwZTBpZzhhOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:08 INFO Agent received command: run
2024-05-20 17:09:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:09:08 ERROR Exception while processing command: {'run_id': 'x54iljrp', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mjg1Ng==', 'logs': ['expected_improvement: 4.229217e-02', 'predicted_value: -5.222079e-01', 'predicted_value_std_dev: 2.547603e-01', 'success_probability: 9.308500e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOng1NGlsanJwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:14 INFO Agent received command: run
2024-05-20 17:09:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:09:14 ERROR Exception while processing command: {'run_id': 's9prpeu6', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mjg4Mg==', 'logs': ['expected_improvement: 5.075730e-02', 'predicted_value: -5.429495e-01', 'predicted_value_std_dev: 2.562248e-01', 'success_probability: 1.061717e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnM5cHJwZXU2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:20 INFO Agent received command: run
2024-05-20 17:09:20 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:09:20 ERROR Exception while processing command: {'run_id': '7off9bx9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjkwMg==', 'logs': ['expected_improvement: 5.184857e-02', 'predicted_value: -5.274014e-01', 'predicted_value_std_dev: 2.584723e-01', 'success_probability: 1.078990e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjdvZmY5Yng5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:25 INFO Agent received command: run
2024-05-20 17:09:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:09:25 ERROR Exception while processing command: {'run_id': 't0gjfifo', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MjkxNw==', 'logs': ['expected_improvement: 9.654450e-02', 'predicted_value: -6.500885e-01', 'predicted_value_std_dev: 2.252811e-01', 'success_probability: 1.906378e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnQwZ2pmaWZvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:31 INFO Agent received command: run
2024-05-20 17:09:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:09:31 ERROR Exception while processing command: {'run_id': 'v0azpme2', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mjk1MA==', 'logs': ['expected_improvement: 8.164939e-02', 'predicted_value: -6.125369e-01', 'predicted_value_std_dev: 2.481265e-01', 'success_probability: 1.601195e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnYwYXpwbWUyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:37 INFO Agent received command: run
2024-05-20 17:09:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:09:37 ERROR Exception while processing command: {'run_id': 'efhn79sh', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mjk4OQ==', 'logs': ['expected_improvement: 5.717882e-02', 'predicted_value: -5.721918e-01', 'predicted_value_std_dev: 2.322916e-01', 'success_probability: 1.201134e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmVmaG43OXNoOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:43 INFO Agent received command: run
2024-05-20 17:09:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:09:43 ERROR Exception while processing command: {'run_id': 'bc2znppq', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzAyNQ==', 'logs': ['expected_improvement: 8.109090e-02', 'predicted_value: -6.051444e-01', 'predicted_value_std_dev: 2.477212e-01', 'success_probability: 1.565795e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJjMnpucHBxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:49 INFO Agent received command: run
2024-05-20 17:09:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:09:49 ERROR Exception while processing command: {'run_id': 'vo7z0vil', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzA1OQ==', 'logs': ['expected_improvement: 5.275555e-02', 'predicted_value: -5.437837e-01', 'predicted_value_std_dev: 2.578556e-01', 'success_probability: 1.107685e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnZvN3owdmlsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:09:55 INFO Agent received command: run
2024-05-20 17:09:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:09:55 ERROR Exception while processing command: {'run_id': 'em6446s8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzA2NQ==', 'logs': ['expected_improvement: 4.060468e-02', 'predicted_value: -5.265572e-01', 'predicted_value_std_dev: 2.389997e-01', 'success_probability: 8.797712e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmVtNjQ0NnM4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:01 INFO Agent received command: run
2024-05-20 17:10:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:10:01 ERROR Exception while processing command: {'run_id': '8zytmyt9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzA4MQ==', 'logs': ['expected_improvement: 2.987465e-02', 'predicted_value: -4.644544e-01', 'predicted_value_std_dev: 2.554781e-01', 'success_probability: 6.791534e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjh6eXRteXQ5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:07 INFO Agent received command: run
2024-05-20 17:10:07 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:10:07 ERROR Exception while processing command: {'run_id': 'mwe4081t', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzEyNg==', 'logs': ['expected_improvement: 4.959242e-02', 'predicted_value: -5.185790e-01', 'predicted_value_std_dev: 2.708740e-01', 'success_probability: 1.043108e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm13ZTQwODF0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:13 INFO Agent received command: run
2024-05-20 17:10:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:10:13 ERROR Exception while processing command: {'run_id': 'ebtrr1et', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzEzNg==', 'logs': ['expected_improvement: 4.963415e-02', 'predicted_value: -5.251262e-01', 'predicted_value_std_dev: 2.548501e-01', 'success_probability: 1.041211e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmVidHJyMWV0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:47 INFO Agent received command: run
2024-05-20 17:10:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 17:10:47 ERROR Exception while processing command: {'run_id': 'v25ciz95', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzIwNQ==', 'logs': ['expected_improvement: 4.155482e-02', 'predicted_value: -4.862823e-01', 'predicted_value_std_dev: 2.603493e-01', 'success_probability: 8.969723e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnYyNWNpejk1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:53 INFO Agent received command: run
2024-05-20 17:10:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:10:53 ERROR Exception while processing command: {'run_id': 'uo472tnv', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzIzOQ==', 'logs': ['expected_improvement: 4.064474e-02', 'predicted_value: -4.945279e-01', 'predicted_value_std_dev: 2.521784e-01', 'success_probability: 8.817082e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnVvNDcydG52OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:10:59 INFO Agent received command: run
2024-05-20 17:10:59 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:10:59 ERROR Exception while processing command: {'run_id': 'wqh5nkk3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzI2Nw==', 'logs': ['expected_improvement: 5.790475e-02', 'predicted_value: -5.810374e-01', 'predicted_value_std_dev: 2.284416e-01', 'success_probability: 1.206905e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOndxaDVua2szOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:05 INFO Agent received command: run
2024-05-20 17:11:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:11:05 ERROR Exception while processing command: {'run_id': '508xjarq', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzI4Mg==', 'logs': ['expected_improvement: 7.776277e-02', 'predicted_value: -6.053380e-01', 'predicted_value_std_dev: 2.493990e-01', 'success_probability: 1.543959e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjUwOHhqYXJxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:11 INFO Agent received command: run
2024-05-20 17:11:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:11:11 ERROR Exception while processing command: {'run_id': 'kelt1stg', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzMxMQ==', 'logs': ['expected_improvement: 3.598656e-02', 'predicted_value: -5.083939e-01', 'predicted_value_std_dev: 2.426389e-01', 'success_probability: 7.958370e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmtlbHQxc3RnOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:17 INFO Agent received command: run
2024-05-20 17:11:17 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:11:17 ERROR Exception while processing command: {'run_id': 'o1ml0snr', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzMzNw==', 'logs': ['expected_improvement: 5.713854e-02', 'predicted_value: -5.282307e-01', 'predicted_value_std_dev: 2.541950e-01', 'success_probability: 1.175831e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm8xbWwwc25yOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:23 INFO Agent received command: run
2024-05-20 17:11:23 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:11:23 ERROR Exception while processing command: {'run_id': '4ocs1opk', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzM0Ng==', 'logs': ['expected_improvement: 3.527770e-02', 'predicted_value: -4.547554e-01', 'predicted_value_std_dev: 2.664866e-01', 'success_probability: 7.816871e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjRvY3Mxb3BrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:29 INFO Agent received command: run
2024-05-20 17:11:29 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:11:29 ERROR Exception while processing command: {'run_id': 'c8fuq0sj', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzM4Mg==', 'logs': ['expected_improvement: 3.563979e-02', 'predicted_value: -5.181713e-01', 'predicted_value_std_dev: 2.318370e-01', 'success_probability: 7.930922e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmM4ZnVxMHNqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:35 INFO Agent received command: run
2024-05-20 17:11:35 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:11:35 ERROR Exception while processing command: {'run_id': 'lz5xyb71', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzQxNg==', 'logs': ['expected_improvement: 4.696610e-02', 'predicted_value: -5.063434e-01', 'predicted_value_std_dev: 2.712837e-01', 'success_probability: 9.935958e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmx6NXh5YjcxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:40 INFO Agent received command: run
2024-05-20 17:11:40 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 17:11:40 ERROR Exception while processing command: {'run_id': 'bnenyy9a', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzQzMQ==', 'logs': ['expected_improvement: 4.513201e-02', 'predicted_value: -5.245486e-01', 'predicted_value_std_dev: 2.485367e-01', 'success_probability: 9.609907e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmJuZW55eTlhOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:47 INFO Agent received command: run
2024-05-20 17:11:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:11:47 ERROR Exception while processing command: {'run_id': '6cf4fvt7', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzQ0NA==', 'logs': ['expected_improvement: 8.374570e-02', 'predicted_value: -6.284245e-01', 'predicted_value_std_dev: 2.439999e-01', 'success_probability: 1.686975e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjZjZjRmdnQ3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:52 INFO Agent received command: run
2024-05-20 17:11:52 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:11:52 ERROR Exception while processing command: {'run_id': 'hgkxyudr', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzUwMA==', 'logs': ['expected_improvement: 5.051608e-02', 'predicted_value: -5.093961e-01', 'predicted_value_std_dev: 2.421833e-01', 'success_probability: 1.058703e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmhna3h5dWRyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:11:58 INFO Agent received command: run
2024-05-20 17:11:58 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:11:58 ERROR Exception while processing command: {'run_id': 'q0i1ibjm', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzUyMg==', 'logs': ['expected_improvement: 9.119455e-02', 'predicted_value: -6.246795e-01', 'predicted_value_std_dev: 2.443806e-01', 'success_probability: 1.811230e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnEwaTFpYmptOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:04 INFO Agent received command: run
2024-05-20 17:12:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:12:04 ERROR Exception while processing command: {'run_id': 'xuoc88qx', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzU1MQ==', 'logs': ['expected_improvement: 5.216758e-02', 'predicted_value: -5.109883e-01', 'predicted_value_std_dev: 2.605808e-01', 'success_probability: 1.086339e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnh1b2M4OHF4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:10 INFO Agent received command: run
2024-05-20 17:12:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:12:10 ERROR Exception while processing command: {'run_id': 'lwtc2o8g', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzU1Mw==', 'logs': ['expected_improvement: 5.849565e-02', 'predicted_value: -5.507196e-01', 'predicted_value_std_dev: 2.534417e-01', 'success_probability: 1.198768e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmx3dGMybzhnOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:16 INFO Agent received command: run
2024-05-20 17:12:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:12:16 ERROR Exception while processing command: {'run_id': '5jq0f3rq', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzU3OQ==', 'logs': ['expected_improvement: 5.009071e-02', 'predicted_value: -5.219822e-01', 'predicted_value_std_dev: 2.521307e-01', 'success_probability: 1.061184e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVqcTBmM3JxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:22 INFO Agent received command: run
2024-05-20 17:12:22 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-20 17:12:22 ERROR Exception while processing command: {'run_id': 'rnd4t2pe', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzYwMg==', 'logs': ['expected_improvement: 3.719792e-02', 'predicted_value: -4.999467e-01', 'predicted_value_std_dev: 2.502512e-01', 'success_probability: 8.173766e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnJuZDR0MnBlOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:28 INFO Agent received command: run
2024-05-20 17:12:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:12:28 ERROR Exception while processing command: {'run_id': '45nu9g1e', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzYwOA==', 'logs': ['expected_improvement: 8.083910e-02', 'predicted_value: -6.124707e-01', 'predicted_value_std_dev: 2.349823e-01', 'success_probability: 1.587788e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjQ1bnU5ZzFlOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:34 INFO Agent received command: run
2024-05-20 17:12:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:12:34 ERROR Exception while processing command: {'run_id': '55wa6qcj', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzYyMw==', 'logs': ['expected_improvement: 5.090190e-02', 'predicted_value: -5.375850e-01', 'predicted_value_std_dev: 2.423888e-01', 'success_probability: 1.067121e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjU1d2E2cWNqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:39 INFO Agent received command: run
2024-05-20 17:12:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:12:39 ERROR Exception while processing command: {'run_id': 'ojb3dvql', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzYyNw==', 'logs': ['expected_improvement: 5.623542e-02', 'predicted_value: -5.583027e-01', 'predicted_value_std_dev: 2.311449e-01', 'success_probability: 1.207764e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm9qYjNkdnFsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:46 INFO Agent received command: run
2024-05-20 17:12:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:12:46 ERROR Exception while processing command: {'run_id': 'mwd78o7n', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzY4NQ==', 'logs': ['expected_improvement: 5.726344e-02', 'predicted_value: -5.549566e-01', 'predicted_value_std_dev: 2.496417e-01', 'success_probability: 1.186294e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm13ZDc4bzduOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:52 INFO Agent received command: run
2024-05-20 17:12:52 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:12:52 ERROR Exception while processing command: {'run_id': 'pj5rbg2a', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzcwMw==', 'logs': ['expected_improvement: 6.665555e-02', 'predicted_value: -5.173993e-01', 'predicted_value_std_dev: 2.608862e-01', 'success_probability: 1.327987e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnBqNXJiZzJhOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:12:57 INFO Agent received command: run
2024-05-20 17:12:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:12:57 ERROR Exception while processing command: {'run_id': 'kxzw4qro', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzcxNw==', 'logs': ['expected_improvement: 9.310553e-02', 'predicted_value: -6.203317e-01', 'predicted_value_std_dev: 2.458609e-01', 'success_probability: 1.798768e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmt4enc0cXJvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:03 INFO Agent received command: run
2024-05-20 17:13:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:13:03 ERROR Exception while processing command: {'run_id': 'si68ii2v', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mzc0OA==', 'logs': ['expected_improvement: 2.596173e-02', 'predicted_value: -4.654506e-01', 'predicted_value_std_dev: 2.440508e-01', 'success_probability: 6.051982e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnNpNjhpaTJ2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:09 INFO Agent received command: run
2024-05-20 17:13:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:13:09 ERROR Exception while processing command: {'run_id': 'ht8qb7e8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mzc2Mg==', 'logs': ['expected_improvement: 3.612895e-02', 'predicted_value: -4.901341e-01', 'predicted_value_std_dev: 2.593738e-01', 'success_probability: 7.975565e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmh0OHFiN2U4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:15 INFO Agent received command: run
2024-05-20 17:13:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:13:15 ERROR Exception while processing command: {'run_id': 'vxy6q88o', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzgwMA==', 'logs': ['expected_improvement: 3.760708e-02', 'predicted_value: -4.980964e-01', 'predicted_value_std_dev: 2.525785e-01', 'success_probability: 8.257400e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnZ4eTZxODhvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:21 INFO Agent received command: run
2024-05-20 17:13:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:13:21 ERROR Exception while processing command: {'run_id': 'vbkahgun', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzgyOA==', 'logs': ['expected_improvement: 3.250109e-02', 'predicted_value: -4.749992e-01', 'predicted_value_std_dev: 2.544253e-01', 'success_probability: 7.293717e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnZia2FoZ3VuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:28 INFO Agent received command: run
2024-05-20 17:13:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:13:28 ERROR Exception while processing command: {'run_id': 'nxcpa3m0', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mzg2Mg==', 'logs': ['expected_improvement: 4.653506e-02', 'predicted_value: -5.176559e-01', 'predicted_value_std_dev: 2.686861e-01', 'success_probability: 9.966814e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm54Y3BhM20wOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:37 INFO Agent received command: run
2024-05-20 17:13:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:13:37 ERROR Exception while processing command: {'run_id': '3qg648ib', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mzg5MQ==', 'logs': ['expected_improvement: 8.890102e-02', 'predicted_value: -6.484022e-01', 'predicted_value_std_dev: 2.147006e-01', 'success_probability: 1.813458e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjNxZzY0OGliOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:42 INFO Agent received command: run
2024-05-20 17:13:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:13:42 ERROR Exception while processing command: {'run_id': '9df5w18b', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzkwNQ==', 'logs': ['expected_improvement: 4.716284e-02', 'predicted_value: -5.232289e-01', 'predicted_value_std_dev: 2.554607e-01', 'success_probability: 1.004234e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjlkZjV3MThiOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:13:54 INFO Agent received command: run
2024-05-20 17:13:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:13:54 ERROR Exception while processing command: {'run_id': 'xt1n98x0', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzkzNA==', 'logs': ['expected_improvement: 5.308799e-02', 'predicted_value: -5.054931e-01', 'predicted_value_std_dev: 2.521529e-01', 'success_probability: 1.099498e-01', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnh0MW45OHgwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:00 INFO Agent received command: run
2024-05-20 17:14:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:14:00 ERROR Exception while processing command: {'run_id': '6aaxbw23', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1MzkzOQ==', 'logs': ['expected_improvement: 6.242215e-02', 'predicted_value: -5.504872e-01', 'predicted_value_std_dev: 2.474911e-01', 'success_probability: 1.272503e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjZhYXhidzIzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:06 INFO Agent received command: run
2024-05-20 17:14:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:14:06 ERROR Exception while processing command: {'run_id': '0b8phufr', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1Mzk2MQ==', 'logs': ['expected_improvement: 4.591954e-02', 'predicted_value: -5.018466e-01', 'predicted_value_std_dev: 2.534525e-01', 'success_probability: 9.770638e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjBiOHBodWZyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:12 INFO Agent received command: run
2024-05-20 17:14:12 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:14:12 ERROR Exception while processing command: {'run_id': 'q6rs56y3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDAyMQ==', 'logs': ['expected_improvement: 4.940995e-02', 'predicted_value: -5.274162e-01', 'predicted_value_std_dev: 2.399081e-01', 'success_probability: 1.036099e-01', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnE2cnM1NnkzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:19 INFO Agent received command: run
2024-05-20 17:14:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 17:14:19 ERROR Exception while processing command: {'run_id': 'qm7udvvn', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDAyNw==', 'logs': ['expected_improvement: 6.571199e-02', 'predicted_value: -5.320595e-01', 'predicted_value_std_dev: 2.527618e-01', 'success_probability: 1.320490e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnFtN3VkdnZuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:25 INFO Agent received command: run
2024-05-20 17:14:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:14:25 ERROR Exception while processing command: {'run_id': 'mgyxpyfh', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDA0Ng==', 'logs': ['expected_improvement: 5.117791e-02', 'predicted_value: -5.362279e-01', 'predicted_value_std_dev: 2.526596e-01', 'success_probability: 1.071413e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm1neXhweWZoOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:31 INFO Agent received command: run
2024-05-20 17:14:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:14:31 ERROR Exception while processing command: {'run_id': 'ajx7a6yw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDA4Mw==', 'logs': ['expected_improvement: 4.841223e-02', 'predicted_value: -5.293066e-01', 'predicted_value_std_dev: 2.504907e-01', 'success_probability: 1.021111e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmFqeDdhNnl3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:37 INFO Agent received command: run
2024-05-20 17:14:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:14:37 ERROR Exception while processing command: {'run_id': 'mzsp42dz', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDA4Nw==', 'logs': ['expected_improvement: 4.388479e-02', 'predicted_value: -5.400783e-01', 'predicted_value_std_dev: 2.394590e-01', 'success_probability: 9.423192e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm16c3A0MmR6OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:43 INFO Agent received command: run
2024-05-20 17:14:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 17:14:43 ERROR Exception while processing command: {'run_id': '87fxg05p', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDEwNQ==', 'logs': ['expected_improvement: 4.393283e-02', 'predicted_value: -4.991037e-01', 'predicted_value_std_dev: 2.672122e-01', 'success_probability: 9.456228e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjg3ZnhnMDVwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:49 INFO Agent received command: run
2024-05-20 17:14:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:14:49 ERROR Exception while processing command: {'run_id': 'grgypq4u', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDE0MQ==', 'logs': ['expected_improvement: 5.727315e-02', 'predicted_value: -5.737771e-01', 'predicted_value_std_dev: 2.457433e-01', 'success_probability: 1.228916e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmdyZ3lwcTR1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:14:55 INFO Agent received command: run
2024-05-20 17:14:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:14:55 ERROR Exception while processing command: {'run_id': '62iddhfu', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDE0Nw==', 'logs': ['expected_improvement: 5.054352e-02', 'predicted_value: -5.272011e-01', 'predicted_value_std_dev: 2.562191e-01', 'success_probability: 1.057510e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjYyaWRkaGZ1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:01 INFO Agent received command: run
2024-05-20 17:15:01 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 17:15:01 ERROR Exception while processing command: {'run_id': 'cp174ewi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDE4Mw==', 'logs': ['expected_improvement: 3.696141e-02', 'predicted_value: -4.738958e-01', 'predicted_value_std_dev: 2.599603e-01', 'success_probability: 8.153155e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmNwMTc0ZXdpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:07 INFO Agent received command: run
2024-05-20 17:15:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:15:08 ERROR Exception while processing command: {'run_id': 'ayl58bck', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDE4OQ==', 'logs': ['expected_improvement: 4.161423e-02', 'predicted_value: -5.139756e-01', 'predicted_value_std_dev: 2.609212e-01', 'success_probability: 9.081636e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmF5bDU4YmNrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:24 INFO Agent received command: run
2024-05-20 17:15:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:15:24 ERROR Exception while processing command: {'run_id': 'ows6sgii', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDIyNQ==', 'logs': ['expected_improvement: 4.419005e-02', 'predicted_value: -4.965248e-01', 'predicted_value_std_dev: 2.643152e-01', 'success_probability: 9.442440e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOm93czZzZ2lpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:30 INFO Agent received command: run
2024-05-20 17:15:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 17:15:30 ERROR Exception while processing command: {'run_id': 'vjjenxf3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDI0MQ==', 'logs': ['expected_improvement: 7.092830e-02', 'predicted_value: -5.810754e-01', 'predicted_value_std_dev: 2.607802e-01', 'success_probability: 1.432702e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnZqamVueGYzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:36 INFO Agent received command: run
2024-05-20 17:15:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:15:36 ERROR Exception while processing command: {'run_id': 'ufzyx0yx', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDI2Ng==', 'logs': ['expected_improvement: 4.392529e-02', 'predicted_value: -4.911020e-01', 'predicted_value_std_dev: 2.796813e-01', 'success_probability: 9.408477e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnVmenl4MHl4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:42 INFO Agent received command: run
2024-05-20 17:15:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 17:15:42 ERROR Exception while processing command: {'run_id': 'jcvy249e', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDI5MQ==', 'logs': ['expected_improvement: 3.019228e-02', 'predicted_value: -4.584787e-01', 'predicted_value_std_dev: 2.693644e-01', 'success_probability: 6.851913e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmpjdnkyNDllOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:48 INFO Agent received command: run
2024-05-20 17:15:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:15:48 ERROR Exception while processing command: {'run_id': 'ajiolk35', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDI5OA==', 'logs': ['expected_improvement: 8.788416e-02', 'predicted_value: -5.722302e-01', 'predicted_value_std_dev: 2.501005e-01', 'success_probability: 1.725766e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmFqaW9sazM1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:15:54 INFO Agent received command: run
2024-05-20 17:15:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:15:54 ERROR Exception while processing command: {'run_id': 'qbt8deq9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDMyNA==', 'logs': ['expected_improvement: 4.497171e-02', 'predicted_value: -4.958045e-01', 'predicted_value_std_dev: 2.638078e-01', 'success_probability: 9.871212e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnFidDhkZXE5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:00 INFO Agent received command: run
2024-05-20 17:16:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:16:00 ERROR Exception while processing command: {'run_id': 'eq4vqonc', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDM1Mg==', 'logs': ['expected_improvement: 3.608919e-02', 'predicted_value: -4.538024e-01', 'predicted_value_std_dev: 2.816580e-01', 'success_probability: 7.976404e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmVxNHZxb25jOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:06 INFO Agent received command: run
2024-05-20 17:16:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:16:06 ERROR Exception while processing command: {'run_id': 'bjjzunyt', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDM3Ng==', 'logs': ['expected_improvement: 4.890305e-02', 'predicted_value: -5.249814e-01', 'predicted_value_std_dev: 2.662157e-01', 'success_probability: 1.046819e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJqanp1bnl0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:12 INFO Agent received command: run
2024-05-20 17:16:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:16:12 ERROR Exception while processing command: {'run_id': '5bks25qi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDQyMg==', 'logs': ['expected_improvement: 6.208700e-02', 'predicted_value: -5.246204e-01', 'predicted_value_std_dev: 2.831002e-01', 'success_probability: 1.252072e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVia3MyNXFpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:18 INFO Agent received command: run
2024-05-20 17:16:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:16:18 ERROR Exception while processing command: {'run_id': 'fomztfv4', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDQyNQ==', 'logs': ['expected_improvement: 5.295923e-02', 'predicted_value: -5.280516e-01', 'predicted_value_std_dev: 2.603474e-01', 'success_probability: 1.100303e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmZvbXp0ZnY0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:25 INFO Agent received command: run
2024-05-20 17:16:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 17:16:26 ERROR Exception while processing command: {'run_id': '2dkuyewv', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDQzMA==', 'logs': ['expected_improvement: 3.312440e-02', 'predicted_value: -4.631158e-01', 'predicted_value_std_dev: 2.647129e-01', 'success_probability: 7.411914e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjJka3V5ZXd2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:16:31 INFO Agent received command: run
2024-05-20 17:16:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:16:31 ERROR Exception while processing command: {'run_id': '5p72ifp5', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDQ2NQ==', 'logs': ['expected_improvement: 3.593064e-02', 'predicted_value: -4.394395e-01', 'predicted_value_std_dev: 2.852138e-01', 'success_probability: 7.940349e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVwNzJpZnA1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:01 ERROR 500 response executing GraphQL.
2024-05-20 17:17:01 ERROR {"errors":[{"message":"Post \"http://anaconda2.default.svc.cluster.local/search\": read tcp 10.52.68.3:36672-\u003e10.55.247.53:80: read: connection reset by peer","path":["agentHeartbeat"]}],"data":{"agentHeartbeat":null}}
2024-05-20 17:17:03 INFO Agent received command: run
2024-05-20 17:17:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:17:03 ERROR Exception while processing command: {'run_id': 'jx4uzo9q', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDU1NQ==', 'logs': ['expected_improvement: 3.740685e-02', 'predicted_value: -4.931579e-01', 'predicted_value_std_dev: 2.630199e-01', 'success_probability: 8.212365e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmp4NHV6bzlxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:10 INFO Agent received command: run
2024-05-20 17:17:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:17:10 ERROR Exception while processing command: {'run_id': 'ek5vwg7l', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDU4MA==', 'logs': ['expected_improvement: 4.620452e-02', 'predicted_value: -4.978088e-01', 'predicted_value_std_dev: 2.724620e-01', 'success_probability: 9.807061e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmVrNXZ3ZzdsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:16 INFO Agent received command: run
2024-05-20 17:17:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:17:16 ERROR Exception while processing command: {'run_id': 'oyayua5m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDYwOA==', 'logs': ['expected_improvement: 7.894057e-02', 'predicted_value: -5.783332e-01', 'predicted_value_std_dev: 2.420079e-01', 'success_probability: 1.637143e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm95YXl1YTVtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:24 INFO Agent received command: run
2024-05-20 17:17:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:17:24 ERROR Exception while processing command: {'run_id': 'maum5452', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDYxMQ==', 'logs': ['expected_improvement: 4.314080e-02', 'predicted_value: -4.980968e-01', 'predicted_value_std_dev: 2.763248e-01', 'success_probability: 9.362672e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm1hdW01NDUyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:29 INFO Agent received command: run
2024-05-20 17:17:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:17:29 ERROR Exception while processing command: {'run_id': 'esk6z8xk', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDYyNg==', 'logs': ['expected_improvement: 4.895713e-02', 'predicted_value: -5.354530e-01', 'predicted_value_std_dev: 2.590362e-01', 'success_probability: 1.033751e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmVzazZ6OHhrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:35 INFO Agent received command: run
2024-05-20 17:17:35 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-20 17:17:35 ERROR Exception while processing command: {'run_id': 'c1hw1n4m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDY0NA==', 'logs': ['expected_improvement: 3.322241e-02', 'predicted_value: -4.589486e-01', 'predicted_value_std_dev: 2.741859e-01', 'success_probability: 7.430459e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmMxaHcxbjRtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:41 INFO Agent received command: run
2024-05-20 17:17:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:17:41 ERROR Exception while processing command: {'run_id': '5qgh9v14', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDY3MA==', 'logs': ['expected_improvement: 3.976011e-02', 'predicted_value: -4.799979e-01', 'predicted_value_std_dev: 2.708160e-01', 'success_probability: 8.748581e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVxZ2g5djE0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:48 INFO Agent received command: run
2024-05-20 17:17:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:17:48 ERROR Exception while processing command: {'run_id': '4jp127fb', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDY4NQ==', 'logs': ['expected_improvement: 7.701836e-02', 'predicted_value: -5.496430e-01', 'predicted_value_std_dev: 2.599726e-01', 'success_probability: 1.533923e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjRqcDEyN2ZiOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:17:54 INFO Agent received command: run
2024-05-20 17:17:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:17:54 ERROR Exception while processing command: {'run_id': 'y8gybjn9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDY4OQ==', 'logs': ['expected_improvement: 3.439456e-02', 'predicted_value: -4.697799e-01', 'predicted_value_std_dev: 2.652315e-01', 'success_probability: 7.657221e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnk4Z3liam45OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:00 INFO Agent received command: run
2024-05-20 17:18:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:18:00 ERROR Exception while processing command: {'run_id': '2ph6ayc9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDcwNQ==', 'logs': ['expected_improvement: 5.569667e-02', 'predicted_value: -5.555014e-01', 'predicted_value_std_dev: 2.422559e-01', 'success_probability: 1.156389e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjJwaDZheWM5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:06 INFO Agent received command: run
2024-05-20 17:18:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 17:18:06 ERROR Exception while processing command: {'run_id': '2awjx8rz', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDczNA==', 'logs': ['expected_improvement: 2.721132e-02', 'predicted_value: -4.553826e-01', 'predicted_value_std_dev: 2.568754e-01', 'success_probability: 6.288115e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjJhd2p4OHJ6OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:12 INFO Agent received command: run
2024-05-20 17:18:12 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 17:18:12 ERROR Exception while processing command: {'run_id': '4texyzin', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDc1MQ==', 'logs': ['expected_improvement: 3.377753e-02', 'predicted_value: -4.769427e-01', 'predicted_value_std_dev: 2.659793e-01', 'success_probability: 7.535288e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjR0ZXh5emluOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:18 INFO Agent received command: run
2024-05-20 17:18:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:18:18 ERROR Exception while processing command: {'run_id': 'y0bcxnud', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDc3MQ==', 'logs': ['expected_improvement: 5.498295e-02', 'predicted_value: -5.121780e-01', 'predicted_value_std_dev: 2.620297e-01', 'success_probability: 1.133111e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnkwYmN4bnVkOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:24 INFO Agent received command: run
2024-05-20 17:18:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 17:18:24 ERROR Exception while processing command: {'run_id': '2ixf79yl', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDc4OQ==', 'logs': ['expected_improvement: 3.628002e-02', 'predicted_value: -4.611191e-01', 'predicted_value_std_dev: 2.832785e-01', 'success_probability: 8.007666e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjJpeGY3OXlsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:30 INFO Agent received command: run
2024-05-20 17:18:30 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:18:30 ERROR Exception while processing command: {'run_id': 'x7gsre9y', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDgxNg==', 'logs': ['expected_improvement: 6.233074e-02', 'predicted_value: -5.227262e-01', 'predicted_value_std_dev: 2.686841e-01', 'success_probability: 1.271636e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOng3Z3NyZTl5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:36 INFO Agent received command: run
2024-05-20 17:18:36 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:18:36 ERROR Exception while processing command: {'run_id': 'g3xnt9do', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDgyMQ==', 'logs': ['expected_improvement: 3.510865e-02', 'predicted_value: -4.622225e-01', 'predicted_value_std_dev: 2.657473e-01', 'success_probability: 7.803278e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmczeG50OWRvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:41 INFO Agent received command: run
2024-05-20 17:18:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-20 17:18:41 ERROR Exception while processing command: {'run_id': 'utr5tu1m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDg2OQ==', 'logs': ['expected_improvement: 3.885136e-02', 'predicted_value: -4.789193e-01', 'predicted_value_std_dev: 2.638389e-01', 'success_probability: 8.478027e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnV0cjV0dTFtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:47 INFO Agent received command: run
2024-05-20 17:18:47 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 17:18:47 ERROR Exception while processing command: {'run_id': 'xmmfasj9', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDg4Ng==', 'logs': ['expected_improvement: 4.007607e-02', 'predicted_value: -4.640515e-01', 'predicted_value_std_dev: 2.809479e-01', 'success_probability: 8.708841e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnhtbWZhc2o5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:18:54 INFO Agent received command: run
2024-05-20 17:18:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:18:54 ERROR Exception while processing command: {'run_id': '83b9fhwx', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDkwMA==', 'logs': ['expected_improvement: 3.507992e-02', 'predicted_value: -4.714094e-01', 'predicted_value_std_dev: 2.647286e-01', 'success_probability: 7.779889e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjgzYjlmaHd4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:00 INFO Agent received command: run
2024-05-20 17:19:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 17:19:00 ERROR Exception while processing command: {'run_id': '5140grb3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NDkwNA==', 'logs': ['expected_improvement: 4.275309e-02', 'predicted_value: -4.936431e-01', 'predicted_value_std_dev: 2.575586e-01', 'success_probability: 9.199151e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjUxNDBncmIzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:19 INFO Agent received command: run
2024-05-20 17:19:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:19:19 ERROR Exception while processing command: {'run_id': 'mumuzd2m', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTAxNA==', 'logs': ['expected_improvement: 5.087372e-02', 'predicted_value: -4.908520e-01', 'predicted_value_std_dev: 2.777815e-01', 'success_probability: 1.066919e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm11bXV6ZDJtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:25 INFO Agent received command: run
2024-05-20 17:19:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:19:25 ERROR Exception while processing command: {'run_id': 'hm2fu08n', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTAyOQ==', 'logs': ['expected_improvement: 3.905879e-02', 'predicted_value: -5.071492e-01', 'predicted_value_std_dev: 2.566203e-01', 'success_probability: 8.517293e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmhtMmZ1MDhuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:31 INFO Agent received command: run
2024-05-20 17:19:31 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:19:31 ERROR Exception while processing command: {'run_id': 'ng68tqo1', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTA1Ng==', 'logs': ['expected_improvement: 5.244902e-02', 'predicted_value: -5.293379e-01', 'predicted_value_std_dev: 2.434223e-01', 'success_probability: 1.091545e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm5nNjh0cW8xOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:36 INFO Agent received command: run
2024-05-20 17:19:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-20 17:19:36 ERROR Exception while processing command: {'run_id': 'rq81ywcz', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTA2MA==', 'logs': ['expected_improvement: 2.618163e-02', 'predicted_value: -4.389426e-01', 'predicted_value_std_dev: 2.624552e-01', 'success_probability: 6.068447e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnJxODF5d2N6OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:43 INFO Agent received command: run
2024-05-20 17:19:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:19:43 ERROR Exception while processing command: {'run_id': 'bpylkmq2', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTA3Mw==', 'logs': ['expected_improvement: 3.312014e-02', 'predicted_value: -4.475726e-01', 'predicted_value_std_dev: 2.691824e-01', 'success_probability: 7.425065e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJweWxrbXEyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:19:49 INFO Agent received command: run
2024-05-20 17:19:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:19:49 ERROR Exception while processing command: {'run_id': 'hftmp1x6', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTA5NA==', 'logs': ['expected_improvement: 6.251773e-02', 'predicted_value: -5.284979e-01', 'predicted_value_std_dev: 2.439946e-01', 'success_probability: 1.261374e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmhmdG1wMXg2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:20:13 INFO Agent received command: run
2024-05-20 17:20:13 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:20:13 ERROR Exception while processing command: {'run_id': 'n0f4xd89', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTE1Ng==', 'logs': ['expected_improvement: 4.208358e-02', 'predicted_value: -4.969014e-01', 'predicted_value_std_dev: 2.734962e-01', 'success_probability: 9.065082e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOm4wZjR4ZDg5OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:20:58 INFO Agent received command: run
2024-05-20 17:20:58 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:20:58 ERROR Exception while processing command: {'run_id': 'dvjtz09o', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTI1Mw==', 'logs': ['expected_improvement: 7.971147e-02', 'predicted_value: -5.301240e-01', 'predicted_value_std_dev: 2.812988e-01', 'success_probability: 1.547503e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmR2anR6MDlvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:03 INFO Agent received command: run
2024-05-20 17:21:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:21:03 ERROR Exception while processing command: {'run_id': 'tlwyq8k0', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTMwNA==', 'logs': ['expected_improvement: 4.082084e-02', 'predicted_value: -4.528142e-01', 'predicted_value_std_dev: 2.756924e-01', 'success_probability: 8.870167e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnRsd3lxOGswOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:09 INFO Agent received command: run
2024-05-20 17:21:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 17:21:09 ERROR Exception while processing command: {'run_id': 'fdwjbp0h', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTMyOQ==', 'logs': ['expected_improvement: 2.651212e-02', 'predicted_value: -4.074293e-01', 'predicted_value_std_dev: 2.737499e-01', 'success_probability: 6.133823e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmZkd2picDBoOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:15 INFO Agent received command: run
2024-05-20 17:21:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:21:15 ERROR Exception while processing command: {'run_id': 'fowowiai', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTMzMw==', 'logs': ['expected_improvement: 4.311757e-02', 'predicted_value: -4.952717e-01', 'predicted_value_std_dev: 2.639171e-01', 'success_probability: 9.256184e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmZvd293aWFpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:21 INFO Agent received command: run
2024-05-20 17:21:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:21:21 ERROR Exception while processing command: {'run_id': 'f5jwzon1', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTM1Nw==', 'logs': ['expected_improvement: 3.518025e-02', 'predicted_value: -4.859512e-01', 'predicted_value_std_dev: 2.604609e-01', 'success_probability: 7.825531e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmY1and6b24xOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:28 INFO Agent received command: run
2024-05-20 17:21:28 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:21:28 ERROR Exception while processing command: {'run_id': '7zy1apav', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTM4Ng==', 'logs': ['expected_improvement: 3.940306e-02', 'predicted_value: -4.664552e-01', 'predicted_value_std_dev: 2.769099e-01', 'success_probability: 8.580773e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjd6eTFhcGF2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:34 INFO Agent received command: run
2024-05-20 17:21:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:21:34 ERROR Exception while processing command: {'run_id': 'w34quwqh', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTM5MQ==', 'logs': ['expected_improvement: 4.408173e-02', 'predicted_value: -4.821490e-01', 'predicted_value_std_dev: 2.758167e-01', 'success_probability: 9.487482e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnczNHF1d3FoOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:40 INFO Agent received command: run
2024-05-20 17:21:40 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:21:40 ERROR Exception while processing command: {'run_id': 'mz2ddkt8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTQwNw==', 'logs': ['expected_improvement: 4.730348e-02', 'predicted_value: -5.008359e-01', 'predicted_value_std_dev: 2.823962e-01', 'success_probability: 1.001502e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm16MmRka3Q4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:46 INFO Agent received command: run
2024-05-20 17:21:46 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:21:46 ERROR Exception while processing command: {'run_id': 'jlczhmpd', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTQxMQ==', 'logs': ['expected_improvement: 4.561277e-02', 'predicted_value: -5.254919e-01', 'predicted_value_std_dev: 2.569095e-01', 'success_probability: 9.711748e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmpsY3pobXBkOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:52 INFO Agent received command: run
2024-05-20 17:21:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:21:52 ERROR Exception while processing command: {'run_id': 'z5t53kgs', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTQ0NQ==', 'logs': ['expected_improvement: 3.270188e-02', 'predicted_value: -4.687295e-01', 'predicted_value_std_dev: 2.691376e-01', 'success_probability: 7.343227e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOno1dDUza2dzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:21:58 INFO Agent received command: run
2024-05-20 17:21:58 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-20 17:21:58 ERROR Exception while processing command: {'run_id': 'j7i5gl0f', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTQ2MQ==', 'logs': ['expected_improvement: 3.115030e-02', 'predicted_value: -4.622140e-01', 'predicted_value_std_dev: 2.496654e-01', 'success_probability: 7.036013e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmo3aTVnbDBmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:04 INFO Agent received command: run
2024-05-20 17:22:04 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:22:04 ERROR Exception while processing command: {'run_id': 'jpuymrzd', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTQ5OA==', 'logs': ['expected_improvement: 2.885628e-02', 'predicted_value: -4.562993e-01', 'predicted_value_std_dev: 2.612847e-01', 'success_probability: 6.593269e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmpwdXltcnpkOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:09 INFO Agent received command: run
2024-05-20 17:22:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:22:09 ERROR Exception while processing command: {'run_id': 'cxadhb5w', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTUxMw==', 'logs': ['expected_improvement: 3.431367e-02', 'predicted_value: -4.284080e-01', 'predicted_value_std_dev: 2.793230e-01', 'success_probability: 7.636207e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmN4YWRoYjV3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:15 INFO Agent received command: run
2024-05-20 17:22:15 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:22:15 ERROR Exception while processing command: {'run_id': '4oxmb6jp', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTUxOA==', 'logs': ['expected_improvement: 3.148928e-02', 'predicted_value: -4.644433e-01', 'predicted_value_std_dev: 2.687131e-01', 'success_probability: 7.100886e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjRveG1iNmpwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:21 INFO Agent received command: run
2024-05-20 17:22:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:22:21 ERROR Exception while processing command: {'run_id': 'zbqfsnwd', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTUzMw==', 'logs': ['expected_improvement: 6.254333e-02', 'predicted_value: -5.405069e-01', 'predicted_value_std_dev: 2.717372e-01', 'success_probability: 1.294219e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnpicWZzbndkOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:27 INFO Agent received command: run
2024-05-20 17:22:27 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: random
2024-05-20 17:22:27 ERROR Exception while processing command: {'run_id': '8j98pjsa', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTUzNQ==', 'logs': ['expected_improvement: 3.478603e-02', 'predicted_value: -4.832117e-01', 'predicted_value_std_dev: 2.640455e-01', 'success_probability: 7.724857e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjhqOThwanNhOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:22:39 INFO Agent received command: run
2024-05-20 17:22:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-20 17:22:39 ERROR Exception while processing command: {'run_id': 'qooua6zo', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTU5Mw==', 'logs': ['expected_improvement: 3.026049e-02', 'predicted_value: -4.525780e-01', 'predicted_value_std_dev: 2.735157e-01', 'success_probability: 6.865058e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnFvb3VhNnpvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:21 INFO Agent received command: run
2024-05-20 17:23:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:23:21 ERROR Exception while processing command: {'run_id': 'zinygsxw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTcxMw==', 'logs': ['expected_improvement: 4.444360e-02', 'predicted_value: -4.908544e-01', 'predicted_value_std_dev: 2.839390e-01', 'success_probability: 9.528567e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnppbnlnc3h3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:27 INFO Agent received command: run
2024-05-20 17:23:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:23:27 ERROR Exception while processing command: {'run_id': '26r5ioqn', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTcxNg==', 'logs': ['expected_improvement: 3.121522e-02', 'predicted_value: -4.576697e-01', 'predicted_value_std_dev: 2.665805e-01', 'success_probability: 7.054928e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjI2cjVpb3FuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:33 INFO Agent received command: run
2024-05-20 17:23:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: random
2024-05-20 17:23:33 ERROR Exception while processing command: {'run_id': 'mmetd460', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTcyMA==', 'logs': ['expected_improvement: 4.614875e-02', 'predicted_value: -4.482448e-01', 'predicted_value_std_dev: 2.790008e-01', 'success_probability: 9.789805e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOm1tZXRkNDYwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:39 INFO Agent received command: run
2024-05-20 17:23:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-20 17:23:39 ERROR Exception while processing command: {'run_id': 'tbzq0mfe', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTcyNA==', 'logs': ['expected_improvement: 2.686740e-02', 'predicted_value: -4.290035e-01', 'predicted_value_std_dev: 2.649731e-01', 'success_probability: 6.203934e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnRienEwbWZlOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:44 INFO Agent received command: run
2024-05-20 17:23:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 17:23:44 ERROR Exception while processing command: {'run_id': 'h7cmeisw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTczMA==', 'logs': ['expected_improvement: 3.216326e-02', 'predicted_value: -4.454659e-01', 'predicted_value_std_dev: 2.755322e-01', 'success_probability: 7.234973e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmg3Y21laXN3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:50 INFO Agent received command: run
2024-05-20 17:23:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:23:50 ERROR Exception while processing command: {'run_id': 'e0c7hrrf', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTc1Nw==', 'logs': ['expected_improvement: 3.921225e-02', 'predicted_value: -4.895479e-01', 'predicted_value_std_dev: 2.613602e-01', 'success_probability: 8.550979e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmUwYzdocnJmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:23:56 INFO Agent received command: run
2024-05-20 17:23:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:23:56 ERROR Exception while processing command: {'run_id': '0v3rvejb', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTc2Mg==', 'logs': ['expected_improvement: 2.744014e-02', 'predicted_value: -4.355981e-01', 'predicted_value_std_dev: 2.769633e-01', 'success_probability: 6.316594e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjB2M3J2ZWpiOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:02 INFO Agent received command: run
2024-05-20 17:24:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:24:02 ERROR Exception while processing command: {'run_id': 'd8df24tw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTc2Nw==', 'logs': ['expected_improvement: 2.640148e-02', 'predicted_value: -4.456196e-01', 'predicted_value_std_dev: 2.576904e-01', 'success_probability: 6.113478e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmQ4ZGYyNHR3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:08 INFO Agent received command: run
2024-05-20 17:24:08 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:24:08 ERROR Exception while processing command: {'run_id': 'jwxufcu8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTc4NA==', 'logs': ['expected_improvement: 3.460036e-02', 'predicted_value: -4.538925e-01', 'predicted_value_std_dev: 2.812351e-01', 'success_probability: 7.690041e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmp3eHVmY3U4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:19 INFO Agent received command: run
2024-05-20 17:24:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-20 17:24:19 ERROR Exception while processing command: {'run_id': 'onifb71n', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTgxMQ==', 'logs': ['expected_improvement: 2.994767e-02', 'predicted_value: -4.486005e-01', 'predicted_value_std_dev: 2.726607e-01', 'success_probability: 6.804726e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOm9uaWZiNzFuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:25 INFO Agent received command: run
2024-05-20 17:24:25 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: random
2024-05-20 17:24:25 ERROR Exception while processing command: {'run_id': 'h20xoczi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTgxNw==', 'logs': ['expected_improvement: 3.027144e-02', 'predicted_value: -4.337518e-01', 'predicted_value_std_dev: 2.801587e-01', 'success_probability: 6.867167e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmgyMHhvY3ppOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:31 INFO Agent received command: run
2024-05-20 17:24:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 17:24:31 ERROR Exception while processing command: {'run_id': 'ffirwiiz', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTg0Ng==', 'logs': ['expected_improvement: 3.786619e-02', 'predicted_value: -4.450263e-01', 'predicted_value_std_dev: 2.860669e-01', 'success_probability: 8.297070e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmZmaXJ3aWl6OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:37 INFO Agent received command: run
2024-05-20 17:24:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:24:37 ERROR Exception while processing command: {'run_id': 'bpems70j', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTg1MQ==', 'logs': ['expected_improvement: 4.679139e-02', 'predicted_value: -5.092676e-01', 'predicted_value_std_dev: 2.616039e-01', 'success_probability: 9.912637e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJwZW1zNzBqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:43 INFO Agent received command: run
2024-05-20 17:24:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:24:43 ERROR Exception while processing command: {'run_id': 'e01fk0oa', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 32}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTg2NA==', 'logs': ['expected_improvement: 2.450976e-02', 'predicted_value: -4.031630e-01', 'predicted_value_std_dev: 2.806349e-01', 'success_probability: 5.735325e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmUwMWZrMG9hOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:24:56 INFO Agent received command: run
2024-05-20 17:24:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:24:56 ERROR Exception while processing command: {'run_id': 'omyo3x90', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTkwMw==', 'logs': ['expected_improvement: 4.376381e-02', 'predicted_value: -4.988095e-01', 'predicted_value_std_dev: 2.616873e-01', 'success_probability: 9.367535e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm9teW8zeDkwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:02 INFO Agent received command: run
2024-05-20 17:25:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:25:02 ERROR Exception while processing command: {'run_id': '7d2sx8gr', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTkwOQ==', 'logs': ['expected_improvement: 4.402490e-02', 'predicted_value: -4.853728e-01', 'predicted_value_std_dev: 2.773918e-01', 'success_probability: 9.434187e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjdkMnN4OGdyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:08 INFO Agent received command: run
2024-05-20 17:25:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:25:08 ERROR Exception while processing command: {'run_id': 'q5ywuos7', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTkyOQ==', 'logs': ['expected_improvement: 3.812182e-02', 'predicted_value: -4.630251e-01', 'predicted_value_std_dev: 2.725901e-01', 'success_probability: 8.381202e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnE1eXd1b3M3OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:20 INFO Agent received command: run
2024-05-20 17:25:20 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:25:20 ERROR Exception while processing command: {'run_id': 'hguf3yju', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTk1NA==', 'logs': ['expected_improvement: 5.399728e-02', 'predicted_value: -5.129318e-01', 'predicted_value_std_dev: 2.623551e-01', 'success_probability: 1.115980e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmhndWYzeWp1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:26 INFO Agent received command: run
2024-05-20 17:25:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 17:25:26 ERROR Exception while processing command: {'run_id': 'pt41o7ej', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTk2MA==', 'logs': ['expected_improvement: 4.167431e-02', 'predicted_value: -4.842408e-01', 'predicted_value_std_dev: 2.768339e-01', 'success_probability: 9.023931e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnB0NDFvN2VqOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:38 INFO Agent received command: run
2024-05-20 17:25:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:25:38 ERROR Exception while processing command: {'run_id': '6i8239bm', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTk5MA==', 'logs': ['expected_improvement: 6.947022e-02', 'predicted_value: -5.627778e-01', 'predicted_value_std_dev: 2.544777e-01', 'success_probability: 1.416350e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjZpODIzOWJtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:44 INFO Agent received command: run
2024-05-20 17:25:44 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:25:44 ERROR Exception while processing command: {'run_id': '9mdld74o', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NTk5NQ==', 'logs': ['expected_improvement: 5.033124e-02', 'predicted_value: -4.953711e-01', 'predicted_value_std_dev: 2.677285e-01', 'success_probability: 1.056716e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjltZGxkNzRvOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:50 INFO Agent received command: run
2024-05-20 17:25:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:25:50 ERROR Exception while processing command: {'run_id': '5qx5nysb', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjAwMg==', 'logs': ['expected_improvement: 4.179323e-02', 'predicted_value: -4.858459e-01', 'predicted_value_std_dev: 2.785093e-01', 'success_probability: 9.015112e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVxeDVueXNiOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:25:56 INFO Agent received command: run
2024-05-20 17:25:56 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:25:56 ERROR Exception while processing command: {'run_id': 'vfs4ew7t', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjA0Ng==', 'logs': ['expected_improvement: 2.634015e-02', 'predicted_value: -4.306924e-01', 'predicted_value_std_dev: 2.743753e-01', 'success_probability: 6.099823e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnZmczRldzd0OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:02 INFO Agent received command: run
2024-05-20 17:26:02 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-20 17:26:02 ERROR Exception while processing command: {'run_id': '0endz5eb', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjA1Mw==', 'logs': ['expected_improvement: 3.954450e-02', 'predicted_value: -4.698367e-01', 'predicted_value_std_dev: 2.720583e-01', 'success_probability: 8.604765e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjBlbmR6NWViOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:08 INFO Agent received command: run
2024-05-20 17:26:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:26:08 ERROR Exception while processing command: {'run_id': '8nl72n2f', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjA3Mw==', 'logs': ['expected_improvement: 2.786272e-02', 'predicted_value: -4.643037e-01', 'predicted_value_std_dev: 2.536000e-01', 'success_probability: 6.414465e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjhubDcybjJmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:14 INFO Agent received command: run
2024-05-20 17:26:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 17:26:14 ERROR Exception while processing command: {'run_id': '5rnvz7f5', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nesterov'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjA4Nw==', 'logs': ['expected_improvement: 4.156228e-02', 'predicted_value: -4.773552e-01', 'predicted_value_std_dev: 2.768925e-01', 'success_probability: 8.996128e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjVybnZ6N2Y1OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:20 INFO Agent received command: run
2024-05-20 17:26:20 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:26:20 ERROR Exception while processing command: {'run_id': 'iu9lcz2s', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 3}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjExNA==', 'logs': ['expected_improvement: 3.274900e-02', 'predicted_value: -4.343503e-01', 'predicted_value_std_dev: 2.928005e-01', 'success_probability: 7.340781e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOml1OWxjejJzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:26 INFO Agent received command: run
2024-05-20 17:26:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:26:26 ERROR Exception while processing command: {'run_id': 'bmkw7zu8', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjExOA==', 'logs': ['expected_improvement: 3.589593e-02', 'predicted_value: -4.504194e-01', 'predicted_value_std_dev: 2.804634e-01', 'success_probability: 7.946645e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJta3c3enU4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:32 INFO Agent received command: run
2024-05-20 17:26:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:26:32 ERROR Exception while processing command: {'run_id': 'ftrv610c', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjEzMQ==', 'logs': ['expected_improvement: 4.268099e-02', 'predicted_value: -4.826940e-01', 'predicted_value_std_dev: 2.716026e-01', 'success_probability: 9.181525e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmZ0cnY2MTBjOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:38 INFO Agent received command: run
2024-05-20 17:26:38 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:26:38 ERROR Exception while processing command: {'run_id': 'inewpmp0', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjE2OQ==', 'logs': ['expected_improvement: 3.915759e-02', 'predicted_value: -4.688985e-01', 'predicted_value_std_dev: 2.767088e-01', 'success_probability: 8.571441e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmluZXdwbXAwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:26:54 INFO Agent received command: run
2024-05-20 17:26:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:26:54 ERROR Exception while processing command: {'run_id': 'gas79g7x', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjI0Mg==', 'logs': ['expected_improvement: 2.625597e-02', 'predicted_value: -4.044549e-01', 'predicted_value_std_dev: 2.910858e-01', 'success_probability: 6.083438e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmdhczc5Zzd4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:00 INFO Agent received command: run
2024-05-20 17:27:00 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: random
2024-05-20 17:27:00 ERROR Exception while processing command: {'run_id': 'z5tfe49k', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.9}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjI1MA==', 'logs': ['expected_improvement: 3.622313e-02', 'predicted_value: -4.621544e-01', 'predicted_value_std_dev: 2.749922e-01', 'success_probability: 7.993076e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOno1dGZlNDlrOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:07 INFO Agent received command: run
2024-05-20 17:27:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:27:07 ERROR Exception while processing command: {'run_id': 'bl1mnn8p', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjI4Mw==', 'logs': ['expected_improvement: 3.490111e-02', 'predicted_value: -4.415743e-01', 'predicted_value_std_dev: 2.938123e-01', 'success_probability: 7.769898e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmJsMW1ubjhwOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:13 INFO Agent received command: run
2024-05-20 17:27:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 17:27:13 ERROR Exception while processing command: {'run_id': 'vzouavpq', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjI5Mg==', 'logs': ['expected_improvement: 3.100193e-02', 'predicted_value: -4.528229e-01', 'predicted_value_std_dev: 2.661805e-01', 'success_probability: 7.007574e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOnZ6b3VhdnBxOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:25 INFO Agent received command: run
2024-05-20 17:27:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:27:25 ERROR Exception while processing command: {'run_id': 'co0w8xxi', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjMyOQ==', 'logs': ['expected_improvement: 3.538442e-02', 'predicted_value: -4.471424e-01', 'predicted_value_std_dev: 2.815848e-01', 'success_probability: 7.840518e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmNvMHc4eHhpOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:32 INFO Agent received command: run
2024-05-20 17:27:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:27:32 ERROR Exception while processing command: {'run_id': 'mzt87qbf', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjM1OA==', 'logs': ['expected_improvement: 4.617549e-02', 'predicted_value: -4.899636e-01', 'predicted_value_std_dev: 2.756038e-01', 'success_probability: 9.852081e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOm16dDg3cWJmOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:38 INFO Agent received command: run
2024-05-20 17:27:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: random
2024-05-20 17:27:38 ERROR Exception while processing command: {'run_id': '4tncjes6', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 32}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjM2NA==', 'logs': ['expected_improvement: 2.406268e-02', 'predicted_value: -4.123090e-01', 'predicted_value_std_dev: 2.818855e-01', 'success_probability: 5.645547e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOjR0bmNqZXM2OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:44 INFO Agent received command: run
2024-05-20 17:27:44 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:27:44 ERROR Exception while processing command: {'run_id': '2ps9eopm', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'sigmoid'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'momentum'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjM3MA==', 'logs': ['expected_improvement: 2.778750e-02', 'predicted_value: -4.417427e-01', 'predicted_value_std_dev: 2.740393e-01', 'success_probability: 6.385118e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjJwczllb3BtOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:50 INFO Agent received command: run
2024-05-20 17:27:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:27:50 ERROR Exception while processing command: {'run_id': 'c0cm4r7x', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjM3NA==', 'logs': ['expected_improvement: 2.084615e-02', 'predicted_value: -4.182207e-01', 'predicted_value_std_dev: 2.703135e-01', 'success_probability: 5.013261e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmMwY200cjd4OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:27:56 INFO Agent received command: run
2024-05-20 17:27:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:27:56 ERROR Exception while processing command: {'run_id': '89n8g0v3', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjQwMA==', 'logs': ['expected_improvement: 2.685228e-02', 'predicted_value: -4.182487e-01', 'predicted_value_std_dev: 2.865803e-01', 'success_probability: 6.202845e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjg5bjhnMHYzOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:02 INFO Agent received command: run
2024-05-20 17:28:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:28:02 ERROR Exception while processing command: {'run_id': 'fut57po5', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.9}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'adam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjQxMw==', 'logs': ['expected_improvement: 4.212472e-02', 'predicted_value: -4.862064e-01', 'predicted_value_std_dev: 2.691991e-01', 'success_probability: 9.078881e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmZ1dDU3cG81OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:15 INFO Agent received command: run
2024-05-20 17:28:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:28:15 ERROR Exception while processing command: {'run_id': '5u6evbyh', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjQ1Nw==', 'logs': ['expected_improvement: 5.270884e-02', 'predicted_value: -5.476643e-01', 'predicted_value_std_dev: 2.568247e-01', 'success_probability: 1.205958e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjV1NmV2YnloOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:21 INFO Agent received command: run
2024-05-20 17:28:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:28:21 ERROR Exception while processing command: {'run_id': 'rning4xn', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.0001}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'nadam'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjQ4Mw==', 'logs': ['expected_improvement: 3.442531e-02', 'predicted_value: -4.548157e-01', 'predicted_value_std_dev: 2.628102e-01', 'success_probability: 7.725508e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOnJuaW5nNHhuOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:27 INFO Agent received command: run
2024-05-20 17:28:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:28:27 ERROR Exception while processing command: {'run_id': 'jcm37xnw', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 128}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjUwMg==', 'logs': ['expected_improvement: 4.440806e-02', 'predicted_value: -4.876603e-01', 'predicted_value_std_dev: 2.860692e-01', 'success_probability: 9.504552e-02', 'warnings: '], 'run_storage_id': 'UnVuOnYxOmpjbTM3eG53OmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:33 INFO Agent received command: run
2024-05-20 17:28:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 17:28:33 ERROR Exception while processing command: {'run_id': '4p833492', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'tanh'}, 'alpha': {'value': 0.001}, 'batch_size': {'value': 64}, 'beta1': {'value': 0.99}, 'epochs': {'value': 5}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 0.01}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 4}, 'optimizer': {'value': 'sgd'}, 'weight_init': {'value': 'he'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjUzOA==', 'logs': ['expected_improvement: 4.809266e-02', 'predicted_value: -4.808119e-01', 'predicted_value_std_dev: 2.985246e-01', 'success_probability: 1.025036e-01', 'warnings: '], 'run_storage_id': 'UnVuOnYxOjRwODMzNDkyOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:39 INFO Agent received command: run
2024-05-20 17:28:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: random
2024-05-20 17:28:39 ERROR Exception while processing command: {'run_id': 'fcicpp7l', 'program': 'train.py', 'type': 'run', 'args': {'activation': {'value': 'ReLU'}, 'alpha': {'value': 0.0001}, 'batch_size': {'value': 16}, 'beta1': {'value': 0.99}, 'epochs': {'value': 10}, 'hidden_sizes': {'value': 64}, 'learning_rate': {'value': 1e-05}, 'loss': {'value': 'cross_entropy'}, 'num_layers': {'value': 5}, 'optimizer': {'value': 'rmsprop'}, 'weight_init': {'value': 'random'}}, 'runqueue_item_id': 'UnVuUXVldWVJdGVtOjU2NDA1NjU1Mw==', 'logs': ['expected_improvement: 2.770725e-02', 'predicted_value: -3.983098e-01', 'predicted_value_std_dev: 2.869913e-01', 'success_probability: 6.368983e-02', 'warnings: \n Some dimmensions of kernel are close to their bounds (bad fit), the next sample will be a random sample within parameter space'], 'run_storage_id': 'UnVuOnYxOmZjaWNwcDdsOmNzNjkxMC1hc3NpZ25tZW50MTpzcmlqYTE3MTk5'}
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 324, in _process_command
    result = self._command_run(command)
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/wandb_agent.py", line 383, in _command_run
    wandb_lib.config_util.save_config_file_from_dict(
  File "/nlsasfs/home/ai4bharat/praveens/miniconda3/envs/dl_as/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py", line 60, in save_config_file_from_dict
    with open(config_filename, "w") as conf_file:
OSError: [Errno 122] Disk quota exceeded
2024-05-20 17:28:45 INFO Agent received command: run
2024-05-20 17:28:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 17:28:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 17:28:50 INFO Running runs: ['2kikduee']
2024-05-20 17:31:02 INFO Cleaning up finished run: 2kikduee
2024-05-20 17:31:04 INFO Agent received command: run
2024-05-20 17:31:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:31:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 17:31:09 INFO Running runs: ['4fz1vdql']
2024-05-20 17:33:37 INFO Cleaning up finished run: 4fz1vdql
2024-05-20 17:33:38 INFO Agent received command: run
2024-05-20 17:33:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 17:33:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 17:33:43 INFO Running runs: ['3n9xnap5']
2024-05-20 17:35:40 INFO Cleaning up finished run: 3n9xnap5
2024-05-20 17:35:41 INFO Agent received command: run
2024-05-20 17:35:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:35:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 17:35:46 INFO Running runs: ['jfoae9tw']
2024-05-20 17:37:26 INFO Cleaning up finished run: jfoae9tw
2024-05-20 17:37:32 INFO Agent received command: run
2024-05-20 17:37:32 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 17:37:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 17:37:38 INFO Running runs: ['qjuyj82r']
2024-05-20 17:39:50 INFO Cleaning up finished run: qjuyj82r
2024-05-20 17:39:51 INFO Agent received command: run
2024-05-20 17:39:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:39:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 17:39:56 INFO Running runs: ['ziiyefnz']
2024-05-20 17:41:05 INFO Cleaning up finished run: ziiyefnz
2024-05-20 17:41:06 INFO Agent received command: run
2024-05-20 17:41:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:41:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 17:41:11 INFO Running runs: ['q4nwv1ma']
2024-05-20 17:42:30 INFO Cleaning up finished run: q4nwv1ma
2024-05-20 17:42:31 INFO Agent received command: run
2024-05-20 17:42:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 17:42:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 17:42:36 INFO Running runs: ['5392xzbd']
2024-05-20 17:44:38 INFO Cleaning up finished run: 5392xzbd
2024-05-20 17:44:39 INFO Agent received command: run
2024-05-20 17:44:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: random
2024-05-20 17:44:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=random
2024-05-20 17:44:44 INFO Running runs: ['fn030eol']
2024-05-20 17:45:58 INFO Cleaning up finished run: fn030eol
2024-05-20 17:45:59 INFO Agent received command: run
2024-05-20 17:45:59 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:45:59 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 17:46:04 INFO Running runs: ['mpyw0n5q']
2024-05-20 17:47:55 INFO Cleaning up finished run: mpyw0n5q
2024-05-20 17:47:56 INFO Agent received command: run
2024-05-20 17:47:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:47:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 17:48:01 INFO Running runs: ['yr8youx9']
2024-05-20 17:50:34 INFO Cleaning up finished run: yr8youx9
2024-05-20 17:50:35 INFO Agent received command: run
2024-05-20 17:50:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 17:50:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 17:50:40 INFO Running runs: ['ocrvbpbj']
2024-05-20 17:51:59 INFO Cleaning up finished run: ocrvbpbj
2024-05-20 17:52:00 INFO Agent received command: run
2024-05-20 17:52:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 17:52:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 17:52:05 INFO Running runs: ['sa56tlo0']
2024-05-20 17:53:19 INFO Cleaning up finished run: sa56tlo0
2024-05-20 17:53:21 INFO Agent received command: run
2024-05-20 17:53:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 17:53:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 17:53:26 INFO Running runs: ['8fgauz35']
2024-05-20 17:56:04 INFO Cleaning up finished run: 8fgauz35
2024-05-20 17:56:05 INFO Agent received command: run
2024-05-20 17:56:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 17:56:05 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 17:56:10 INFO Running runs: ['u2rkpwjt']
2024-05-20 17:57:56 INFO Cleaning up finished run: u2rkpwjt
2024-05-20 17:57:57 INFO Agent received command: run
2024-05-20 17:57:57 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: he
2024-05-20 17:57:57 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=he
2024-05-20 17:58:02 INFO Running runs: ['spbw1ral']
2024-05-20 17:59:32 INFO Cleaning up finished run: spbw1ral
2024-05-20 17:59:33 INFO Agent received command: run
2024-05-20 17:59:33 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: random
2024-05-20 17:59:33 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=random
2024-05-20 17:59:38 INFO Running runs: ['luspeq9i']
2024-05-20 18:01:35 INFO Cleaning up finished run: luspeq9i
2024-05-20 18:01:53 INFO Agent received command: run
2024-05-20 18:01:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 18:01:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 18:01:58 INFO Running runs: ['ns1u1bpp']
2024-05-20 18:04:06 INFO Cleaning up finished run: ns1u1bpp
2024-05-20 18:04:06 INFO Agent received command: run
2024-05-20 18:04:06 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 18:04:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 18:04:11 INFO Running runs: ['qrocatil']
2024-05-20 18:06:55 INFO Cleaning up finished run: qrocatil
2024-05-20 18:06:56 INFO Agent received command: run
2024-05-20 18:06:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 18:06:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 18:07:01 INFO Running runs: ['jq3zg2bh']
2024-05-20 18:08:52 INFO Cleaning up finished run: jq3zg2bh
2024-05-20 18:08:52 INFO Agent received command: run
2024-05-20 18:08:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 18:08:52 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 18:08:57 INFO Running runs: ['p1927gpl']
2024-05-20 18:10:27 INFO Cleaning up finished run: p1927gpl
2024-05-20 18:10:28 INFO Agent received command: run
2024-05-20 18:10:28 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 18:10:28 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 18:10:33 INFO Running runs: ['tjg7mh3k']
2024-05-20 18:12:03 INFO Cleaning up finished run: tjg7mh3k
2024-05-20 18:12:03 INFO Agent received command: run
2024-05-20 18:12:03 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 18:12:03 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 18:12:08 INFO Running runs: ['d4ovuaxi']
2024-05-20 18:13:54 INFO Cleaning up finished run: d4ovuaxi
2024-05-20 18:13:54 INFO Agent received command: run
2024-05-20 18:13:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 18:13:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 18:13:59 INFO Running runs: ['0wdnn9cy']
2024-05-20 18:15:08 INFO Cleaning up finished run: 0wdnn9cy
2024-05-20 18:15:08 INFO Agent received command: run
2024-05-20 18:15:08 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 18:15:08 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 18:15:13 INFO Running runs: ['9xxheo5y']
2024-05-20 18:16:17 INFO Cleaning up finished run: 9xxheo5y
2024-05-20 18:16:18 INFO Agent received command: run
2024-05-20 18:16:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 18:16:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 18:16:23 INFO Running runs: ['pojguk9s']
2024-05-20 18:18:04 INFO Cleaning up finished run: pojguk9s
2024-05-20 18:18:04 INFO Agent received command: run
2024-05-20 18:18:04 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 18:18:04 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 18:18:09 INFO Running runs: ['jmflq7uw']
2024-05-20 18:20:22 INFO Cleaning up finished run: jmflq7uw
2024-05-20 18:20:22 INFO Agent received command: run
2024-05-20 18:20:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 18:20:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 18:20:27 INFO Running runs: ['0qvabc3j']
2024-05-20 18:23:49 INFO Cleaning up finished run: 0qvabc3j
2024-05-20 18:23:49 INFO Agent received command: run
2024-05-20 18:23:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 18:23:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 18:23:54 INFO Running runs: ['c0ndtr4x']
2024-05-20 18:25:13 INFO Cleaning up finished run: c0ndtr4x
2024-05-20 18:25:14 INFO Agent received command: run
2024-05-20 18:25:14 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 18:25:14 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 18:25:19 INFO Running runs: ['vlev4skw']
2024-05-20 18:27:20 INFO Cleaning up finished run: vlev4skw
2024-05-20 18:27:21 INFO Agent received command: run
2024-05-20 18:27:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 18:27:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 18:27:26 INFO Running runs: ['keslfqn4']
2024-05-20 18:29:12 INFO Cleaning up finished run: keslfqn4
2024-05-20 18:29:12 INFO Agent received command: run
2024-05-20 18:29:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 18:29:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 18:29:17 INFO Running runs: ['87be79jh']
2024-05-20 18:31:08 INFO Cleaning up finished run: 87be79jh
2024-05-20 18:31:09 INFO Agent received command: run
2024-05-20 18:31:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 18:31:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 18:31:14 INFO Running runs: ['ag5h837m']
2024-05-20 18:33:21 INFO Cleaning up finished run: ag5h837m
2024-05-20 18:33:21 INFO Agent received command: run
2024-05-20 18:33:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 18:33:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 18:33:26 INFO Running runs: ['xa2yn0vu']
2024-05-20 18:35:33 INFO Cleaning up finished run: xa2yn0vu
2024-05-20 18:35:34 INFO Agent received command: run
2024-05-20 18:35:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 18:35:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 18:35:39 INFO Running runs: ['0t2kdjos']
2024-05-20 18:37:33 INFO Cleaning up finished run: 0t2kdjos
2024-05-20 18:37:33 INFO Agent received command: run
2024-05-20 18:37:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 18:37:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 18:37:38 INFO Running runs: ['kaovwa0s']
2024-05-20 18:39:19 INFO Cleaning up finished run: kaovwa0s
2024-05-20 18:39:19 INFO Agent received command: run
2024-05-20 18:39:19 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 18:39:19 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 18:39:24 INFO Running runs: ['tjwuijkn']
2024-05-20 18:41:53 INFO Cleaning up finished run: tjwuijkn
2024-05-20 18:41:53 INFO Agent received command: run
2024-05-20 18:41:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 18:41:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 18:41:58 INFO Running runs: ['4ko6k7iv']
2024-05-20 18:43:49 INFO Cleaning up finished run: 4ko6k7iv
2024-05-20 18:43:49 INFO Agent received command: run
2024-05-20 18:43:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 18:43:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 18:43:54 INFO Running runs: ['2jgkjxix']
2024-05-20 18:45:35 INFO Cleaning up finished run: 2jgkjxix
2024-05-20 18:45:35 INFO Agent received command: run
2024-05-20 18:45:35 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 18:45:35 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 18:45:40 INFO Running runs: ['z22ss75k']
2024-05-20 18:49:49 INFO Cleaning up finished run: z22ss75k
2024-05-20 18:49:49 INFO Agent received command: run
2024-05-20 18:49:49 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 18:49:49 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 18:49:54 INFO Running runs: ['ivnvpg3m']
2024-05-20 18:52:01 INFO Cleaning up finished run: ivnvpg3m
2024-05-20 18:52:02 INFO Agent received command: run
2024-05-20 18:52:02 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 18:52:02 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 18:52:07 INFO Running runs: ['o6ffqaj8']
2024-05-20 18:53:05 INFO Cleaning up finished run: o6ffqaj8
2024-05-20 18:53:05 INFO Agent received command: run
2024-05-20 18:53:05 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 18:53:05 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 18:53:10 INFO Running runs: ['rcyzwv8m']
2024-05-20 18:54:56 INFO Cleaning up finished run: rcyzwv8m
2024-05-20 18:54:56 INFO Agent received command: run
2024-05-20 18:54:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 18:54:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 18:55:01 INFO Running runs: ['dow887te']
2024-05-20 18:57:24 INFO Cleaning up finished run: dow887te
2024-05-20 18:57:25 INFO Agent received command: run
2024-05-20 18:57:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 18:57:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 18:57:30 INFO Running runs: ['ftd0pj63']
2024-05-20 18:59:16 INFO Cleaning up finished run: ftd0pj63
2024-05-20 18:59:16 INFO Agent received command: run
2024-05-20 18:59:16 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 18:59:16 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 18:59:21 INFO Running runs: ['y20thw8f']
2024-05-20 19:00:30 INFO Cleaning up finished run: y20thw8f
2024-05-20 19:00:30 INFO Agent received command: run
2024-05-20 19:00:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 19:00:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 19:00:35 INFO Running runs: ['ytynlhna']
2024-05-20 19:01:49 INFO Cleaning up finished run: ytynlhna
2024-05-20 19:01:50 INFO Agent received command: run
2024-05-20 19:01:50 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 19:01:50 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 19:01:55 INFO Running runs: ['r3rddsz5']
2024-05-20 19:03:51 INFO Cleaning up finished run: r3rddsz5
2024-05-20 19:03:53 INFO Agent received command: run
2024-05-20 19:03:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 19:03:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 19:03:58 INFO Running runs: ['pahrt2kf']
2024-05-20 19:05:17 INFO Cleaning up finished run: pahrt2kf
2024-05-20 19:05:18 INFO Agent received command: run
2024-05-20 19:05:18 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 19:05:18 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 19:05:23 INFO Running runs: ['xn70mwpi']
2024-05-20 19:06:48 INFO Cleaning up finished run: xn70mwpi
2024-05-20 19:06:48 INFO Agent received command: run
2024-05-20 19:06:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 19:06:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 19:06:53 INFO Running runs: ['0eegcdtm']
2024-05-20 19:08:50 INFO Cleaning up finished run: 0eegcdtm
2024-05-20 19:08:50 INFO Agent received command: run
2024-05-20 19:08:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 19:08:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 19:08:55 INFO Running runs: ['8wtu2m3e']
2024-05-20 19:11:55 INFO Cleaning up finished run: 8wtu2m3e
2024-05-20 19:11:55 INFO Agent received command: run
2024-05-20 19:11:55 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 19:11:55 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 19:12:00 INFO Running runs: ['rmxcr957']
2024-05-20 19:13:52 INFO Cleaning up finished run: rmxcr957
2024-05-20 19:13:52 INFO Agent received command: run
2024-05-20 19:13:52 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 19:13:52 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 19:13:57 INFO Running runs: ['3sajrwt5']
2024-05-20 19:16:15 INFO Cleaning up finished run: 3sajrwt5
2024-05-20 19:16:15 INFO Agent received command: run
2024-05-20 19:16:15 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 19:16:15 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 19:16:20 INFO Running runs: ['ds2k5hqi']
2024-05-20 19:20:14 INFO Cleaning up finished run: ds2k5hqi
2024-05-20 19:20:15 INFO Agent received command: run
2024-05-20 19:20:15 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 19:20:15 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 19:20:20 INFO Running runs: ['cb23noj0']
2024-05-20 19:22:12 INFO Cleaning up finished run: cb23noj0
2024-05-20 19:22:12 INFO Agent received command: run
2024-05-20 19:22:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 19:22:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 19:22:17 INFO Running runs: ['cjc8zgtk']
2024-05-20 19:25:39 INFO Cleaning up finished run: cjc8zgtk
2024-05-20 19:25:39 INFO Agent received command: run
2024-05-20 19:25:39 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 19:25:39 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 19:25:44 INFO Running runs: ['66ymk3vt']
2024-05-20 19:27:52 INFO Cleaning up finished run: 66ymk3vt
2024-05-20 19:27:52 INFO Agent received command: run
2024-05-20 19:27:52 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 19:27:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 19:27:57 INFO Running runs: ['ao5zkia3']
2024-05-20 19:29:59 INFO Cleaning up finished run: ao5zkia3
2024-05-20 19:29:59 INFO Agent received command: run
2024-05-20 19:29:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 19:29:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 19:30:04 INFO Running runs: ['gh8huha4']
2024-05-20 19:32:17 INFO Cleaning up finished run: gh8huha4
2024-05-20 19:32:18 INFO Agent received command: run
2024-05-20 19:32:18 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 19:32:18 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 19:32:23 INFO Running runs: ['wylriu4c']
2024-05-20 19:34:30 INFO Cleaning up finished run: wylriu4c
2024-05-20 19:34:31 INFO Agent received command: run
2024-05-20 19:34:31 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 19:34:31 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 19:34:36 INFO Running runs: ['5rn08zgj']
2024-05-20 19:36:22 INFO Cleaning up finished run: 5rn08zgj
2024-05-20 19:36:22 INFO Agent received command: run
2024-05-20 19:36:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 19:36:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 19:36:27 INFO Running runs: ['ti45wql6']
2024-05-20 19:38:46 INFO Cleaning up finished run: ti45wql6
2024-05-20 19:38:47 INFO Agent received command: run
2024-05-20 19:38:47 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 19:38:47 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 19:38:52 INFO Running runs: ['1z9bwcsy']
2024-05-20 19:42:08 INFO Cleaning up finished run: 1z9bwcsy
2024-05-20 19:42:08 INFO Agent received command: run
2024-05-20 19:42:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 19:42:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 19:42:13 INFO Running runs: ['38tn1rtq']
2024-05-20 19:44:42 INFO Cleaning up finished run: 38tn1rtq
2024-05-20 19:44:42 INFO Agent received command: run
2024-05-20 19:44:42 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 19:44:42 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 19:44:47 INFO Running runs: ['myphmkoc']
2024-05-20 19:46:39 INFO Cleaning up finished run: myphmkoc
2024-05-20 19:46:39 INFO Agent received command: run
2024-05-20 19:46:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 19:46:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 19:46:44 INFO Running runs: ['3ff2litg']
2024-05-20 19:48:09 INFO Cleaning up finished run: 3ff2litg
2024-05-20 19:48:10 INFO Agent received command: run
2024-05-20 19:48:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 19:48:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 19:48:15 INFO Running runs: ['ot9sny1b']
2024-05-20 19:50:06 INFO Cleaning up finished run: ot9sny1b
2024-05-20 19:50:06 INFO Agent received command: run
2024-05-20 19:50:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 19:50:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 19:50:11 INFO Running runs: ['10e0ig8a']
2024-05-20 19:52:56 INFO Cleaning up finished run: 10e0ig8a
2024-05-20 19:52:56 INFO Agent received command: run
2024-05-20 19:52:56 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 19:52:56 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 19:53:01 INFO Running runs: ['x54iljrp']
2024-05-20 19:54:53 INFO Cleaning up finished run: x54iljrp
2024-05-20 19:54:53 INFO Agent received command: run
2024-05-20 19:54:53 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 19:54:53 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 19:54:58 INFO Running runs: ['s9prpeu6']
2024-05-20 19:57:48 INFO Cleaning up finished run: s9prpeu6
2024-05-20 19:57:48 INFO Agent received command: run
2024-05-20 19:57:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 19:57:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 19:57:53 INFO Running runs: ['7off9bx9']
2024-05-20 19:59:45 INFO Cleaning up finished run: 7off9bx9
2024-05-20 19:59:45 INFO Agent received command: run
2024-05-20 19:59:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 19:59:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 19:59:50 INFO Running runs: ['t0gjfifo']
2024-05-20 20:02:24 INFO Cleaning up finished run: t0gjfifo
2024-05-20 20:02:24 INFO Agent received command: run
2024-05-20 20:02:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 20:02:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 20:02:29 INFO Running runs: ['v0azpme2']
2024-05-20 20:04:21 INFO Cleaning up finished run: v0azpme2
2024-05-20 20:04:21 INFO Agent received command: run
2024-05-20 20:04:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 20:04:23 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 20:04:28 INFO Running runs: ['efhn79sh']
2024-05-20 20:06:25 INFO Cleaning up finished run: efhn79sh
2024-05-20 20:06:25 INFO Agent received command: run
2024-05-20 20:06:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 20:06:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 20:06:30 INFO Running runs: ['bc2znppq']
2024-05-20 20:09:04 INFO Cleaning up finished run: bc2znppq
2024-05-20 20:09:05 INFO Agent received command: run
2024-05-20 20:09:05 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 20:09:05 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 20:09:10 INFO Running runs: ['vo7z0vil']
2024-05-20 20:12:58 INFO Cleaning up finished run: vo7z0vil
2024-05-20 20:12:59 INFO Agent received command: run
2024-05-20 20:12:59 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 20:12:59 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 20:13:04 INFO Running runs: ['em6446s8']
2024-05-20 20:17:25 INFO Cleaning up finished run: em6446s8
2024-05-20 20:17:25 INFO Agent received command: run
2024-05-20 20:17:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 20:17:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 20:17:30 INFO Running runs: ['8zytmyt9']
2024-05-20 20:19:43 INFO Cleaning up finished run: 8zytmyt9
2024-05-20 20:19:43 INFO Agent received command: run
2024-05-20 20:19:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 20:19:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 20:19:48 INFO Running runs: ['mwe4081t']
2024-05-20 20:21:24 INFO Cleaning up finished run: mwe4081t
2024-05-20 20:21:24 INFO Agent received command: run
2024-05-20 20:21:24 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 20:21:24 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 20:21:29 INFO Running runs: ['ebtrr1et']
2024-05-20 20:24:09 INFO Cleaning up finished run: ebtrr1et
2024-05-20 20:24:09 INFO Agent received command: run
2024-05-20 20:24:09 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 20:24:09 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=random
2024-05-20 20:24:14 INFO Running runs: ['v25ciz95']
2024-05-20 20:26:33 INFO Cleaning up finished run: v25ciz95
2024-05-20 20:26:33 INFO Agent received command: run
2024-05-20 20:26:33 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 20:26:33 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 20:26:38 INFO Running runs: ['uo472tnv']
2024-05-20 20:29:02 INFO Cleaning up finished run: uo472tnv
2024-05-20 20:29:03 INFO Agent received command: run
2024-05-20 20:29:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 20:29:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 20:29:08 INFO Running runs: ['wqh5nkk3']
2024-05-20 20:31:26 INFO Cleaning up finished run: wqh5nkk3
2024-05-20 20:31:27 INFO Agent received command: run
2024-05-20 20:31:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 20:31:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 20:31:32 INFO Running runs: ['508xjarq']
2024-05-20 20:34:32 INFO Cleaning up finished run: 508xjarq
2024-05-20 20:34:33 INFO Agent received command: run
2024-05-20 20:34:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 20:34:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 20:34:38 INFO Running runs: ['kelt1stg']
2024-05-20 20:36:51 INFO Cleaning up finished run: kelt1stg
2024-05-20 20:36:51 INFO Agent received command: run
2024-05-20 20:36:51 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 20:36:51 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 20:36:56 INFO Running runs: ['o1ml0snr']
2024-05-20 20:39:04 INFO Cleaning up finished run: o1ml0snr
2024-05-20 20:39:04 INFO Agent received command: run
2024-05-20 20:39:04 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 20:39:04 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 20:39:09 INFO Running runs: ['4ocs1opk']
2024-05-20 20:41:44 INFO Cleaning up finished run: 4ocs1opk
2024-05-20 20:41:44 INFO Agent received command: run
2024-05-20 20:41:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 20:41:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 20:41:49 INFO Running runs: ['c8fuq0sj']
2024-05-20 20:45:38 INFO Cleaning up finished run: c8fuq0sj
2024-05-20 20:45:38 INFO Agent received command: run
2024-05-20 20:45:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 20:45:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 20:45:44 INFO Running runs: ['lz5xyb71']
2024-05-20 20:48:01 INFO Cleaning up finished run: lz5xyb71
2024-05-20 20:48:02 INFO Agent received command: run
2024-05-20 20:48:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 20:48:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 20:48:07 INFO Running runs: ['bnenyy9a']
2024-05-20 20:49:42 INFO Cleaning up finished run: bnenyy9a
2024-05-20 20:49:43 INFO Agent received command: run
2024-05-20 20:49:43 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 20:49:43 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 20:49:48 INFO Running runs: ['6cf4fvt7']
2024-05-20 20:51:55 INFO Cleaning up finished run: 6cf4fvt7
2024-05-20 20:51:56 INFO Agent received command: run
2024-05-20 20:51:56 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 20:51:56 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 20:52:01 INFO Running runs: ['hgkxyudr']
2024-05-20 20:54:19 INFO Cleaning up finished run: hgkxyudr
2024-05-20 20:54:19 INFO Agent received command: run
2024-05-20 20:54:19 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 20:54:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 20:54:26 INFO Running runs: ['q0i1ibjm']
2024-05-20 20:57:16 INFO Cleaning up finished run: q0i1ibjm
2024-05-20 20:57:16 INFO Agent received command: run
2024-05-20 20:57:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 20:57:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 20:57:21 INFO Running runs: ['xuoc88qx']
2024-05-20 20:59:44 INFO Cleaning up finished run: xuoc88qx
2024-05-20 20:59:45 INFO Agent received command: run
2024-05-20 20:59:45 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 20:59:45 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 20:59:50 INFO Running runs: ['lwtc2o8g']
2024-05-20 21:01:36 INFO Cleaning up finished run: lwtc2o8g
2024-05-20 21:01:36 INFO Agent received command: run
2024-05-20 21:01:36 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 21:01:36 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 21:01:41 INFO Running runs: ['5jq0f3rq']
2024-05-20 21:04:21 INFO Cleaning up finished run: 5jq0f3rq
2024-05-20 21:04:21 INFO Agent received command: run
2024-05-20 21:04:21 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-20 21:04:21 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-20 21:04:26 INFO Running runs: ['rnd4t2pe']
2024-05-20 21:08:42 INFO Cleaning up finished run: rnd4t2pe
2024-05-20 21:08:42 INFO Agent received command: run
2024-05-20 21:08:42 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 21:08:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 21:08:47 INFO Running runs: ['45nu9g1e']
2024-05-20 21:11:00 INFO Cleaning up finished run: 45nu9g1e
2024-05-20 21:11:00 INFO Agent received command: run
2024-05-20 21:11:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 21:11:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 21:11:05 INFO Running runs: ['55wa6qcj']
2024-05-20 21:14:54 INFO Cleaning up finished run: 55wa6qcj
2024-05-20 21:14:54 INFO Agent received command: run
2024-05-20 21:14:54 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 21:14:54 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 21:14:59 INFO Running runs: ['ojb3dvql']
2024-05-20 21:17:23 INFO Cleaning up finished run: ojb3dvql
2024-05-20 21:17:23 INFO Agent received command: run
2024-05-20 21:17:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 21:17:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 21:17:28 INFO Running runs: ['mwd78o7n']
2024-05-20 21:21:11 INFO Cleaning up finished run: mwd78o7n
2024-05-20 21:21:12 INFO Agent received command: run
2024-05-20 21:21:12 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 21:21:12 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 21:21:17 INFO Running runs: ['pj5rbg2a']
2024-05-20 21:23:51 INFO Cleaning up finished run: pj5rbg2a
2024-05-20 21:23:51 INFO Agent received command: run
2024-05-20 21:23:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 21:23:52 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 21:23:57 INFO Running runs: ['kxzw4qro']
2024-05-20 21:27:13 INFO Cleaning up finished run: kxzw4qro
2024-05-20 21:27:13 INFO Agent received command: run
2024-05-20 21:27:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 21:27:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 21:27:18 INFO Running runs: ['si68ii2v']
2024-05-20 21:30:19 INFO Cleaning up finished run: si68ii2v
2024-05-20 21:30:19 INFO Agent received command: run
2024-05-20 21:30:19 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 21:30:19 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 21:30:24 INFO Running runs: ['ht8qb7e8']
2024-05-20 21:31:33 INFO Cleaning up finished run: ht8qb7e8
2024-05-20 21:31:34 INFO Agent received command: run
2024-05-20 21:31:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 21:31:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 21:31:39 INFO Running runs: ['vxy6q88o']
2024-05-20 21:33:41 INFO Cleaning up finished run: vxy6q88o
2024-05-20 21:33:41 INFO Agent received command: run
2024-05-20 21:33:41 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 21:33:42 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 21:33:47 INFO Running runs: ['vbkahgun']
2024-05-20 21:36:37 INFO Cleaning up finished run: vbkahgun
2024-05-20 21:36:37 INFO Agent received command: run
2024-05-20 21:36:37 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 21:36:37 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 21:36:42 INFO Running runs: ['nxcpa3m0']
2024-05-20 21:38:13 INFO Cleaning up finished run: nxcpa3m0
2024-05-20 21:38:13 INFO Agent received command: run
2024-05-20 21:38:13 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 21:38:13 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 21:38:18 INFO Running runs: ['3qg648ib']
2024-05-20 21:40:04 INFO Cleaning up finished run: 3qg648ib
2024-05-20 21:40:04 INFO Agent received command: run
2024-05-20 21:40:04 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 21:40:04 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 21:40:09 INFO Running runs: ['9df5w18b']
2024-05-20 21:43:10 INFO Cleaning up finished run: 9df5w18b
2024-05-20 21:43:10 INFO Agent received command: run
2024-05-20 21:43:10 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 21:43:10 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 21:43:15 INFO Running runs: ['xt1n98x0']
2024-05-20 21:46:16 INFO Cleaning up finished run: xt1n98x0
2024-05-20 21:46:16 INFO Agent received command: run
2024-05-20 21:46:16 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 21:46:16 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 21:46:21 INFO Running runs: ['6aaxbw23']
2024-05-20 21:48:34 INFO Cleaning up finished run: 6aaxbw23
2024-05-20 21:48:34 INFO Agent received command: run
2024-05-20 21:48:34 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 21:48:34 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 21:48:39 INFO Running runs: ['0b8phufr']
2024-05-20 21:50:10 INFO Cleaning up finished run: 0b8phufr
2024-05-20 21:50:10 INFO Agent received command: run
2024-05-20 21:50:10 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: random
2024-05-20 21:50:10 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=random
2024-05-20 21:50:15 INFO Running runs: ['q6rs56y3']
2024-05-20 21:53:00 INFO Cleaning up finished run: q6rs56y3
2024-05-20 21:53:00 INFO Agent received command: run
2024-05-20 21:53:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 21:53:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-20 21:53:05 INFO Running runs: ['qm7udvvn']
2024-05-20 21:55:02 INFO Cleaning up finished run: qm7udvvn
2024-05-20 21:55:02 INFO Agent received command: run
2024-05-20 21:55:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 21:55:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 21:55:07 INFO Running runs: ['mgyxpyfh']
2024-05-20 21:57:41 INFO Cleaning up finished run: mgyxpyfh
2024-05-20 21:57:41 INFO Agent received command: run
2024-05-20 21:57:41 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 21:57:41 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 21:57:46 INFO Running runs: ['ajx7a6yw']
2024-05-20 21:59:22 INFO Cleaning up finished run: ajx7a6yw
2024-05-20 21:59:22 INFO Agent received command: run
2024-05-20 21:59:22 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 21:59:22 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 21:59:27 INFO Running runs: ['mzsp42dz']
2024-05-20 22:00:41 INFO Cleaning up finished run: mzsp42dz
2024-05-20 22:00:42 INFO Agent received command: run
2024-05-20 22:00:42 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 22:00:42 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-20 22:00:47 INFO Running runs: ['87fxg05p']
2024-05-20 22:02:22 INFO Cleaning up finished run: 87fxg05p
2024-05-20 22:02:23 INFO Agent received command: run
2024-05-20 22:02:23 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 22:02:23 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 22:02:28 INFO Running runs: ['grgypq4u']
2024-05-20 22:05:07 INFO Cleaning up finished run: grgypq4u
2024-05-20 22:05:07 INFO Agent received command: run
2024-05-20 22:05:07 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 22:05:07 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 22:05:12 INFO Running runs: ['62iddhfu']
2024-05-20 22:07:51 INFO Cleaning up finished run: 62iddhfu
2024-05-20 22:07:51 INFO Agent received command: run
2024-05-20 22:07:51 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 22:07:51 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 22:07:57 INFO Running runs: ['cp174ewi']
2024-05-20 22:09:53 INFO Cleaning up finished run: cp174ewi
2024-05-20 22:09:53 INFO Agent received command: run
2024-05-20 22:09:53 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 22:09:53 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 22:09:58 INFO Running runs: ['ayl58bck']
2024-05-20 22:11:07 INFO Cleaning up finished run: ayl58bck
2024-05-20 22:11:08 INFO Agent received command: run
2024-05-20 22:11:08 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: random
2024-05-20 22:11:08 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=random
2024-05-20 22:11:13 INFO Running runs: ['ows6sgii']
2024-05-20 22:12:43 INFO Cleaning up finished run: ows6sgii
2024-05-20 22:12:43 INFO Agent received command: run
2024-05-20 22:12:43 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: momentum
	weight_init: he
2024-05-20 22:12:43 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=momentum --weight_init=he
2024-05-20 22:12:48 INFO Running runs: ['vjjenxf3']
2024-05-20 22:15:11 INFO Cleaning up finished run: vjjenxf3
2024-05-20 22:15:12 INFO Agent received command: run
2024-05-20 22:15:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 22:15:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 22:15:17 INFO Running runs: ['ufzyx0yx']
2024-05-20 22:17:03 INFO Cleaning up finished run: ufzyx0yx
2024-05-20 22:17:03 INFO Agent received command: run
2024-05-20 22:17:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: he
2024-05-20 22:17:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=he
2024-05-20 22:17:08 INFO Running runs: ['jcvy249e']
2024-05-20 22:18:38 INFO Cleaning up finished run: jcvy249e
2024-05-20 22:18:39 INFO Agent received command: run
2024-05-20 22:18:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 22:18:39 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 22:18:44 INFO Running runs: ['ajiolk35']
2024-05-20 22:21:01 INFO Cleaning up finished run: ajiolk35
2024-05-20 22:21:02 INFO Agent received command: run
2024-05-20 22:21:02 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 22:21:02 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 22:21:07 INFO Running runs: ['qbt8deq9']
2024-05-20 22:23:14 INFO Cleaning up finished run: qbt8deq9
2024-05-20 22:23:14 INFO Agent received command: run
2024-05-20 22:23:14 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 22:23:14 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 22:23:19 INFO Running runs: ['eq4vqonc']
2024-05-20 22:25:26 INFO Cleaning up finished run: eq4vqonc
2024-05-20 22:25:27 INFO Agent received command: run
2024-05-20 22:25:27 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 22:25:27 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 22:25:32 INFO Running runs: ['bjjzunyt']
2024-05-20 22:27:44 INFO Cleaning up finished run: bjjzunyt
2024-05-20 22:27:45 INFO Agent received command: run
2024-05-20 22:27:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 22:27:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 22:27:50 INFO Running runs: ['5bks25qi']
2024-05-20 22:30:45 INFO Cleaning up finished run: 5bks25qi
2024-05-20 22:30:45 INFO Agent received command: run
2024-05-20 22:30:45 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 22:30:45 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 22:30:50 INFO Running runs: ['fomztfv4']
2024-05-20 22:34:01 INFO Cleaning up finished run: fomztfv4
2024-05-20 22:34:01 INFO Agent received command: run
2024-05-20 22:34:01 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 22:34:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=random
2024-05-20 22:34:06 INFO Running runs: ['2dkuyewv']
2024-05-20 22:35:47 INFO Cleaning up finished run: 2dkuyewv
2024-05-20 22:35:48 INFO Agent received command: run
2024-05-20 22:35:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 22:35:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 22:35:53 INFO Running runs: ['5p72ifp5']
2024-05-20 22:39:37 INFO Cleaning up finished run: 5p72ifp5
2024-05-20 22:39:38 INFO Agent received command: run
2024-05-20 22:39:38 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-20 22:39:38 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=random
2024-05-20 22:39:43 INFO Running runs: ['jx4uzo9q']
2024-05-20 22:41:56 INFO Cleaning up finished run: jx4uzo9q
2024-05-20 22:41:57 INFO Agent received command: run
2024-05-20 22:41:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 22:41:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 22:42:02 INFO Running runs: ['ek5vwg7l']
2024-05-20 22:43:48 INFO Cleaning up finished run: ek5vwg7l
2024-05-20 22:43:48 INFO Agent received command: run
2024-05-20 22:43:48 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 22:43:48 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 22:43:53 INFO Running runs: ['oyayua5m']
2024-05-20 22:45:55 INFO Cleaning up finished run: oyayua5m
2024-05-20 22:45:56 INFO Agent received command: run
2024-05-20 22:45:56 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 22:45:56 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 22:46:01 INFO Running runs: ['maum5452']
2024-05-20 22:47:48 INFO Cleaning up finished run: maum5452
2024-05-20 22:47:49 INFO Agent received command: run
2024-05-20 22:47:49 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: sgd
	weight_init: he
2024-05-20 22:47:49 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=sgd --weight_init=he
2024-05-20 22:47:54 INFO Running runs: ['esk6z8xk']
2024-05-20 22:49:13 INFO Cleaning up finished run: esk6z8xk
2024-05-20 22:49:14 INFO Agent received command: run
2024-05-20 22:49:14 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: random
2024-05-20 22:49:14 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=random
2024-05-20 22:49:19 INFO Running runs: ['c1hw1n4m']
2024-05-20 22:50:44 INFO Cleaning up finished run: c1hw1n4m
2024-05-20 22:50:44 INFO Agent received command: run
2024-05-20 22:50:44 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 22:50:44 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 22:50:49 INFO Running runs: ['5qgh9v14']
2024-05-20 22:52:45 INFO Cleaning up finished run: 5qgh9v14
2024-05-20 22:52:46 INFO Agent received command: run
2024-05-20 22:52:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 22:52:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 22:52:51 INFO Running runs: ['4jp127fb']
2024-05-20 22:54:00 INFO Cleaning up finished run: 4jp127fb
2024-05-20 22:54:00 INFO Agent received command: run
2024-05-20 22:54:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 4
	optimizer: sgd
	weight_init: he
2024-05-20 22:54:00 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=4 --optimizer=sgd --weight_init=he
2024-05-20 22:54:05 INFO Running runs: ['y8gybjn9']
2024-05-20 22:55:46 INFO Cleaning up finished run: y8gybjn9
2024-05-20 22:55:46 INFO Agent received command: run
2024-05-20 22:55:46 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 22:55:46 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 22:55:51 INFO Running runs: ['2ph6ayc9']
2024-05-20 22:58:26 INFO Cleaning up finished run: 2ph6ayc9
2024-05-20 22:58:26 INFO Agent received command: run
2024-05-20 22:58:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: he
2024-05-20 22:58:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=he
2024-05-20 22:58:31 INFO Running runs: ['2awjx8rz']
2024-05-20 22:59:29 INFO Cleaning up finished run: 2awjx8rz
2024-05-20 22:59:30 INFO Agent received command: run
2024-05-20 22:59:30 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 22:59:30 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.01 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=random
2024-05-20 22:59:35 INFO Running runs: ['4texyzin']
2024-05-20 23:00:54 INFO Cleaning up finished run: 4texyzin
2024-05-20 23:00:54 INFO Agent received command: run
2024-05-20 23:00:54 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 16
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-20 23:00:54 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=16 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-20 23:00:59 INFO Running runs: ['y0bcxnud']
2024-05-20 23:04:48 INFO Cleaning up finished run: y0bcxnud
2024-05-20 23:04:48 INFO Agent received command: run
2024-05-20 23:04:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 23:04:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 23:04:53 INFO Running runs: ['2ixf79yl']
2024-05-20 23:07:32 INFO Cleaning up finished run: 2ixf79yl
2024-05-20 23:07:33 INFO Agent received command: run
2024-05-20 23:07:33 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 23:07:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 23:07:38 INFO Running runs: ['x7gsre9y']
2024-05-20 23:09:56 INFO Cleaning up finished run: x7gsre9y
2024-05-20 23:09:57 INFO Agent received command: run
2024-05-20 23:09:57 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 23:09:57 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 23:10:02 INFO Running runs: ['g3xnt9do']
2024-05-20 23:12:26 INFO Cleaning up finished run: g3xnt9do
2024-05-20 23:12:26 INFO Agent received command: run
2024-05-20 23:12:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nesterov
	weight_init: random
2024-05-20 23:12:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nesterov --weight_init=random
2024-05-20 23:12:31 INFO Running runs: ['utr5tu1m']
2024-05-20 23:14:29 INFO Cleaning up finished run: utr5tu1m
2024-05-20 23:14:29 INFO Agent received command: run
2024-05-20 23:14:29 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 23:14:29 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 23:14:34 INFO Running runs: ['xmmfasj9']
2024-05-20 23:16:17 INFO Cleaning up finished run: xmmfasj9
2024-05-20 23:16:17 INFO Agent received command: run
2024-05-20 23:16:17 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: adam
	weight_init: he
2024-05-20 23:16:17 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=adam --weight_init=he
2024-05-20 23:16:22 INFO Running runs: ['83b9fhwx']
2024-05-20 23:18:20 INFO Cleaning up finished run: 83b9fhwx
2024-05-20 23:18:21 INFO Agent received command: run
2024-05-20 23:18:21 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: he
2024-05-20 23:18:21 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=he
2024-05-20 23:18:26 INFO Running runs: ['5140grb3']
2024-05-20 23:20:34 INFO Cleaning up finished run: 5140grb3
2024-05-20 23:20:35 INFO Agent received command: run
2024-05-20 23:20:35 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 23:20:35 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 23:20:40 INFO Running runs: ['mumuzd2m']
2024-05-20 23:23:58 INFO Cleaning up finished run: mumuzd2m
2024-05-20 23:23:58 INFO Agent received command: run
2024-05-20 23:23:58 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: he
2024-05-20 23:23:58 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=he
2024-05-20 23:24:03 INFO Running runs: ['hm2fu08n']
2024-05-20 23:26:49 INFO Cleaning up finished run: hm2fu08n
2024-05-20 23:26:50 INFO Agent received command: run
2024-05-20 23:26:50 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 23:26:50 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 23:26:55 INFO Running runs: ['ng68tqo1']
2024-05-20 23:30:23 INFO Cleaning up finished run: ng68tqo1
2024-05-20 23:30:24 INFO Agent received command: run
2024-05-20 23:30:24 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 3
	optimizer: sgd
	weight_init: random
2024-05-20 23:30:24 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=3 --optimizer=sgd --weight_init=random
2024-05-20 23:30:29 INFO Running runs: ['rq81ywcz']
2024-05-20 23:32:26 INFO Cleaning up finished run: rq81ywcz
2024-05-20 23:32:26 INFO Agent received command: run
2024-05-20 23:32:26 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 23:32:26 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 23:32:31 INFO Running runs: ['bpylkmq2']
2024-05-20 23:34:02 INFO Cleaning up finished run: bpylkmq2
2024-05-20 23:34:03 INFO Agent received command: run
2024-05-20 23:34:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: rmsprop
	weight_init: he
2024-05-20 23:34:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=rmsprop --weight_init=he
2024-05-20 23:34:08 INFO Running runs: ['hftmp1x6']
2024-05-20 23:36:32 INFO Cleaning up finished run: hftmp1x6
2024-05-20 23:36:32 INFO Agent received command: run
2024-05-20 23:36:32 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 23:36:33 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 23:36:38 INFO Running runs: ['n0f4xd89']
2024-05-20 23:41:11 INFO Cleaning up finished run: n0f4xd89
2024-05-20 23:41:11 INFO Agent received command: run
2024-05-20 23:41:11 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 23:41:11 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 23:41:16 INFO Running runs: ['dvjtz09o']
2024-05-20 23:44:59 INFO Cleaning up finished run: dvjtz09o
2024-05-20 23:45:00 INFO Agent received command: run
2024-05-20 23:45:00 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 3
	optimizer: nadam
	weight_init: he
2024-05-20 23:45:01 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=3 --optimizer=nadam --weight_init=he
2024-05-20 23:45:06 INFO Running runs: ['tlwyq8k0']
2024-05-20 23:48:12 INFO Cleaning up finished run: tlwyq8k0
2024-05-20 23:48:12 INFO Agent received command: run
2024-05-20 23:48:12 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: momentum
	weight_init: random
2024-05-20 23:48:12 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=momentum --weight_init=random
2024-05-20 23:48:17 INFO Running runs: ['fdwjbp0h']
2024-05-20 23:50:26 INFO Cleaning up finished run: fdwjbp0h
2024-05-20 23:50:26 INFO Agent received command: run
2024-05-20 23:50:26 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-20 23:50:26 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-20 23:50:31 INFO Running runs: ['fowowiai']
2024-05-20 23:53:05 INFO Cleaning up finished run: fowowiai
2024-05-20 23:53:06 INFO Agent received command: run
2024-05-20 23:53:06 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-20 23:53:06 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.001 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-20 23:53:11 INFO Running runs: ['f5jwzon1']
2024-05-20 23:55:05 INFO Cleaning up finished run: f5jwzon1
2024-05-20 23:55:05 INFO Agent received command: run
2024-05-20 23:55:05 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 0.01
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: he
2024-05-20 23:55:06 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=0.01 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=he
2024-05-20 23:55:11 INFO Running runs: ['7zy1apav']
2024-05-20 23:56:25 INFO Cleaning up finished run: 7zy1apav
2024-05-20 23:56:25 INFO Agent received command: run
2024-05-20 23:56:25 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-20 23:56:25 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-20 23:56:30 INFO Running runs: ['w34quwqh']
2024-05-20 23:59:10 INFO Cleaning up finished run: w34quwqh
2024-05-20 23:59:10 INFO Agent received command: run
2024-05-20 23:59:10 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.001
	batch_size: 64
	beta1: 0.9
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: adam
	weight_init: he
2024-05-20 23:59:10 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.001 --batch_size=64 --beta1=0.9 --epochs=10 --hidden_sizes=64 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=adam --weight_init=he
2024-05-20 23:59:15 INFO Running runs: ['mz2ddkt8']
2024-05-21 00:01:33 INFO Cleaning up finished run: mz2ddkt8
2024-05-21 00:01:34 INFO Agent received command: run
2024-05-21 00:01:34 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 16
	beta1: 0.99
	epochs: 5
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 4
	optimizer: adam
	weight_init: he
2024-05-21 00:01:34 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=16 --beta1=0.99 --epochs=5 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=4 --optimizer=adam --weight_init=he
2024-05-21 00:01:39 INFO Running runs: ['jlczhmpd']
2024-05-21 00:04:03 INFO Cleaning up finished run: jlczhmpd
2024-05-21 00:04:03 INFO Agent received command: run
2024-05-21 00:04:03 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.0001
	batch_size: 64
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: nesterov
	weight_init: he
2024-05-21 00:04:03 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.0001 --batch_size=64 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=nesterov --weight_init=he
2024-05-21 00:04:08 INFO Running runs: ['z5t53kgs']
2024-05-21 00:06:41 INFO Cleaning up finished run: z5t53kgs
2024-05-21 00:06:42 INFO Agent received command: run
2024-05-21 00:06:42 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.001
	batch_size: 32
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nesterov
	weight_init: random
2024-05-21 00:06:42 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.001 --batch_size=32 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nesterov --weight_init=random
2024-05-21 00:06:47 INFO Running runs: ['j7i5gl0f']
2024-05-21 00:08:01 INFO Cleaning up finished run: j7i5gl0f
2024-05-21 00:08:02 INFO Agent received command: run
2024-05-21 00:08:02 INFO Agent starting run with config:
	activation: sigmoid
	alpha: 0.0001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 3
	optimizer: rmsprop
	weight_init: he
2024-05-21 00:08:02 INFO About to run command: /usr/bin/env python train.py --activation=sigmoid --alpha=0.0001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.001 --loss=cross_entropy --num_layers=3 --optimizer=rmsprop --weight_init=he
2024-05-21 00:08:07 INFO Running runs: ['jpuymrzd']
2024-05-21 00:09:47 INFO Cleaning up finished run: jpuymrzd
2024-05-21 00:09:48 INFO Agent received command: run
2024-05-21 00:09:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 16
	beta1: 0.9
	epochs: 5
	hidden_sizes: 32
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 4
	optimizer: rmsprop
	weight_init: random
2024-05-21 00:09:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=16 --beta1=0.9 --epochs=5 --hidden_sizes=32 --learning_rate=0.0001 --loss=cross_entropy --num_layers=4 --optimizer=rmsprop --weight_init=random
2024-05-21 00:09:53 INFO Running runs: ['cxadhb5w']
2024-05-21 00:11:39 INFO Cleaning up finished run: cxadhb5w
2024-05-21 00:11:39 INFO Agent received command: run
2024-05-21 00:11:39 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 64
	learning_rate: 0.001
	loss: cross_entropy
	num_layers: 4
	optimizer: nadam
	weight_init: he
2024-05-21 00:11:40 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=64 --learning_rate=0.001 --loss=cross_entropy --num_layers=4 --optimizer=nadam --weight_init=he
2024-05-21 00:11:45 INFO Running runs: ['4oxmb6jp']
2024-05-21 00:13:47 INFO Cleaning up finished run: 4oxmb6jp
2024-05-21 00:13:48 INFO Agent received command: run
2024-05-21 00:13:48 INFO Agent starting run with config:
	activation: tanh
	alpha: 0.001
	batch_size: 32
	beta1: 0.99
	epochs: 10
	hidden_sizes: 128
	learning_rate: 0.0001
	loss: cross_entropy
	num_layers: 5
	optimizer: nadam
	weight_init: he
2024-05-21 00:13:48 INFO About to run command: /usr/bin/env python train.py --activation=tanh --alpha=0.001 --batch_size=32 --beta1=0.99 --epochs=10 --hidden_sizes=128 --learning_rate=0.0001 --loss=cross_entropy --num_layers=5 --optimizer=nadam --weight_init=he
2024-05-21 00:13:53 INFO Running runs: ['zbqfsnwd']
2024-05-21 00:17:24 INFO Cleaning up finished run: zbqfsnwd
2024-05-21 00:17:25 INFO Agent received command: run
2024-05-21 00:17:25 INFO Agent starting run with config:
	activation: ReLU
	alpha: 0.0001
	batch_size: 32
	beta1: 0.99
	epochs: 5
	hidden_sizes: 32
	learning_rate: 1e-05
	loss: cross_entropy
	num_layers: 5
	optimizer: momentum
	weight_init: random
2024-05-21 00:17:25 INFO About to run command: /usr/bin/env python train.py --activation=ReLU --alpha=0.0001 --batch_size=32 --beta1=0.99 --epochs=5 --hidden_sizes=32 --learning_rate=1e-05 --loss=cross_entropy --num_layers=5 --optimizer=momentum --weight_init=random
2024-05-21 00:17:30 INFO Running runs: ['8j98pjsa']
2024-05-21 00:18:28 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-21 00:18:28 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-21 00:18:28 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-21 00:18:28 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-21 00:18:28 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
2024-05-21 00:18:28 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'OSError('Tunnel connection failed: 403 Forbidden')': /api/4504800232407040/envelope/
